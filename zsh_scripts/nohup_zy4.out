WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-10-19 17:20:06,599] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-19 17:20:06,604] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-19 17:20:06,630] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-19 17:20:06,630] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!
Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!
PyTorch: setting up devices
PyTorch: setting up devices
Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!
Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!
PyTorch: setting up devices
PyTorch: setting up devices
/root/miniconda3/lib/python3.10/site-packages/transformers/training_args.py:1598: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
ModelArguments(model_name_or_path='/ML-A100/home/xiangyue/models/Llama-2-7b-hf', is_initialized=False)
DataArguments(data_path='/ML-A100/home/xiangyue/lyf/AttributionBench/data/hf_data', train_subset=None, test_subset=None, generator_or_evaluator='evaluator', num_train_samples=-1, debug_setting=False, contained_datasets='all', dataset_version='v2.2', template='base_llama', template_path='../src/template.json')
TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=100,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>],
fsdp_config={'min_num_params': 0, 'transformer_layer_cls_to_wrap': ['LlamaDecoderLayer'], 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer,
full_determinism=False,
gradient_accumulation_steps=8,
gradient_checkpointing=True,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/runs/Oct19_17-20-09_di-20230817113112-ghnj4,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
model_max_length=4096,
mp_parameters=,
no_cuda=False,
num_train_epochs=2.0,
optim=adamw_torch,
optim_args=None,
output_dir=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)
/root/miniconda3/lib/python3.10/site-packages/transformers/training_args.py:1598: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
/root/miniconda3/lib/python3.10/site-packages/transformers/training_args.py:1598: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
ModelArguments(model_name_or_path='/ML-A100/home/xiangyue/models/Llama-2-7b-hf', is_initialized=False)
DataArguments(data_path='/ML-A100/home/xiangyue/lyf/AttributionBench/data/hf_data', train_subset=None, test_subset=None, generator_or_evaluator='evaluator', num_train_samples=-1, debug_setting=False, contained_datasets='all', dataset_version='v2.2', template='base_llama', template_path='../src/template.json')
ModelArguments(model_name_or_path='/ML-A100/home/xiangyue/models/Llama-2-7b-hf', is_initialized=False)
DataArguments(data_path='/ML-A100/home/xiangyue/lyf/AttributionBench/data/hf_data', train_subset=None, test_subset=None, generator_or_evaluator='evaluator', num_train_samples=-1, debug_setting=False, contained_datasets='all', dataset_version='v2.2', template='base_llama', template_path='../src/template.json')
TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=100,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>],
fsdp_config={'min_num_params': 0, 'transformer_layer_cls_to_wrap': ['LlamaDecoderLayer'], 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer,
full_determinism=False,
gradient_accumulation_steps=8,
gradient_checkpointing=True,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/runs/Oct19_17-20-09_di-20230817113112-ghnj4,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
model_max_length=4096,
mp_parameters=,
no_cuda=False,
num_train_epochs=2.0,
optim=adamw_torch,
optim_args=None,
output_dir=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)
TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=100,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>],
fsdp_config={'min_num_params': 0, 'transformer_layer_cls_to_wrap': ['LlamaDecoderLayer'], 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer,
full_determinism=False,
gradient_accumulation_steps=8,
gradient_checkpointing=True,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/runs/Oct19_17-20-09_di-20230817113112-ghnj4,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
model_max_length=4096,
mp_parameters=,
no_cuda=False,
num_train_epochs=2.0,
optim=adamw_torch,
optim_args=None,
output_dir=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/config.json
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/config.json
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/config.json
Model config LlamaConfig {
  "_name_or_path": "/ML-A100/home/xiangyue/models/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

Start Loading Model
False
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/config.json
Model config LlamaConfig {
  "_name_or_path": "/ML-A100/home/xiangyue/models/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

Start Loading ModelModel config LlamaConfig {
  "_name_or_path": "/ML-A100/home/xiangyue/models/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}


Start Loading ModelFalse

False
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/config.json
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/config.json
Model config LlamaConfig {
  "_name_or_path": "/ML-A100/home/xiangyue/models/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

Model config LlamaConfig {
  "_name_or_path": "/ML-A100/home/xiangyue/models/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

Model config LlamaConfig {
  "_name_or_path": "/ML-A100/home/xiangyue/models/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

/root/miniconda3/lib/python3.10/site-packages/transformers/training_args.py:1598: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
ModelArguments(model_name_or_path='/ML-A100/home/xiangyue/models/Llama-2-7b-hf', is_initialized=False)
DataArguments(data_path='/ML-A100/home/xiangyue/lyf/AttributionBench/data/hf_data', train_subset=None, test_subset=None, generator_or_evaluator='evaluator', num_train_samples=-1, debug_setting=False, contained_datasets='all', dataset_version='v2.2', template='base_llama', template_path='../src/template.json')
TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=100,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>],
fsdp_config={'min_num_params': 0, 'transformer_layer_cls_to_wrap': ['LlamaDecoderLayer'], 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer,
full_determinism=False,
gradient_accumulation_steps=8,
gradient_checkpointing=True,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=3,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/runs/Oct19_17-20-09_di-20230817113112-ghnj4,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
model_max_length=4096,
mp_parameters=,
no_cuda=False,
num_train_epochs=2.0,
optim=adamw_torch,
optim_args=None,
output_dir=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/config.json
Model config LlamaConfig {
  "_name_or_path": "/ML-A100/home/xiangyue/models/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

Start Loading Model
False
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/config.json
Model config LlamaConfig {
  "_name_or_path": "/ML-A100/home/xiangyue/models/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

loading weights file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/model.safetensors.index.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

loading weights file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/model.safetensors.index.json
loading weights file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/model.safetensors.index.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

loading weights file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/model.safetensors.index.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  8.02it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.46it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.11it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.67it/s]
All model checkpoint weights were used when initializing LlamaForCausalLM.

All the weights of LlamaForCausalLM were initialized from the model checkpoint at /ML-A100/home/xiangyue/models/Llama-2-7b-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.85it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.70it/s]
All model checkpoint weights were used when initializing LlamaForCausalLM.

All the weights of LlamaForCausalLM were initialized from the model checkpoint at /ML-A100/home/xiangyue/models/Llama-2-7b-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

loading file tokenizer.model
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading file tokenizer.json
loading file tokenizer.model
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading file tokenizer.json
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.39it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.16it/s]
All model checkpoint weights were used when initializing LlamaForCausalLM.

All the weights of LlamaForCausalLM were initialized from the model checkpoint at /ML-A100/home/xiangyue/models/Llama-2-7b-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

loading file tokenizer.model
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading file tokenizer.json
Adding <s> to the vocabulary
Adding </s> to the vocabulary
Adding <unk> to the vocabulary
Adding <s> to the vocabulary
Adding </s> to the vocabulary
Adding <unk> to the vocabulary
Adding <s> to the vocabulary
Adding </s> to the vocabulary
Adding <unk> to the vocabulary
Adding <unk> to the vocabulary
Adding <s> to the vocabulary
Adding </s> to the vocabulary
Adding <unk> to the vocabulary
Adding <s> to the vocabulary
Adding </s> to the vocabulary
Adding <unk> to the vocabulary
Adding <s> to the vocabulary
Adding </s> to the vocabulary
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
before smart_tokenizer_and_embedding_resize 32000
Assigning [PAD] to the pad_token key of the tokenizer
before smart_tokenizer_and_embedding_resize 32000
Assigning [PAD] to the pad_token key of the tokenizer
before smart_tokenizer_and_embedding_resize 32000
Assigning [PAD] to the pad_token key of the tokenizer
Adding [PAD] to the vocabulary
Adding [PAD] to the vocabulary
Adding [PAD] to the vocabulary
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
after smart_tokenizer_and_embedding_resize 32001
after smart_tokenizer_and_embedding_resize 32001
after smart_tokenizer_and_embedding_resize 32001
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.99s/it]
All model checkpoint weights were used when initializing LlamaForCausalLM.

All the weights of LlamaForCausalLM were initialized from the model checkpoint at /ML-A100/home/xiangyue/models/Llama-2-7b-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
loading configuration file /ML-A100/home/xiangyue/models/Llama-2-7b-hf/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

loading file tokenizer.model
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading file tokenizer.json
Adding <s> to the vocabulary
Adding </s> to the vocabulary
Adding <unk> to the vocabulary
Adding <unk> to the vocabulary
Adding <s> to the vocabulary
Adding </s> to the vocabulary
Using pad_token, but it is not set yet.
before smart_tokenizer_and_embedding_resize 32000
Assigning [PAD] to the pad_token key of the tokenizer
Adding [PAD] to the vocabulary
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
after smart_tokenizer_and_embedding_resize 32001
Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 4/4 [00:00<00:00, 26886.56it/s]
Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]Extracting data files:  25%|██▌       | 1/4 [00:00<00:00,  4.60it/s]Extracting data files: 100%|██████████| 4/4 [00:00<00:00, 17.57it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 10500 examples [00:00, 86928.58 examples/s]Generating train split: 10500 examples [00:00, 86346.04 examples/s]
Generating dev split: 0 examples [00:00, ? examples/s]Generating dev split: 802 examples [00:00, 91158.28 examples/s]
Generating test split: 0 examples [00:00, ? examples/s]Generating test split: 1658 examples [00:00, 120193.51 examples/s]
Generating test_ood split: 0 examples [00:00, ? examples/s]Generating test_ood split: 240 examples [00:00, 76271.63 examples/s]
Map (num_proc=2):   0%|          | 0/10500 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 24/10500 [00:00<02:52, 60.81 examples/s]Map (num_proc=2):   1%|          | 109/10500 [00:00<00:38, 268.42 examples/s]Map (num_proc=2):   2%|▏         | 198/10500 [00:00<00:23, 435.61 examples/s]Map (num_proc=2):   3%|▎         | 288/10500 [00:00<00:18, 561.74 examples/s]Map (num_proc=2):   4%|▎         | 383/10500 [00:00<00:15, 669.89 examples/s]Map (num_proc=2):   5%|▍         | 476/10500 [00:00<00:13, 738.95 examples/s]Map (num_proc=2):   5%|▌         | 569/10500 [00:01<00:12, 793.44 examples/s]Map (num_proc=2):   6%|▋         | 664/10500 [00:01<00:11, 830.48 examples/s]Map (num_proc=2):   7%|▋         | 773/10500 [00:01<00:11, 873.12 examples/s]Map (num_proc=2):   8%|▊         | 865/10500 [00:01<00:10, 884.91 examples/s]Map (num_proc=2):   9%|▉         | 958/10500 [00:01<00:10, 889.40 examples/s]Map (num_proc=2):  10%|█         | 1055/10500 [00:01<00:10, 908.50 examples/s]Map (num_proc=2):  11%|█         | 1159/10500 [00:01<00:09, 943.82 examples/s]Map (num_proc=2):  12%|█▏        | 1262/10500 [00:01<00:09, 968.36 examples/s]Map (num_proc=2):  13%|█▎        | 1382/10500 [00:01<00:09, 918.53 examples/s]Map (num_proc=2):  14%|█▍        | 1476/10500 [00:01<00:09, 923.56 examples/s]Map (num_proc=2):  15%|█▍        | 1574/10500 [00:02<00:09, 936.92 examples/s]Map (num_proc=2):  16%|█▌        | 1672/10500 [00:02<00:09, 941.72 examples/s]Map (num_proc=2):  17%|█▋        | 1774/10500 [00:02<00:09, 956.18 examples/s]Map (num_proc=2):  18%|█▊        | 1886/10500 [00:02<00:09, 950.01 examples/s]Map (num_proc=2):  19%|█▉        | 1986/10500 [00:02<00:09, 865.10 examples/s]Map (num_proc=2):  20%|█▉        | 2095/10500 [00:02<00:10, 812.78 examples/s]Map (num_proc=2):  21%|██        | 2188/10500 [00:02<00:09, 835.40 examples/s]Map (num_proc=2):  22%|██▏       | 2282/10500 [00:02<00:09, 857.18 examples/s]Map (num_proc=2):  23%|██▎       | 2378/10500 [00:03<00:09, 880.03 examples/s]Map (num_proc=2):  24%|██▎       | 2469/10500 [00:03<00:09, 885.70 examples/s]Map (num_proc=2):  24%|██▍       | 2571/10500 [00:03<00:08, 916.51 examples/s]Map (num_proc=2):  25%|██▌       | 2668/10500 [00:03<00:08, 926.23 examples/s]Map (num_proc=2):  26%|██▋       | 2772/10500 [00:03<00:08, 953.19 examples/s]Map (num_proc=2):  27%|██▋       | 2871/10500 [00:03<00:07, 955.03 examples/s]Map (num_proc=2):  28%|██▊       | 2971/10500 [00:03<00:07, 964.82 examples/s]Map (num_proc=2):  29%|██▉       | 3090/10500 [00:03<00:07, 986.90 examples/s]Map (num_proc=2):  31%|███       | 3211/10500 [00:03<00:07, 941.84 examples/s]Map (num_proc=2):  32%|███▏      | 3309/10500 [00:03<00:07, 949.02 examples/s]Map (num_proc=2):  32%|███▏      | 3406/10500 [00:04<00:07, 943.12 examples/s]Map (num_proc=2):  34%|███▎      | 3525/10500 [00:04<00:07, 959.67 examples/s]Map (num_proc=2):  35%|███▍      | 3625/10500 [00:04<00:07, 965.48 examples/s]Map (num_proc=2):  36%|███▌      | 3744/10500 [00:04<00:07, 911.63 examples/s]Map (num_proc=2):  37%|███▋      | 3843/10500 [00:04<00:07, 929.60 examples/s]Map (num_proc=2):  38%|███▊      | 3951/10500 [00:04<00:06, 937.91 examples/s]Map (num_proc=2):  39%|███▊      | 4058/10500 [00:04<00:08, 798.80 examples/s]Map (num_proc=2):  40%|███▉      | 4157/10500 [00:04<00:07, 834.17 examples/s]Map (num_proc=2):  41%|████      | 4260/10500 [00:05<00:07, 879.47 examples/s]Map (num_proc=2):  42%|████▏     | 4358/10500 [00:05<00:06, 904.80 examples/s]Map (num_proc=2):  43%|████▎     | 4475/10500 [00:05<00:06, 862.12 examples/s]Map (num_proc=2):  44%|████▎     | 4584/10500 [00:05<00:06, 908.48 examples/s]Map (num_proc=2):  45%|████▍     | 4678/10500 [00:05<00:06, 908.51 examples/s]Map (num_proc=2):  46%|████▌     | 4795/10500 [00:05<00:06, 852.29 examples/s]Map (num_proc=2):  47%|████▋     | 4889/10500 [00:05<00:06, 870.45 examples/s]Map (num_proc=2):  47%|████▋     | 4987/10500 [00:05<00:06, 889.44 examples/s]Map (num_proc=2):  48%|████▊     | 5078/10500 [00:05<00:06, 889.42 examples/s]Map (num_proc=2):  49%|████▉     | 5178/10500 [00:06<00:05, 896.46 examples/s]Map (num_proc=2):  50%|█████     | 5269/10500 [00:06<00:05, 895.24 examples/s]Map (num_proc=2):  51%|█████     | 5371/10500 [00:06<00:05, 929.26 examples/s]Map (num_proc=2):  52%|█████▏    | 5470/10500 [00:06<00:05, 941.17 examples/s]Map (num_proc=2):  53%|█████▎    | 5568/10500 [00:06<00:05, 926.40 examples/s]Map (num_proc=2):  54%|█████▍    | 5665/10500 [00:06<00:05, 935.69 examples/s]Map (num_proc=2):  55%|█████▍    | 5766/10500 [00:06<00:04, 953.92 examples/s]Map (num_proc=2):  56%|█████▌    | 5886/10500 [00:06<00:04, 983.99 examples/s]Map (num_proc=2):  57%|█████▋    | 6000/10500 [00:06<00:05, 816.96 examples/s]Map (num_proc=2):  58%|█████▊    | 6101/10500 [00:07<00:05, 854.78 examples/s]Map (num_proc=2):  59%|█████▉    | 6199/10500 [00:07<00:04, 883.06 examples/s]Map (num_proc=2):  60%|█████▉    | 6297/10500 [00:07<00:04, 905.12 examples/s]Map (num_proc=2):  61%|██████    | 6401/10500 [00:07<00:04, 936.95 examples/s]Map (num_proc=2):  62%|██████▏   | 6509/10500 [00:07<00:04, 930.35 examples/s]Map (num_proc=2):  63%|██████▎   | 6607/10500 [00:07<00:04, 937.36 examples/s]Map (num_proc=2):  64%|██████▍   | 6723/10500 [00:07<00:04, 909.22 examples/s]Map (num_proc=2):  65%|██████▌   | 6825/10500 [00:07<00:03, 931.13 examples/s]Map (num_proc=2):  66%|██████▌   | 6930/10500 [00:07<00:03, 959.62 examples/s]Map (num_proc=2):  67%|██████▋   | 7035/10500 [00:08<00:03, 937.45 examples/s]Map (num_proc=2):  68%|██████▊   | 7157/10500 [00:08<00:03, 911.26 examples/s]Map (num_proc=2):  69%|██████▉   | 7258/10500 [00:08<00:03, 934.10 examples/s]Map (num_proc=2):  70%|███████   | 7358/10500 [00:08<00:03, 888.78 examples/s]Map (num_proc=2):  71%|███████   | 7452/10500 [00:08<00:03, 896.14 examples/s]Map (num_proc=2):  72%|███████▏  | 7566/10500 [00:08<00:03, 842.21 examples/s]Map (num_proc=2):  73%|███████▎  | 7666/10500 [00:08<00:03, 873.58 examples/s]Map (num_proc=2):  74%|███████▍  | 7758/10500 [00:08<00:03, 884.35 examples/s]Map (num_proc=2):  75%|███████▍  | 7855/10500 [00:09<00:02, 903.69 examples/s]Map (num_proc=2):  76%|███████▌  | 7951/10500 [00:09<00:02, 913.84 examples/s]Map (num_proc=2):  77%|███████▋  | 8044/10500 [00:09<00:03, 807.63 examples/s]Map (num_proc=2):  77%|███████▋  | 8136/10500 [00:09<00:02, 833.81 examples/s]Map (num_proc=2):  78%|███████▊  | 8232/10500 [00:09<00:02, 855.85 examples/s]Map (num_proc=2):  79%|███████▉  | 8332/10500 [00:09<00:02, 890.21 examples/s]Map (num_proc=2):  80%|████████  | 8435/10500 [00:09<00:02, 911.40 examples/s]Map (num_proc=2):  81%|████████  | 8529/10500 [00:09<00:02, 918.78 examples/s]Map (num_proc=2):  82%|████████▏ | 8632/10500 [00:09<00:01, 943.05 examples/s]Map (num_proc=2):  83%|████████▎ | 8741/10500 [00:10<00:01, 894.01 examples/s]Map (num_proc=2):  84%|████████▍ | 8845/10500 [00:10<00:01, 923.13 examples/s]Map (num_proc=2):  85%|████████▌ | 8944/10500 [00:10<00:01, 938.95 examples/s]Map (num_proc=2):  86%|████████▌ | 9042/10500 [00:10<00:01, 939.26 examples/s]Map (num_proc=2):  87%|████████▋ | 9160/10500 [00:10<00:01, 907.35 examples/s]Map (num_proc=2):  88%|████████▊ | 9265/10500 [00:10<00:01, 939.03 examples/s]Map (num_proc=2):  89%|████████▉ | 9362/10500 [00:10<00:01, 937.01 examples/s]Map (num_proc=2):  90%|█████████ | 9480/10500 [00:10<00:01, 965.37 examples/s]Map (num_proc=2):  91%|█████████ | 9579/10500 [00:10<00:00, 967.07 examples/s]Map (num_proc=2):  92%|█████████▏| 9679/10500 [00:11<00:00, 877.98 examples/s]Map (num_proc=2):  93%|█████████▎| 9779/10500 [00:11<00:00, 905.59 examples/s]Map (num_proc=2):  94%|█████████▍| 9876/10500 [00:11<00:00, 905.55 examples/s]Map (num_proc=2):  95%|█████████▍| 9974/10500 [00:11<00:00, 883.63 examples/s]Map (num_proc=2):  96%|█████████▌| 10068/10500 [00:11<00:00, 850.12 examples/s]Map (num_proc=2):  97%|█████████▋| 10166/10500 [00:11<00:00, 876.77 examples/s]Map (num_proc=2):  98%|█████████▊| 10278/10500 [00:11<00:00, 821.22 examples/s]Map (num_proc=2):  99%|█████████▉| 10374/10500 [00:11<00:00, 852.45 examples/s]Map (num_proc=2): 100%|█████████▉| 10470/10500 [00:11<00:00, 866.40 examples/s]Map (num_proc=2): 100%|██████████| 10500/10500 [00:12<00:00, 833.52 examples/s]
Filter (num_proc=2):   0%|          | 0/10500 [00:00<?, ? examples/s]Filter (num_proc=2):  10%|▉         | 1000/10500 [00:00<00:04, 1927.75 examples/s]Filter (num_proc=2):  29%|██▊       | 3000/10500 [00:00<00:01, 4795.03 examples/s]Filter (num_proc=2):  48%|████▊     | 5000/10500 [00:00<00:00, 6609.87 examples/s]Filter (num_proc=2):  67%|██████▋   | 7000/10500 [00:01<00:00, 7803.27 examples/s]Filter (num_proc=2):  86%|████████▌ | 9000/10500 [00:01<00:00, 8561.08 examples/s]Filter (num_proc=2): 100%|██████████| 10500/10500 [00:01<00:00, 5551.89 examples/s]
Map (num_proc=2):   0%|          | 0/802 [00:00<?, ? examples/s]Map (num_proc=2):   3%|▎         | 25/802 [00:00<00:13, 59.52 examples/s]Map (num_proc=2):  12%|█▏        | 99/802 [00:00<00:03, 231.88 examples/s]Map (num_proc=2):  24%|██▎       | 190/802 [00:00<00:01, 410.68 examples/s]Map (num_proc=2):  35%|███▌      | 283/802 [00:00<00:00, 549.98 examples/s]Map (num_proc=2):  47%|████▋     | 376/802 [00:00<00:00, 647.83 examples/s]Map (num_proc=2):  59%|█████▊    | 471/802 [00:00<00:00, 731.68 examples/s]Map (num_proc=2):  71%|███████▏  | 573/802 [00:01<00:00, 779.71 examples/s]Map (num_proc=2):  83%|████████▎ | 668/802 [00:01<00:00, 740.59 examples/s]Map (num_proc=2):  94%|█████████▍| 754/802 [00:01<00:00, 746.34 examples/s]Map (num_proc=2): 100%|██████████| 802/802 [00:01<00:00, 416.35 examples/s]
Filter (num_proc=2):   0%|          | 0/802 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 401/802 [00:00<00:00, 998.29 examples/s]Filter (num_proc=2): 100%|██████████| 802/802 [00:01<00:00, 735.84 examples/s]
Map (num_proc=2):   0%|          | 0/240 [00:00<?, ? examples/s]Map (num_proc=2):  11%|█         | 26/240 [00:00<00:03, 58.62 examples/s]Map (num_proc=2):  57%|█████▊    | 138/240 [00:00<00:00, 316.10 examples/s]Map (num_proc=2): 100%|██████████| 240/240 [00:01<00:00, 181.82 examples/s]
Filter (num_proc=2):   0%|          | 0/240 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 120/240 [00:00<00:00, 285.59 examples/s]Filter (num_proc=2): 100%|██████████| 240/240 [00:00<00:00, 258.23 examples/s]
Map (num_proc=2):   0%|          | 0/10500 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/10500 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/10500 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 24/10500 [00:00<00:59, 176.40 examples/s]Map (num_proc=2):   0%|          | 22/10500 [00:00<01:06, 158.54 examples/s]Map (num_proc=2):   0%|          | 24/10500 [00:00<01:03, 165.69 examples/s]Map (num_proc=2):   1%|          | 106/10500 [00:00<00:20, 497.77 examples/s]Map (num_proc=2):   1%|▏         | 132/10500 [00:00<00:17, 607.46 examples/s]Map (num_proc=2):   1%|          | 110/10500 [00:00<00:20, 506.61 examples/s]Map (num_proc=2):   2%|▏         | 198/10500 [00:00<00:15, 666.89 examples/s]Map (num_proc=2):   2%|▏         | 228/10500 [00:00<00:13, 740.36 examples/s]Map (num_proc=2):   2%|▏         | 205/10500 [00:00<00:14, 687.28 examples/s]Map (num_proc=2):   3%|▎         | 293/10500 [00:00<00:13, 760.85 examples/s]Map (num_proc=2):   3%|▎         | 325/10500 [00:00<00:12, 815.92 examples/s]Map (num_proc=2):   3%|▎         | 301/10500 [00:00<00:13, 780.30 examples/s]Map (num_proc=2):   4%|▎         | 390/10500 [00:00<00:12, 824.27 examples/s]Map (num_proc=2):   4%|▍         | 422/10500 [00:00<00:11, 861.12 examples/s]Map (num_proc=2):   4%|▍         | 402/10500 [00:00<00:11, 846.79 examples/s]Map (num_proc=2):   5%|▍         | 514/10500 [00:00<00:11, 876.03 examples/s]Map (num_proc=2):   5%|▍         | 484/10500 [00:00<00:11, 855.33 examples/s]Map (num_proc=2):   5%|▍         | 490/10500 [00:00<00:11, 850.66 examples/s]Map (num_proc=2):   6%|▌         | 615/10500 [00:00<00:10, 910.73 examples/s]Map (num_proc=2):   5%|▌         | 577/10500 [00:00<00:11, 872.09 examples/s]Map (num_proc=2):   6%|▌         | 586/10500 [00:00<00:11, 881.85 examples/s]Map (num_proc=2):   6%|▋         | 671/10500 [00:00<00:11, 886.65 examples/s]Map (num_proc=2):   7%|▋         | 684/10500 [00:00<00:10, 909.28 examples/s]Map (num_proc=2):   7%|▋         | 730/10500 [00:00<00:11, 871.87 examples/s]Map (num_proc=2):   7%|▋         | 779/10500 [00:00<00:10, 916.17 examples/s]Map (num_proc=2):   7%|▋         | 776/10500 [00:00<00:10, 905.34 examples/s]Map (num_proc=2):   8%|▊         | 822/10500 [00:01<00:10, 880.12 examples/s]Map (num_proc=2):   8%|▊         | 874/10500 [00:01<00:10, 918.17 examples/s]Map (num_proc=2):   9%|▉         | 922/10500 [00:01<00:10, 909.96 examples/s]Map (num_proc=2):   9%|▊         | 893/10500 [00:01<00:10, 948.19 examples/s]Map (num_proc=2):   9%|▉         | 970/10500 [00:01<00:10, 922.98 examples/s]Map (num_proc=2):  10%|▉         | 1019/10500 [00:01<00:10, 922.35 examples/s]Map (num_proc=2):   9%|▉         | 992/10500 [00:01<00:09, 954.88 examples/s]Map (num_proc=2):  10%|█         | 1068/10500 [00:01<00:10, 931.50 examples/s]Map (num_proc=2):  11%|█         | 1117/10500 [00:01<00:10, 932.54 examples/s]Map (num_proc=2):  10%|█         | 1091/10500 [00:01<00:09, 959.58 examples/s]Map (num_proc=2):  11%|█         | 1170/10500 [00:01<00:09, 954.14 examples/s]Map (num_proc=2):  12%|█▏        | 1223/10500 [00:01<00:09, 967.00 examples/s]Map (num_proc=2):  11%|█▏        | 1194/10500 [00:01<00:09, 971.10 examples/s]Map (num_proc=2):  12%|█▏        | 1272/10500 [00:01<00:09, 959.67 examples/s]Map (num_proc=2):  13%|█▎        | 1330/10500 [00:01<00:09, 987.52 examples/s]Map (num_proc=2):  12%|█▏        | 1299/10500 [00:01<00:09, 992.75 examples/s]Map (num_proc=2):  13%|█▎        | 1369/10500 [00:01<00:09, 948.55 examples/s]Map (num_proc=2):  13%|█▎        | 1399/10500 [00:01<00:09, 987.85 examples/s]Map (num_proc=2):  14%|█▍        | 1452/10500 [00:01<00:09, 967.47 examples/s]Map (num_proc=2):  14%|█▍        | 1468/10500 [00:01<00:09, 955.89 examples/s]Map (num_proc=2):  15%|█▍        | 1555/10500 [00:01<00:09, 970.13 examples/s]Map (num_proc=2):  14%|█▍        | 1519/10500 [00:01<00:09, 938.46 examples/s]Map (num_proc=2):  15%|█▍        | 1567/10500 [00:01<00:09, 948.06 examples/s]Map (num_proc=2):  16%|█▌        | 1654/10500 [00:01<00:09, 968.32 examples/s]Map (num_proc=2):  15%|█▌        | 1615/10500 [00:01<00:09, 940.70 examples/s]Map (num_proc=2):  16%|█▌        | 1663/10500 [00:01<00:09, 947.67 examples/s]Map (num_proc=2):  17%|█▋        | 1758/10500 [00:01<00:08, 978.96 examples/s]Map (num_proc=2):  16%|█▋        | 1712/10500 [00:01<00:09, 946.64 examples/s]Map (num_proc=2):  17%|█▋        | 1763/10500 [00:02<00:09, 953.38 examples/s]Map (num_proc=2):  17%|█▋        | 1813/10500 [00:02<00:09, 961.50 examples/s]Map (num_proc=2):  18%|█▊        | 1883/10500 [00:02<00:08, 1001.67 examples/s]Map (num_proc=2):  18%|█▊        | 1864/10500 [00:02<00:08, 966.83 examples/s]Map (num_proc=2):  18%|█▊        | 1915/10500 [00:02<00:08, 971.26 examples/s]Map (num_proc=2):  19%|█▊        | 1964/10500 [00:02<00:08, 975.44 examples/s]Map (num_proc=2):  19%|█▉        | 1998/10500 [00:02<00:10, 832.53 examples/s] Map (num_proc=2):  19%|█▉        | 2022/10500 [00:02<00:10, 839.86 examples/s]Map (num_proc=2):  20%|█▉        | 2091/10500 [00:02<00:09, 845.30 examples/s]Map (num_proc=2):  20%|█▉        | 2067/10500 [00:02<00:10, 802.21 examples/s]Map (num_proc=2):  20%|██        | 2137/10500 [00:02<00:09, 839.95 examples/s]Map (num_proc=2):  21%|██        | 2199/10500 [00:02<00:09, 894.10 examples/s]Map (num_proc=2):  21%|██        | 2156/10500 [00:02<00:10, 820.49 examples/s]Map (num_proc=2):  22%|██▏       | 2304/10500 [00:02<00:08, 928.46 examples/s]Map (num_proc=2):  21%|██▏       | 2245/10500 [00:02<00:09, 859.16 examples/s]Map (num_proc=2):  21%|██▏       | 2249/10500 [00:02<00:09, 838.04 examples/s]Map (num_proc=2):  23%|██▎       | 2406/10500 [00:02<00:08, 947.15 examples/s]Map (num_proc=2):  22%|██▏       | 2353/10500 [00:02<00:08, 912.10 examples/s]Map (num_proc=2):  22%|██▏       | 2347/10500 [00:02<00:09, 869.98 examples/s]Map (num_proc=2):  23%|██▎       | 2448/10500 [00:02<00:08, 915.36 examples/s]Map (num_proc=2):  23%|██▎       | 2441/10500 [00:02<00:09, 882.31 examples/s]Map (num_proc=2):  24%|██▍       | 2526/10500 [00:02<00:08, 890.81 examples/s]Map (num_proc=2):  24%|██▍       | 2551/10500 [00:02<00:08, 938.51 examples/s]Map (num_proc=2):  24%|██▍       | 2531/10500 [00:02<00:09, 883.37 examples/s]Map (num_proc=2):  25%|██▌       | 2628/10500 [00:02<00:08, 922.37 examples/s]Map (num_proc=2):  25%|██▌       | 2649/10500 [00:02<00:08, 943.79 examples/s]Map (num_proc=2):  25%|██▌       | 2625/10500 [00:02<00:08, 896.14 examples/s]Map (num_proc=2):  26%|██▌       | 2729/10500 [00:03<00:08, 938.58 examples/s]Map (num_proc=2):  26%|██▌       | 2752/10500 [00:03<00:08, 964.79 examples/s]Map (num_proc=2):  26%|██▌       | 2730/10500 [00:03<00:08, 930.10 examples/s]Map (num_proc=2):  27%|██▋       | 2830/10500 [00:03<00:08, 953.70 examples/s]Map (num_proc=2):  27%|██▋       | 2831/10500 [00:03<00:08, 932.54 examples/s]Map (num_proc=2):  27%|██▋       | 2873/10500 [00:03<00:08, 936.86 examples/s]Map (num_proc=2):  28%|██▊       | 2944/10500 [00:03<00:07, 972.30 examples/s]Map (num_proc=2):  28%|██▊       | 2929/10500 [00:03<00:08, 936.19 examples/s]Map (num_proc=2):  28%|██▊       | 2975/10500 [00:03<00:07, 952.79 examples/s]Map (num_proc=2):  29%|██▉       | 3049/10500 [00:03<00:07, 989.13 examples/s]Map (num_proc=2):  29%|██▉       | 3030/10500 [00:03<00:07, 945.02 examples/s]Map (num_proc=2):  29%|██▉       | 3077/10500 [00:03<00:07, 964.33 examples/s]Map (num_proc=2):  30%|███       | 3150/10500 [00:03<00:07, 986.94 examples/s]Map (num_proc=2):  30%|██▉       | 3127/10500 [00:03<00:07, 949.19 examples/s]Map (num_proc=2):  30%|███       | 3179/10500 [00:03<00:07, 974.84 examples/s]Map (num_proc=2):  31%|███       | 3269/10500 [00:03<00:07, 934.99 examples/s]Map (num_proc=2):  31%|███       | 3223/10500 [00:03<00:07, 949.72 examples/s]Map (num_proc=2):  31%|███▏      | 3297/10500 [00:03<00:07, 978.27 examples/s]Map (num_proc=2):  32%|███▏      | 3370/10500 [00:03<00:07, 948.67 examples/s]Map (num_proc=2):  32%|███▏      | 3341/10500 [00:03<00:07, 928.01 examples/s]Map (num_proc=2):  32%|███▏      | 3396/10500 [00:03<00:07, 978.36 examples/s]Map (num_proc=2):  33%|███▎      | 3490/10500 [00:03<00:07, 979.02 examples/s]Map (num_proc=2):  33%|███▎      | 3437/10500 [00:03<00:07, 927.09 examples/s]Map (num_proc=2):  33%|███▎      | 3515/10500 [00:03<00:07, 940.91 examples/s]Map (num_proc=2):  34%|███▍      | 3591/10500 [00:03<00:07, 982.37 examples/s]Map (num_proc=2):  34%|███▎      | 3535/10500 [00:03<00:07, 934.43 examples/s]Map (num_proc=2):  34%|███▍      | 3616/10500 [00:03<00:07, 951.77 examples/s]Map (num_proc=2):  35%|███▌      | 3695/10500 [00:04<00:06, 995.83 examples/s]Map (num_proc=2):  35%|███▍      | 3635/10500 [00:04<00:07, 947.47 examples/s]Map (num_proc=2):  35%|███▌      | 3714/10500 [00:04<00:07, 955.62 examples/s]Map (num_proc=2):  36%|███▌      | 3796/10500 [00:04<00:06, 989.48 examples/s]Map (num_proc=2):  36%|███▌      | 3735/10500 [00:04<00:07, 953.79 examples/s]Map (num_proc=2):  36%|███▋      | 3814/10500 [00:04<00:06, 960.06 examples/s]Map (num_proc=2):  37%|███▋      | 3915/10500 [00:04<00:06, 941.02 examples/s]Map (num_proc=2):  37%|███▋      | 3851/10500 [00:04<00:06, 957.87 examples/s]Map (num_proc=2):  37%|███▋      | 3932/10500 [00:04<00:06, 982.76 examples/s]Map (num_proc=2):  38%|███▊      | 4022/10500 [00:04<00:07, 855.34 examples/s]Map (num_proc=2):  38%|███▊      | 3963/10500 [00:04<00:07, 868.87 examples/s]Map (num_proc=2):  39%|███▊      | 4043/10500 [00:04<00:07, 841.91 examples/s]Map (num_proc=2):  39%|███▉      | 4112/10500 [00:04<00:07, 861.55 examples/s]Map (num_proc=2):  39%|███▊      | 4058/10500 [00:04<00:07, 832.77 examples/s]Map (num_proc=2):  39%|███▉      | 4139/10500 [00:04<00:07, 863.76 examples/s]Map (num_proc=2):  40%|████      | 4211/10500 [00:04<00:07, 893.84 examples/s]Map (num_proc=2):  40%|███▉      | 4162/10500 [00:04<00:07, 831.84 examples/s]Map (num_proc=2):  40%|████      | 4239/10500 [00:04<00:06, 896.16 examples/s]Map (num_proc=2):  41%|████      | 4318/10500 [00:04<00:06, 934.72 examples/s]Map (num_proc=2):  41%|████      | 4264/10500 [00:04<00:07, 877.07 examples/s]Map (num_proc=2):  41%|████▏     | 4343/10500 [00:04<00:06, 930.42 examples/s]Map (num_proc=2):  42%|████▏     | 4418/10500 [00:04<00:06, 947.90 examples/s]Map (num_proc=2):  42%|████▏     | 4368/10500 [00:04<00:06, 912.95 examples/s]Map (num_proc=2):  42%|████▏     | 4440/10500 [00:04<00:06, 935.64 examples/s]Map (num_proc=2):  43%|████▎     | 4515/10500 [00:04<00:06, 944.78 examples/s]Map (num_proc=2):  43%|████▎     | 4466/10500 [00:04<00:06, 928.44 examples/s]Map (num_proc=2):  43%|████▎     | 4537/10500 [00:04<00:06, 932.58 examples/s]Map (num_proc=2):  44%|████▍     | 4612/10500 [00:05<00:06, 946.10 examples/s]Map (num_proc=2):  43%|████▎     | 4560/10500 [00:05<00:06, 923.24 examples/s]Map (num_proc=2):  44%|████▍     | 4656/10500 [00:05<00:06, 892.16 examples/s]Map (num_proc=2):  45%|████▌     | 4732/10500 [00:05<00:06, 893.41 examples/s]Map (num_proc=2):  44%|████▍     | 4656/10500 [00:05<00:06, 931.82 examples/s]Map (num_proc=2):  45%|████▌     | 4751/10500 [00:05<00:06, 903.20 examples/s]Map (num_proc=2):  46%|████▌     | 4825/10500 [00:05<00:06, 899.45 examples/s]Map (num_proc=2):  45%|████▌     | 4765/10500 [00:05<00:06, 884.44 examples/s]Map (num_proc=2):  46%|████▌     | 4847/10500 [00:05<00:06, 912.78 examples/s]Map (num_proc=2):  47%|████▋     | 4922/10500 [00:05<00:06, 904.10 examples/s]Map (num_proc=2):  46%|████▋     | 4857/10500 [00:05<00:06, 886.22 examples/s]Map (num_proc=2):  47%|████▋     | 4946/10500 [00:05<00:05, 927.72 examples/s]Map (num_proc=2):  48%|████▊     | 5020/10500 [00:05<00:05, 919.94 examples/s]Map (num_proc=2):  47%|████▋     | 4953/10500 [00:05<00:06, 900.45 examples/s]Map (num_proc=2):  48%|████▊     | 5055/10500 [00:05<00:05, 932.83 examples/s]Map (num_proc=2):  49%|████▉     | 5129/10500 [00:05<00:05, 952.78 examples/s]Map (num_proc=2):  48%|████▊     | 5054/10500 [00:05<00:05, 923.77 examples/s]Map (num_proc=2):  49%|████▉     | 5155/10500 [00:05<00:05, 949.29 examples/s]Map (num_proc=2):  50%|████▉     | 5230/10500 [00:05<00:05, 962.97 examples/s]Map (num_proc=2):  49%|████▉     | 5152/10500 [00:05<00:05, 932.98 examples/s]Map (num_proc=2):  50%|█████     | 5258/10500 [00:05<00:05, 962.57 examples/s]Map (num_proc=2):  51%|█████     | 5330/10500 [00:05<00:05, 967.66 examples/s]Map (num_proc=2):  50%|█████     | 5260/10500 [00:05<00:05, 926.60 examples/s]Map (num_proc=2):  52%|█████▏    | 5436/10500 [00:05<00:05, 973.07 examples/s]Map (num_proc=2):  51%|█████     | 5375/10500 [00:05<00:05, 913.89 examples/s]Map (num_proc=2):  51%|█████     | 5359/10500 [00:05<00:05, 936.12 examples/s]Map (num_proc=2):  53%|█████▎    | 5537/10500 [00:06<00:05, 974.46 examples/s]Map (num_proc=2):  52%|█████▏    | 5471/10500 [00:05<00:05, 922.86 examples/s]Map (num_proc=2):  52%|█████▏    | 5460/10500 [00:06<00:05, 951.02 examples/s]Map (num_proc=2):  53%|█████▎    | 5568/10500 [00:06<00:05, 931.71 examples/s]Map (num_proc=2):  54%|█████▍    | 5655/10500 [00:06<00:05, 905.73 examples/s]Map (num_proc=2):  53%|█████▎    | 5580/10500 [00:06<00:05, 930.96 examples/s]Map (num_proc=2):  54%|█████▍    | 5668/10500 [00:06<00:05, 946.62 examples/s]Map (num_proc=2):  55%|█████▍    | 5759/10500 [00:06<00:05, 935.81 examples/s]Map (num_proc=2):  54%|█████▍    | 5676/10500 [00:06<00:05, 936.96 examples/s]Map (num_proc=2):  55%|█████▍    | 5771/10500 [00:06<00:04, 960.87 examples/s]Map (num_proc=2):  56%|█████▌    | 5859/10500 [00:06<00:04, 945.71 examples/s]Map (num_proc=2):  55%|█████▌    | 5794/10500 [00:06<00:04, 951.27 examples/s]Map (num_proc=2):  56%|█████▌    | 5871/10500 [00:06<00:04, 958.89 examples/s]Map (num_proc=2):  57%|█████▋    | 5960/10500 [00:06<00:04, 959.03 examples/s]Map (num_proc=2):  57%|█████▋    | 5970/10500 [00:06<00:04, 965.07 examples/s]Map (num_proc=2):  56%|█████▌    | 5898/10500 [00:06<00:05, 854.63 examples/s]Map (num_proc=2):  58%|█████▊    | 6070/10500 [00:06<00:05, 853.52 examples/s]Map (num_proc=2):  58%|█████▊    | 6072/10500 [00:06<00:05, 862.05 examples/s]Map (num_proc=2):  57%|█████▋    | 5992/10500 [00:06<00:05, 863.10 examples/s]Map (num_proc=2):  59%|█████▉    | 6169/10500 [00:06<00:04, 886.64 examples/s]Map (num_proc=2):  59%|█████▊    | 6168/10500 [00:06<00:04, 886.88 examples/s]Map (num_proc=2):  58%|█████▊    | 6084/10500 [00:06<00:05, 876.11 examples/s]Map (num_proc=2):  60%|█████▉    | 6267/10500 [00:06<00:04, 908.76 examples/s]Map (num_proc=2):  60%|█████▉    | 6268/10500 [00:06<00:04, 906.26 examples/s]Map (num_proc=2):  59%|█████▉    | 6173/10500 [00:06<00:05, 859.40 examples/s]Map (num_proc=2):  61%|██████    | 6370/10500 [00:06<00:04, 933.88 examples/s]Map (num_proc=2):  61%|██████    | 6364/10500 [00:06<00:04, 920.79 examples/s]Map (num_proc=2):  60%|█████▉    | 6270/10500 [00:06<00:04, 883.46 examples/s]Map (num_proc=2):  62%|██████▏   | 6465/10500 [00:07<00:04, 935.31 examples/s]Map (num_proc=2):  62%|██████▏   | 6466/10500 [00:07<00:04, 945.72 examples/s]Map (num_proc=2):  61%|██████    | 6363/10500 [00:07<00:04, 891.17 examples/s]Map (num_proc=2):  63%|██████▎   | 6567/10500 [00:07<00:04, 951.50 examples/s]Map (num_proc=2):  62%|██████▏   | 6562/10500 [00:07<00:04, 942.81 examples/s]Map (num_proc=2):  62%|██████▏   | 6462/10500 [00:07<00:04, 909.40 examples/s]Map (num_proc=2):  63%|██████▎   | 6667/10500 [00:07<00:04, 954.82 examples/s]Map (num_proc=2):  63%|██████▎   | 6659/10500 [00:07<00:04, 938.66 examples/s]Map (num_proc=2):  62%|██████▏   | 6562/10500 [00:07<00:04, 928.17 examples/s]Map (num_proc=2):  64%|██████▍   | 6764/10500 [00:07<00:03, 946.91 examples/s]Map (num_proc=2):  64%|██████▍   | 6759/10500 [00:07<00:03, 945.60 examples/s]Map (num_proc=2):  63%|██████▎   | 6667/10500 [00:07<00:04, 958.12 examples/s]Map (num_proc=2):  65%|██████▌   | 6869/10500 [00:07<00:03, 974.15 examples/s]Map (num_proc=2):  65%|██████▌   | 6862/10500 [00:07<00:03, 969.25 examples/s]Map (num_proc=2):  66%|██████▋   | 6968/10500 [00:07<00:03, 965.60 examples/s]Map (num_proc=2):  65%|██████▍   | 6783/10500 [00:07<00:04, 907.00 examples/s]Map (num_proc=2):  66%|██████▋   | 6962/10500 [00:07<00:03, 970.98 examples/s]Map (num_proc=2):  67%|██████▋   | 7066/10500 [00:07<00:03, 960.07 examples/s]Map (num_proc=2):  65%|██████▌   | 6876/10500 [00:07<00:04, 902.23 examples/s]Map (num_proc=2):  67%|██████▋   | 7077/10500 [00:07<00:03, 888.67 examples/s]Map (num_proc=2):  66%|██████▋   | 6975/10500 [00:07<00:03, 915.68 examples/s]Map (num_proc=2):  68%|██████▊   | 7192/10500 [00:07<00:03, 943.19 examples/s]Map (num_proc=2):  68%|██████▊   | 7180/10500 [00:07<00:03, 920.62 examples/s]Map (num_proc=2):  67%|██████▋   | 7085/10500 [00:07<00:03, 938.87 examples/s]Map (num_proc=2):  69%|██████▉   | 7288/10500 [00:07<00:03, 943.34 examples/s]Map (num_proc=2):  69%|██████▉   | 7278/10500 [00:07<00:03, 923.57 examples/s]Map (num_proc=2):  68%|██████▊   | 7184/10500 [00:07<00:03, 946.58 examples/s]Map (num_proc=2):  71%|███████   | 7405/10500 [00:08<00:03, 902.74 examples/s]Map (num_proc=2):  69%|██████▉   | 7280/10500 [00:08<00:03, 944.99 examples/s]Map (num_proc=2):  70%|███████   | 7392/10500 [00:08<00:03, 875.21 examples/s]Map (num_proc=2):  71%|███████▏  | 7499/10500 [00:08<00:03, 909.81 examples/s]Map (num_proc=2):  70%|███████   | 7388/10500 [00:08<00:03, 981.82 examples/s]Map (num_proc=2):  71%|███████▏  | 7490/10500 [00:08<00:03, 896.16 examples/s]Map (num_proc=2):  72%|███████▏  | 7592/10500 [00:08<00:03, 911.94 examples/s]Map (num_proc=2):  72%|███████▏  | 7589/10500 [00:08<00:03, 917.33 examples/s]Map (num_proc=2):  72%|███████▏  | 7510/10500 [00:08<00:03, 911.92 examples/s]Map (num_proc=2):  73%|███████▎  | 7687/10500 [00:08<00:03, 911.60 examples/s]Map (num_proc=2):  73%|███████▎  | 7686/10500 [00:08<00:03, 922.46 examples/s]Map (num_proc=2):  74%|███████▍  | 7779/10500 [00:08<00:02, 909.78 examples/s]Map (num_proc=2):  73%|███████▎  | 7619/10500 [00:08<00:03, 839.76 examples/s]Map (num_proc=2):  74%|███████▍  | 7781/10500 [00:08<00:02, 926.03 examples/s]Map (num_proc=2):  75%|███████▌  | 7878/10500 [00:08<00:02, 922.80 examples/s]Map (num_proc=2):  73%|███████▎  | 7711/10500 [00:08<00:03, 855.71 examples/s]Map (num_proc=2):  75%|███████▌  | 7883/10500 [00:08<00:02, 942.83 examples/s]Map (num_proc=2):  76%|███████▌  | 7981/10500 [00:08<00:02, 883.96 examples/s]Map (num_proc=2):  74%|███████▍  | 7801/10500 [00:08<00:03, 857.06 examples/s]Map (num_proc=2):  76%|███████▌  | 7982/10500 [00:08<00:02, 918.13 examples/s]Map (num_proc=2):  77%|███████▋  | 8083/10500 [00:08<00:02, 806.76 examples/s]Map (num_proc=2):  75%|███████▌  | 7906/10500 [00:08<00:03, 813.63 examples/s]Map (num_proc=2):  77%|███████▋  | 8089/10500 [00:08<00:02, 815.32 examples/s]Map (num_proc=2):  78%|███████▊  | 8180/10500 [00:08<00:02, 846.04 examples/s]Map (num_proc=2):  76%|███████▌  | 8003/10500 [00:08<00:02, 848.67 examples/s]Map (num_proc=2):  78%|███████▊  | 8191/10500 [00:08<00:02, 860.78 examples/s]Map (num_proc=2):  79%|███████▉  | 8281/10500 [00:09<00:02, 887.93 examples/s]Map (num_proc=2):  77%|███████▋  | 8105/10500 [00:09<00:02, 885.20 examples/s]Map (num_proc=2):  79%|███████▉  | 8283/10500 [00:09<00:02, 866.90 examples/s]Map (num_proc=2):  80%|███████▉  | 8381/10500 [00:09<00:02, 896.97 examples/s]Map (num_proc=2):  78%|███████▊  | 8205/10500 [00:09<00:02, 912.28 examples/s]Map (num_proc=2):  80%|███████▉  | 8387/10500 [00:09<00:02, 909.85 examples/s]Map (num_proc=2):  81%|████████  | 8486/10500 [00:09<00:02, 935.42 examples/s]Map (num_proc=2):  79%|███████▉  | 8311/10500 [00:09<00:02, 858.67 examples/s]Map (num_proc=2):  81%|████████  | 8486/10500 [00:09<00:02, 920.60 examples/s]Map (num_proc=2):  82%|████████▏ | 8586/10500 [00:09<00:02, 950.96 examples/s]Map (num_proc=2):  80%|████████  | 8410/10500 [00:09<00:02, 889.42 examples/s]Map (num_proc=2):  82%|████████▏ | 8588/10500 [00:09<00:02, 943.29 examples/s]Map (num_proc=2):  83%|████████▎ | 8685/10500 [00:09<00:01, 959.74 examples/s]Map (num_proc=2):  81%|████████  | 8504/10500 [00:09<00:02, 902.06 examples/s]Map (num_proc=2):  83%|████████▎ | 8703/10500 [00:09<00:01, 961.68 examples/s]Map (num_proc=2):  84%|████████▍ | 8808/10500 [00:09<00:01, 970.56 examples/s]Map (num_proc=2):  82%|████████▏ | 8600/10500 [00:09<00:02, 909.06 examples/s]Map (num_proc=2):  84%|████████▍ | 8803/10500 [00:09<00:01, 963.96 examples/s]Map (num_proc=2):  85%|████████▍ | 8910/10500 [00:09<00:01, 977.62 examples/s]Map (num_proc=2):  83%|████████▎ | 8714/10500 [00:09<00:01, 918.98 examples/s]Map (num_proc=2):  85%|████████▍ | 8907/10500 [00:09<00:01, 982.02 examples/s]Map (num_proc=2):  86%|████████▌ | 9029/10500 [00:09<00:01, 953.59 examples/s]Map (num_proc=2):  84%|████████▍ | 8811/10500 [00:09<00:01, 929.91 examples/s]Map (num_proc=2):  86%|████████▌ | 9026/10500 [00:09<00:01, 937.66 examples/s]Map (num_proc=2):  87%|████████▋ | 9129/10500 [00:09<00:01, 962.04 examples/s]Map (num_proc=2):  85%|████████▍ | 8905/10500 [00:09<00:01, 927.01 examples/s]Map (num_proc=2):  87%|████████▋ | 9122/10500 [00:09<00:01, 938.19 examples/s]Map (num_proc=2):  88%|████████▊ | 9235/10500 [00:09<00:01, 988.21 examples/s]Map (num_proc=2):  86%|████████▌ | 9002/10500 [00:10<00:01, 928.79 examples/s]Map (num_proc=2):  88%|████████▊ | 9225/10500 [00:10<00:01, 954.87 examples/s]Map (num_proc=2):  89%|████████▉ | 9353/10500 [00:10<00:01, 969.41 examples/s]Map (num_proc=2):  87%|████████▋ | 9103/10500 [00:10<00:01, 945.36 examples/s]Map (num_proc=2):  89%|████████▉ | 9325/10500 [00:10<00:01, 962.30 examples/s]Map (num_proc=2):  88%|████████▊ | 9205/10500 [00:10<00:01, 945.83 examples/s]Map (num_proc=2):  90%|█████████ | 9474/10500 [00:10<00:01, 958.69 examples/s]Map (num_proc=2):  90%|████████▉ | 9426/10500 [00:10<00:01, 960.86 examples/s]Map (num_proc=2):  89%|████████▊ | 9302/10500 [00:10<00:01, 948.23 examples/s]Map (num_proc=2):  91%|█████████ | 9574/10500 [00:10<00:00, 962.65 examples/s]Map (num_proc=2):  91%|█████████ | 9547/10500 [00:10<00:00, 1004.16 examples/s]Map (num_proc=2):  90%|████████▉ | 9398/10500 [00:10<00:01, 947.69 examples/s]Map (num_proc=2):  92%|█████████▏| 9673/10500 [00:10<00:00, 944.49 examples/s]Map (num_proc=2):  90%|█████████ | 9502/10500 [00:10<00:01, 953.70 examples/s]Map (num_proc=2):  92%|█████████▏| 9665/10500 [00:10<00:00, 926.51 examples/s] Map (num_proc=2):  93%|█████████▎| 9774/10500 [00:10<00:00, 955.98 examples/s]Map (num_proc=2):  91%|█████████▏| 9599/10500 [00:10<00:00, 941.39 examples/s]Map (num_proc=2):  93%|█████████▎| 9765/10500 [00:10<00:00, 944.91 examples/s]Map (num_proc=2):  94%|█████████▍| 9872/10500 [00:10<00:00, 944.16 examples/s]Map (num_proc=2):  94%|█████████▍| 9866/10500 [00:10<00:00, 954.08 examples/s]Map (num_proc=2):  92%|█████████▏| 9711/10500 [00:10<00:00, 938.67 examples/s]Map (num_proc=2):  95%|█████████▍| 9972/10500 [00:10<00:00, 930.26 examples/s]Map (num_proc=2):  95%|█████████▍| 9963/10500 [00:10<00:00, 950.99 examples/s]Map (num_proc=2):  96%|█████████▌| 10068/10500 [00:10<00:00, 861.47 examples/s]Map (num_proc=2):  94%|█████████▎| 9824/10500 [00:10<00:00, 855.08 examples/s]Map (num_proc=2):  97%|█████████▋| 10166/10500 [00:11<00:00, 886.37 examples/s]Map (num_proc=2):  96%|█████████▌| 10070/10500 [00:10<00:00, 837.93 examples/s]Map (num_proc=2):  94%|█████████▍| 9914/10500 [00:11<00:00, 864.93 examples/s]Map (num_proc=2):  98%|█████████▊| 10259/10500 [00:11<00:00, 894.03 examples/s]Map (num_proc=2):  97%|█████████▋| 10162/10500 [00:11<00:00, 846.34 examples/s]Map (num_proc=2):  95%|█████████▌| 10010/10500 [00:11<00:00, 886.25 examples/s]Map (num_proc=2):  99%|█████████▊| 10357/10500 [00:11<00:00, 913.80 examples/s]Map (num_proc=2):  98%|█████████▊| 10258/10500 [00:11<00:00, 873.16 examples/s]Map (num_proc=2):  96%|█████████▋| 10109/10500 [00:11<00:00, 898.83 examples/s]Map (num_proc=2): 100%|█████████▉| 10459/10500 [00:11<00:00, 935.99 examples/s]Map (num_proc=2):  99%|█████████▊| 10358/10500 [00:11<00:00, 901.26 examples/s]Map (num_proc=2):  97%|█████████▋| 10204/10500 [00:11<00:00, 906.72 examples/s]Map (num_proc=2): 100%|█████████▉| 10461/10500 [00:11<00:00, 930.25 examples/s]Map (num_proc=2): 100%|██████████| 10500/10500 [00:11<00:00, 911.83 examples/s]
Map (num_proc=2):  98%|█████████▊| 10317/10500 [00:11<00:00, 711.87 examples/s]Map (num_proc=2): 100%|██████████| 10500/10500 [00:11<00:00, 904.54 examples/s]
Filter (num_proc=2):   0%|          | 0/10500 [00:00<?, ? examples/s]Map (num_proc=2):  99%|█████████▉| 10408/10500 [00:11<00:00, 606.97 examples/s]Filter (num_proc=2):   0%|          | 0/10500 [00:00<?, ? examples/s]Map (num_proc=2): 100%|█████████▉| 10480/10500 [00:11<00:00, 566.06 examples/s]Filter (num_proc=2):  10%|▉         | 1000/10500 [00:00<00:02, 3822.87 examples/s]Filter (num_proc=2):  10%|▉         | 1000/10500 [00:00<00:02, 4009.11 examples/s]Map (num_proc=2): 100%|██████████| 10500/10500 [00:12<00:00, 867.02 examples/s]
Filter (num_proc=2):  29%|██▊       | 3000/10500 [00:00<00:01, 6855.59 examples/s]Filter (num_proc=2):  29%|██▊       | 3000/10500 [00:00<00:01, 7190.46 examples/s]Filter (num_proc=2):   0%|          | 0/10500 [00:00<?, ? examples/s]Filter (num_proc=2):  48%|████▊     | 5000/10500 [00:00<00:00, 7995.70 examples/s]Filter (num_proc=2):  48%|████▊     | 5000/10500 [00:00<00:00, 8370.50 examples/s]Filter (num_proc=2):  10%|▉         | 1000/10500 [00:00<00:02, 3760.35 examples/s]Filter (num_proc=2):  67%|██████▋   | 7000/10500 [00:00<00:00, 8616.08 examples/s]Filter (num_proc=2):  67%|██████▋   | 7000/10500 [00:00<00:00, 9056.42 examples/s]Filter (num_proc=2):  29%|██▊       | 3000/10500 [00:00<00:01, 7007.32 examples/s]Filter (num_proc=2):  86%|████████▌ | 9000/10500 [00:01<00:00, 8851.80 examples/s]Filter (num_proc=2):  86%|████████▌ | 9000/10500 [00:01<00:00, 9419.68 examples/s]Filter (num_proc=2):  48%|████▊     | 5000/10500 [00:00<00:00, 8288.47 examples/s]Filter (num_proc=2): 100%|██████████| 10500/10500 [00:01<00:00, 8045.89 examples/s]
Filter (num_proc=2): 100%|██████████| 10500/10500 [00:01<00:00, 7829.88 examples/s]
Filter (num_proc=2):  67%|██████▋   | 7000/10500 [00:00<00:00, 8971.35 examples/s]Filter (num_proc=2):  86%|████████▌ | 9000/10500 [00:01<00:00, 9331.66 examples/s]Filter (num_proc=2): 100%|██████████| 10500/10500 [00:01<00:00, 8387.15 examples/s]
Map (num_proc=2):   0%|          | 0/802 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/802 [00:00<?, ? examples/s]Map (num_proc=2):   3%|▎         | 25/802 [00:00<00:04, 159.45 examples/s]Map (num_proc=2):   3%|▎         | 25/802 [00:00<00:04, 170.58 examples/s]Map (num_proc=2):  14%|█▎        | 109/802 [00:00<00:01, 482.82 examples/s]Map (num_proc=2):  13%|█▎        | 108/802 [00:00<00:01, 495.01 examples/s]Map (num_proc=2):  25%|██▍       | 198/802 [00:00<00:00, 642.69 examples/s]Map (num_proc=2):  25%|██▍       | 198/802 [00:00<00:00, 654.61 examples/s]Map (num_proc=2):  36%|███▌      | 288/802 [00:00<00:00, 732.19 examples/s]Map (num_proc=2):   0%|          | 0/802 [00:00<?, ? examples/s]Map (num_proc=2):  36%|███▌      | 288/802 [00:00<00:00, 739.18 examples/s]Map (num_proc=2):  47%|████▋     | 377/802 [00:00<00:00, 782.77 examples/s]Map (num_proc=2):  47%|████▋     | 377/802 [00:00<00:00, 787.62 examples/s]Map (num_proc=2):   3%|▎         | 25/802 [00:00<00:04, 161.28 examples/s]Map (num_proc=2):  59%|█████▉    | 472/802 [00:00<00:00, 833.52 examples/s]Map (num_proc=2):  13%|█▎        | 105/802 [00:00<00:01, 464.17 examples/s]Map (num_proc=2):  59%|█████▉    | 474/802 [00:00<00:00, 839.43 examples/s]Map (num_proc=2):  70%|██████▉   | 558/802 [00:00<00:00, 836.59 examples/s]Map (num_proc=2):  24%|██▍       | 194/802 [00:00<00:00, 631.74 examples/s]Map (num_proc=2):  70%|███████   | 564/802 [00:00<00:00, 852.23 examples/s]Map (num_proc=2):  81%|████████  | 650/802 [00:00<00:00, 824.71 examples/s]Map (num_proc=2):  35%|███▌      | 283/802 [00:00<00:00, 721.28 examples/s]Map (num_proc=2):  83%|████████▎ | 664/802 [00:00<00:00, 836.27 examples/s]Map (num_proc=2):  93%|█████████▎| 744/802 [00:01<00:00, 744.20 examples/s]Map (num_proc=2):  47%|████▋     | 374/802 [00:00<00:00, 779.63 examples/s]Map (num_proc=2):  94%|█████████▍| 755/802 [00:01<00:00, 737.43 examples/s]Map (num_proc=2):  59%|█████▊    | 470/802 [00:00<00:00, 834.16 examples/s]Map (num_proc=2):  70%|██████▉   | 559/802 [00:00<00:00, 843.95 examples/s]Map (num_proc=2): 100%|██████████| 802/802 [00:01<00:00, 628.35 examples/s]
Map (num_proc=2): 100%|██████████| 802/802 [00:01<00:00, 634.99 examples/s]
Map (num_proc=2):  82%|████████▏ | 658/802 [00:00<00:00, 852.84 examples/s]Filter (num_proc=2):   0%|          | 0/802 [00:00<?, ? examples/s]Filter (num_proc=2):   0%|          | 0/802 [00:00<?, ? examples/s]Map (num_proc=2):  93%|█████████▎| 747/802 [00:01<00:00, 744.41 examples/s]Filter (num_proc=2):  50%|█████     | 401/802 [00:00<00:00, 2666.30 examples/s]Filter (num_proc=2):  50%|█████     | 401/802 [00:00<00:00, 2712.80 examples/s]Filter (num_proc=2): 100%|██████████| 802/802 [00:00<00:00, 2567.23 examples/s]
Map (num_proc=2): 100%|██████████| 802/802 [00:01<00:00, 618.86 examples/s]
Filter (num_proc=2): 100%|██████████| 802/802 [00:00<00:00, 2063.13 examples/s]
Filter (num_proc=2):   0%|          | 0/802 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 401/802 [00:00<00:00, 2561.07 examples/s]Filter (num_proc=2): 100%|██████████| 802/802 [00:00<00:00, 2529.85 examples/s]
Map (num_proc=2):   0%|          | 0/240 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/240 [00:00<?, ? examples/s]Map (num_proc=2):  11%|█         | 26/240 [00:00<00:01, 153.09 examples/s]Map (num_proc=2):  57%|█████▋    | 137/240 [00:00<00:00, 587.71 examples/s]Map (num_proc=2):  11%|█         | 26/240 [00:00<00:01, 160.40 examples/s]Map (num_proc=2):  57%|█████▋    | 136/240 [00:00<00:00, 595.15 examples/s]Map (num_proc=2):   0%|          | 0/240 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 240/240 [00:00<00:00, 481.62 examples/s]
Map (num_proc=2):  11%|█         | 26/240 [00:00<00:01, 160.59 examples/s]Filter (num_proc=2):   0%|          | 0/240 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 240/240 [00:00<00:00, 394.88 examples/s]
Map (num_proc=2):  56%|█████▋    | 135/240 [00:00<00:00, 595.30 examples/s]Filter (num_proc=2): 100%|██████████| 240/240 [00:00<00:00, 1199.52 examples/s]
Filter (num_proc=2):   0%|          | 0/240 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 240/240 [00:00<00:00, 384.43 examples/s]
Filter (num_proc=2): 100%|██████████| 240/240 [00:00<00:00, 1186.47 examples/s]
Filter (num_proc=2):   0%|          | 0/240 [00:00<?, ? examples/s]Filter (num_proc=2): 100%|██████████| 240/240 [00:00<00:00, 1066.08 examples/s]
WARNING:accelerate.accelerator:FSDP Warning: When using FSDP, it is efficient and recommended to call prepare for the model before creating the optimizer
WARNING:accelerate.accelerator:FSDP Warning: When using FSDP, several parameter groups will be conflated into a single one due to nested module wrapping and parameter flattening.
***** Running training *****
  Num examples = 10,500
  Num Epochs = 2
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 8
  Total optimization steps = 656
  Number of trainable parameters = 1,684,605,952
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: flyhero99. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /ML-A100/home/xiangyue/lyf/AttributionBench/zsh_scripts/wandb/run-20231019_172136-9tsm8ipl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run llama2_7b_template-base_llama-bs32-lr1e-5-gas8_dataset_v2.2_2023-10-19-17:20:03
wandb: ⭐️ View project at https://wandb.ai/flyhero99/attribution-eval-v2.0
wandb: 🚀 View run at https://wandb.ai/flyhero99/attribution-eval-v2.0/runs/9tsm8ipl
  0%|          | 0/656 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/656 [00:05<55:53,  5.12s/it]  0%|          | 2/656 [00:08<47:38,  4.37s/it]  0%|          | 3/656 [00:12<41:53,  3.85s/it]  1%|          | 4/656 [00:15<39:24,  3.63s/it]  1%|          | 5/656 [00:18<38:12,  3.52s/it]  1%|          | 6/656 [00:22<39:15,  3.62s/it]  1%|          | 7/656 [00:26<38:37,  3.57s/it]  1%|          | 8/656 [00:29<37:49,  3.50s/it]  1%|▏         | 9/656 [00:33<38:32,  3.57s/it]  2%|▏         | 10/656 [00:36<37:53,  3.52s/it]                                                {'loss': 0.6555, 'learning_rate': 5e-06, 'epoch': 0.03}
  2%|▏         | 10/656 [00:36<37:53,  3.52s/it]  2%|▏         | 11/656 [00:39<37:09,  3.46s/it]  2%|▏         | 12/656 [00:43<38:16,  3.57s/it]  2%|▏         | 13/656 [00:47<37:37,  3.51s/it]  2%|▏         | 14/656 [00:50<37:10,  3.47s/it]  2%|▏         | 15/656 [00:57<47:18,  4.43s/it]  2%|▏         | 16/656 [01:00<44:22,  4.16s/it]  3%|▎         | 17/656 [01:04<41:40,  3.91s/it]  3%|▎         | 18/656 [01:07<39:38,  3.73s/it]  3%|▎         | 19/656 [01:10<39:21,  3.71s/it]  3%|▎         | 20/656 [01:14<38:57,  3.68s/it]                                                {'loss': 0.1276, 'learning_rate': 1e-05, 'epoch': 0.06}
  3%|▎         | 20/656 [01:14<38:57,  3.68s/it]  3%|▎         | 21/656 [01:18<38:33,  3.64s/it]  3%|▎         | 22/656 [01:21<37:19,  3.53s/it]  4%|▎         | 23/656 [01:24<36:48,  3.49s/it]  4%|▎         | 24/656 [01:28<36:11,  3.44s/it]  4%|▍         | 25/656 [01:31<36:04,  3.43s/it]  4%|▍         | 26/656 [01:34<35:46,  3.41s/it]  4%|▍         | 27/656 [01:38<37:59,  3.62s/it]  4%|▍         | 28/656 [01:42<37:22,  3.57s/it]  4%|▍         | 29/656 [01:45<37:04,  3.55s/it]  5%|▍         | 30/656 [01:49<36:16,  3.48s/it]                                                {'loss': 0.1142, 'learning_rate': 9.993901300776358e-06, 'epoch': 0.09}
  5%|▍         | 30/656 [01:49<36:16,  3.48s/it]  5%|▍         | 31/656 [01:52<36:05,  3.46s/it]  5%|▍         | 32/656 [01:56<36:06,  3.47s/it]  5%|▌         | 33/656 [01:59<36:09,  3.48s/it]  5%|▌         | 34/656 [02:03<37:42,  3.64s/it]  5%|▌         | 35/656 [02:07<37:16,  3.60s/it]  5%|▌         | 36/656 [02:11<38:01,  3.68s/it]  6%|▌         | 37/656 [02:14<38:08,  3.70s/it]  6%|▌         | 38/656 [02:18<37:19,  3.62s/it]  6%|▌         | 39/656 [02:21<36:38,  3.56s/it]  6%|▌         | 40/656 [02:25<37:50,  3.69s/it]                                                {'loss': 0.1179, 'learning_rate': 9.975620080758321e-06, 'epoch': 0.12}
  6%|▌         | 40/656 [02:25<37:50,  3.69s/it]  6%|▋         | 41/656 [02:28<36:44,  3.58s/it]  6%|▋         | 42/656 [02:32<36:29,  3.57s/it]  7%|▋         | 43/656 [02:35<36:00,  3.52s/it]  7%|▋         | 44/656 [02:39<35:49,  3.51s/it]  7%|▋         | 45/656 [02:42<35:23,  3.48s/it]  7%|▋         | 46/656 [02:46<36:32,  3.59s/it]  7%|▋         | 47/656 [02:50<36:10,  3.56s/it]  7%|▋         | 48/656 [02:53<35:39,  3.52s/it]  7%|▋         | 49/656 [02:57<35:46,  3.54s/it]  8%|▊         | 50/656 [03:00<35:09,  3.48s/it]                                                {'loss': 0.1138, 'learning_rate': 9.945200936610821e-06, 'epoch': 0.15}
  8%|▊         | 50/656 [03:00<35:09,  3.48s/it]  8%|▊         | 51/656 [03:04<35:18,  3.50s/it]  8%|▊         | 52/656 [03:07<35:20,  3.51s/it]  8%|▊         | 53/656 [03:11<35:14,  3.51s/it]  8%|▊         | 54/656 [03:14<35:46,  3.57s/it]  8%|▊         | 55/656 [03:18<36:22,  3.63s/it]  9%|▊         | 56/656 [03:22<36:11,  3.62s/it]  9%|▊         | 57/656 [03:25<35:24,  3.55s/it]  9%|▉         | 58/656 [03:29<35:20,  3.55s/it]  9%|▉         | 59/656 [03:32<34:39,  3.48s/it]  9%|▉         | 60/656 [03:36<35:56,  3.62s/it]                                                {'loss': 0.0942, 'learning_rate': 9.902718075218176e-06, 'epoch': 0.18}
  9%|▉         | 60/656 [03:36<35:56,  3.62s/it]  9%|▉         | 61/656 [03:39<35:19,  3.56s/it]  9%|▉         | 62/656 [03:43<34:51,  3.52s/it] 10%|▉         | 63/656 [03:46<34:21,  3.48s/it] 10%|▉         | 64/656 [03:50<34:34,  3.50s/it] 10%|▉         | 65/656 [03:53<34:21,  3.49s/it] 10%|█         | 66/656 [03:57<34:19,  3.49s/it] 10%|█         | 67/656 [04:00<34:22,  3.50s/it] 10%|█         | 68/656 [04:04<34:44,  3.55s/it] 11%|█         | 69/656 [04:07<34:07,  3.49s/it] 11%|█         | 70/656 [04:10<33:26,  3.42s/it]                                                {'loss': 0.1025, 'learning_rate': 9.848275132657903e-06, 'epoch': 0.21}
 11%|█         | 70/656 [04:11<33:26,  3.42s/it] 11%|█         | 71/656 [04:14<33:41,  3.46s/it] 11%|█         | 72/656 [04:18<33:53,  3.48s/it] 11%|█         | 73/656 [04:21<33:56,  3.49s/it] 11%|█▏        | 74/656 [04:24<33:45,  3.48s/it] 11%|█▏        | 75/656 [04:28<33:08,  3.42s/it] 12%|█▏        | 76/656 [04:31<33:26,  3.46s/it] 12%|█▏        | 77/656 [04:35<33:08,  3.43s/it] 12%|█▏        | 78/656 [04:38<33:34,  3.48s/it] 12%|█▏        | 79/656 [04:42<33:50,  3.52s/it] 12%|█▏        | 80/656 [04:46<34:47,  3.62s/it]                                                {'loss': 0.089, 'learning_rate': 9.782004921382612e-06, 'epoch': 0.24}
 12%|█▏        | 80/656 [04:46<34:47,  3.62s/it] 12%|█▏        | 81/656 [04:49<34:19,  3.58s/it] 12%|█▎        | 82/656 [04:53<34:00,  3.55s/it] 13%|█▎        | 83/656 [04:56<33:08,  3.47s/it] 13%|█▎        | 84/656 [05:00<33:16,  3.49s/it] 13%|█▎        | 85/656 [05:03<33:10,  3.49s/it] 13%|█▎        | 86/656 [05:06<32:54,  3.46s/it] 13%|█▎        | 87/656 [05:11<35:05,  3.70s/it] 13%|█▎        | 88/656 [05:14<34:11,  3.61s/it] 14%|█▎        | 89/656 [05:18<33:45,  3.57s/it] 14%|█▎        | 90/656 [05:21<33:06,  3.51s/it]                                                {'loss': 0.1187, 'learning_rate': 9.704069106226728e-06, 'epoch': 0.27}
 14%|█▎        | 90/656 [05:21<33:06,  3.51s/it] 14%|█▍        | 91/656 [05:24<33:07,  3.52s/it] 14%|█▍        | 92/656 [05:28<33:55,  3.61s/it] 14%|█▍        | 93/656 [05:32<33:21,  3.56s/it] 14%|█▍        | 94/656 [05:35<32:51,  3.51s/it] 14%|█▍        | 95/656 [05:39<33:07,  3.54s/it] 15%|█▍        | 96/656 [05:42<32:08,  3.44s/it] 15%|█▍        | 97/656 [05:45<32:00,  3.44s/it] 15%|█▍        | 98/656 [05:49<32:54,  3.54s/it] 15%|█▌        | 99/656 [05:53<32:33,  3.51s/it] 15%|█▌        | 100/656 [05:56<32:05,  3.46s/it]                                                 {'loss': 0.0916, 'learning_rate': 9.614657810028402e-06, 'epoch': 0.3}
 15%|█▌        | 100/656 [05:56<32:05,  3.46s/it]***** Running Evaluation *****
  Num examples = 802
  Batch size = 2

  0%|          | 0/101 [00:00<?, ?it/s][A
  2%|▏         | 2/101 [00:00<00:05, 16.63it/s][A
  4%|▍         | 4/101 [00:00<00:09,  9.88it/s][A
  6%|▌         | 6/101 [00:00<00:12,  7.77it/s][A
  7%|▋         | 7/101 [00:00<00:11,  8.03it/s][A
  8%|▊         | 8/101 [00:00<00:11,  8.02it/s][A
  9%|▉         | 9/101 [00:01<00:11,  7.71it/s][A
 11%|█         | 11/101 [00:01<00:10,  8.24it/s][A
 12%|█▏        | 12/101 [00:01<00:10,  8.23it/s][A
 13%|█▎        | 13/101 [00:01<00:10,  8.45it/s][A
 14%|█▍        | 14/101 [00:01<00:10,  7.98it/s][A
 15%|█▍        | 15/101 [00:01<00:10,  7.91it/s][A
 16%|█▌        | 16/101 [00:01<00:10,  7.83it/s][A
 17%|█▋        | 17/101 [00:02<00:10,  7.81it/s][A
 18%|█▊        | 18/101 [00:02<00:10,  8.13it/s][A
 19%|█▉        | 19/101 [00:02<00:09,  8.23it/s][A
 20%|█▉        | 20/101 [00:02<00:10,  7.84it/s][A
 21%|██        | 21/101 [00:02<00:10,  7.44it/s][A
 22%|██▏       | 22/101 [00:02<00:11,  6.63it/s][A
 23%|██▎       | 23/101 [00:02<00:11,  7.07it/s][A
 24%|██▍       | 24/101 [00:03<00:10,  7.41it/s][A
 25%|██▍       | 25/101 [00:03<00:10,  7.45it/s][A
 26%|██▌       | 26/101 [00:03<00:09,  7.67it/s][A
 27%|██▋       | 27/101 [00:03<00:09,  7.69it/s][A
 28%|██▊       | 28/101 [00:03<00:09,  7.59it/s][A
 29%|██▊       | 29/101 [00:03<00:10,  7.14it/s][A
 30%|██▉       | 30/101 [00:03<00:09,  7.43it/s][A
 31%|███       | 31/101 [00:03<00:08,  7.84it/s][A
 32%|███▏      | 32/101 [00:04<00:08,  7.94it/s][A
 33%|███▎      | 33/101 [00:04<00:08,  8.20it/s][A
 34%|███▎      | 34/101 [00:04<00:08,  8.03it/s][A
 35%|███▍      | 35/101 [00:04<00:08,  8.05it/s][A
 36%|███▌      | 36/101 [00:04<00:08,  8.03it/s][A
 37%|███▋      | 37/101 [00:04<00:08,  7.69it/s][A
 38%|███▊      | 38/101 [00:04<00:08,  7.86it/s][A
 39%|███▊      | 39/101 [00:04<00:07,  8.03it/s][A
 40%|███▉      | 40/101 [00:05<00:07,  7.89it/s][A
 41%|████      | 41/101 [00:05<00:07,  8.02it/s][A
 42%|████▏     | 42/101 [00:05<00:07,  7.65it/s][A
 43%|████▎     | 43/101 [00:05<00:07,  7.26it/s][A
 44%|████▎     | 44/101 [00:05<00:07,  7.72it/s][A
 45%|████▍     | 45/101 [00:05<00:07,  7.86it/s][A
 46%|████▌     | 46/101 [00:05<00:07,  7.28it/s][A
 47%|████▋     | 47/101 [00:05<00:07,  7.54it/s][A
 48%|████▊     | 48/101 [00:06<00:17,  3.11it/s][A
 49%|████▊     | 49/101 [00:07<00:21,  2.37it/s][A
 50%|████▉     | 50/101 [00:07<00:17,  2.90it/s][A
 50%|█████     | 51/101 [00:07<00:14,  3.52it/s][A
 51%|█████▏    | 52/101 [00:07<00:11,  4.14it/s][A
 52%|█████▏    | 53/101 [00:08<00:10,  4.72it/s][A
 53%|█████▎    | 54/101 [00:08<00:08,  5.32it/s][A
 54%|█████▍    | 55/101 [00:08<00:08,  5.48it/s][A
 55%|█████▌    | 56/101 [00:08<00:08,  5.34it/s][A
 56%|█████▋    | 57/101 [00:08<00:07,  5.75it/s][A
 57%|█████▋    | 58/101 [00:08<00:06,  6.19it/s][A
 58%|█████▊    | 59/101 [00:09<00:09,  4.42it/s][A
 59%|█████▉    | 60/101 [00:09<00:08,  5.04it/s][A
 60%|██████    | 61/101 [00:09<00:07,  5.39it/s][A
 61%|██████▏   | 62/101 [00:09<00:06,  5.84it/s][A
 62%|██████▏   | 63/101 [00:09<00:06,  6.28it/s][A
 63%|██████▎   | 64/101 [00:09<00:05,  6.59it/s][A
 64%|██████▍   | 65/101 [00:09<00:05,  6.84it/s][A
 65%|██████▌   | 66/101 [00:10<00:05,  6.74it/s][A
 66%|██████▋   | 67/101 [00:10<00:04,  6.82it/s][A
 67%|██████▋   | 68/101 [00:10<00:04,  6.63it/s][A
 68%|██████▊   | 69/101 [00:10<00:04,  6.84it/s][A
 69%|██████▉   | 70/101 [00:10<00:04,  6.34it/s][A
 70%|███████   | 71/101 [00:10<00:04,  6.79it/s][A
 71%|███████▏  | 72/101 [00:11<00:04,  7.04it/s][A
 72%|███████▏  | 73/101 [00:11<00:03,  7.36it/s][A
 73%|███████▎  | 74/101 [00:11<00:04,  6.52it/s][A
 74%|███████▍  | 75/101 [00:11<00:03,  6.61it/s][A
 75%|███████▌  | 76/101 [00:11<00:04,  6.08it/s][A
 76%|███████▌  | 77/101 [00:11<00:03,  6.09it/s][A
 77%|███████▋  | 78/101 [00:11<00:03,  6.35it/s][A
 78%|███████▊  | 79/101 [00:12<00:03,  5.87it/s][A
 79%|███████▉  | 80/101 [00:12<00:03,  6.25it/s][A
 80%|████████  | 81/101 [00:12<00:03,  6.43it/s][A
 81%|████████  | 82/101 [00:12<00:02,  6.40it/s][A
 82%|████████▏ | 83/101 [00:12<00:02,  6.11it/s][A
 83%|████████▎ | 84/101 [00:12<00:02,  5.92it/s][A
 84%|████████▍ | 85/101 [00:13<00:02,  5.99it/s][A
 85%|████████▌ | 86/101 [00:13<00:02,  6.39it/s][A
 86%|████████▌ | 87/101 [00:13<00:02,  6.40it/s][A
 87%|████████▋ | 88/101 [00:13<00:01,  6.57it/s][A
 88%|████████▊ | 89/101 [00:13<00:01,  6.79it/s][A
 89%|████████▉ | 90/101 [00:13<00:01,  7.03it/s][A
 90%|█████████ | 91/101 [00:13<00:01,  7.16it/s][A
 91%|█████████ | 92/101 [00:14<00:01,  7.12it/s][A
 92%|█████████▏| 93/101 [00:14<00:01,  7.62it/s][A
 94%|█████████▍| 95/101 [00:14<00:00,  8.59it/s][A
 96%|█████████▌| 97/101 [00:14<00:00,  9.24it/s][A
 97%|█████████▋| 98/101 [00:14<00:00,  9.40it/s][A
 98%|█████████▊| 99/101 [00:14<00:00,  9.50it/s][A
 99%|█████████▉| 100/101 [00:14<00:00,  9.59it/s][A
100%|██████████| 101/101 [00:15<00:00,  8.69it/s][A                                                 
                                                 [A{'eval_loss': 0.14031606912612915, 'eval_acc': 59.9251, 'eval_precision': 0.6828626799557032, 'eval_recall': 0.5988279301745636, 'eval_f1': 0.547016738399308, 'eval_runtime': 15.3458, 'eval_samples_per_second': 52.262, 'eval_steps_per_second': 6.582, 'epoch': 0.3}
 15%|█▌        | 100/656 [06:11<32:05,  3.46s/it]
100%|██████████| 101/101 [00:15<00:00,  8.69it/s][A
                                                 [A 15%|█▌        | 101/656 [06:15<1:15:43,  8.19s/it] 16%|█▌        | 102/656 [06:18<1:02:11,  6.74s/it] 16%|█▌        | 103/656 [06:22<53:05,  5.76s/it]   16%|█▌        | 104/656 [06:26<48:05,  5.23s/it] 16%|█▌        | 105/656 [06:29<43:19,  4.72s/it] 16%|█▌        | 106/656 [06:33<39:44,  4.33s/it] 16%|█▋        | 107/656 [06:37<37:37,  4.11s/it] 16%|█▋        | 108/656 [06:40<35:59,  3.94s/it] 17%|█▋        | 109/656 [06:44<34:33,  3.79s/it] 17%|█▋        | 110/656 [06:47<33:29,  3.68s/it]                                                 {'loss': 0.0828, 'learning_rate': 9.513989149828718e-06, 'epoch': 0.34}
 17%|█▋        | 110/656 [06:47<33:29,  3.68s/it] 17%|█▋        | 111/656 [06:50<32:39,  3.60s/it] 17%|█▋        | 112/656 [06:54<32:18,  3.56s/it] 17%|█▋        | 113/656 [06:57<32:28,  3.59s/it] 17%|█▋        | 114/656 [07:02<33:42,  3.73s/it] 18%|█▊        | 115/656 [07:05<32:41,  3.63s/it] 18%|█▊        | 116/656 [07:08<32:31,  3.61s/it] 18%|█▊        | 117/656 [07:12<32:21,  3.60s/it] 18%|█▊        | 118/656 [07:16<31:59,  3.57s/it] 18%|█▊        | 119/656 [07:19<32:08,  3.59s/it] 18%|█▊        | 120/656 [07:23<32:06,  3.59s/it]                                                 {'loss': 0.096, 'learning_rate': 9.4023087047796e-06, 'epoch': 0.37}
 18%|█▊        | 120/656 [07:23<32:06,  3.59s/it] 18%|█▊        | 121/656 [07:26<31:44,  3.56s/it] 19%|█▊        | 122/656 [07:30<31:09,  3.50s/it] 19%|█▉        | 123/656 [07:33<31:26,  3.54s/it] 19%|█▉        | 124/656 [07:37<31:06,  3.51s/it] 19%|█▉        | 125/656 [07:40<31:32,  3.56s/it] 19%|█▉        | 126/656 [07:44<31:18,  3.54s/it] 19%|█▉        | 127/656 [07:47<30:42,  3.48s/it] 20%|█▉        | 128/656 [07:51<30:31,  3.47s/it] 20%|█▉        | 129/656 [07:54<31:09,  3.55s/it] 20%|█▉        | 130/656 [07:58<30:40,  3.50s/it]                                                 {'loss': 0.0895, 'learning_rate': 9.279888917058453e-06, 'epoch': 0.4}
 20%|█▉        | 130/656 [07:58<30:40,  3.50s/it] 20%|█▉        | 131/656 [08:01<30:55,  3.53s/it] 20%|██        | 132/656 [08:05<30:47,  3.53s/it] 20%|██        | 133/656 [08:09<31:32,  3.62s/it] 20%|██        | 134/656 [08:12<31:25,  3.61s/it] 21%|██        | 135/656 [08:16<31:17,  3.60s/it] 21%|██        | 136/656 [08:19<30:40,  3.54s/it] 21%|██        | 137/656 [08:23<30:44,  3.55s/it] 21%|██        | 138/656 [08:26<30:16,  3.51s/it] 21%|██        | 139/656 [08:30<29:57,  3.48s/it] 21%|██▏       | 140/656 [08:33<29:43,  3.46s/it]                                                 {'loss': 0.1207, 'learning_rate': 9.14702842725101e-06, 'epoch': 0.43}
 21%|██▏       | 140/656 [08:33<29:43,  3.46s/it] 21%|██▏       | 141/656 [08:37<29:48,  3.47s/it] 22%|██▏       | 142/656 [08:40<29:56,  3.49s/it] 22%|██▏       | 143/656 [08:44<29:48,  3.49s/it] 22%|██▏       | 144/656 [08:47<29:47,  3.49s/it] 22%|██▏       | 145/656 [08:51<29:34,  3.47s/it] 22%|██▏       | 146/656 [08:54<29:06,  3.42s/it] 22%|██▏       | 147/656 [08:57<28:57,  3.41s/it] 23%|██▎       | 148/656 [09:01<28:43,  3.39s/it] 23%|██▎       | 149/656 [09:04<28:44,  3.40s/it] 23%|██▎       | 150/656 [09:07<28:36,  3.39s/it]                                                 {'loss': 0.0851, 'learning_rate': 9.00405134582369e-06, 'epoch': 0.46}
 23%|██▎       | 150/656 [09:08<28:36,  3.39s/it] 23%|██▎       | 151/656 [09:11<28:42,  3.41s/it] 23%|██▎       | 152/656 [09:14<28:33,  3.40s/it] 23%|██▎       | 153/656 [09:18<28:39,  3.42s/it] 23%|██▎       | 154/656 [09:21<28:53,  3.45s/it] 24%|██▎       | 155/656 [09:25<28:55,  3.46s/it] 24%|██▍       | 156/656 [09:28<28:40,  3.44s/it] 24%|██▍       | 157/656 [09:32<28:37,  3.44s/it] 24%|██▍       | 158/656 [09:35<28:26,  3.43s/it] 24%|██▍       | 159/656 [09:39<31:05,  3.75s/it] 24%|██▍       | 160/656 [09:43<30:23,  3.68s/it]                                                 {'loss': 0.0982, 'learning_rate': 8.851306462462689e-06, 'epoch': 0.49}
 24%|██▍       | 160/656 [09:43<30:23,  3.68s/it] 25%|██▍       | 161/656 [09:47<31:03,  3.76s/it] 25%|██▍       | 162/656 [09:50<29:55,  3.64s/it] 25%|██▍       | 163/656 [09:54<29:32,  3.60s/it] 25%|██▌       | 164/656 [09:57<29:21,  3.58s/it] 25%|██▌       | 165/656 [10:01<29:14,  3.57s/it] 25%|██▌       | 166/656 [10:04<29:04,  3.56s/it] 25%|██▌       | 167/656 [10:08<28:46,  3.53s/it] 26%|██▌       | 168/656 [10:11<28:30,  3.51s/it] 26%|██▌       | 169/656 [10:15<27:54,  3.44s/it] 26%|██▌       | 170/656 [10:18<28:28,  3.52s/it]                                                 {'loss': 0.1066, 'learning_rate': 8.689166395208638e-06, 'epoch': 0.52}
 26%|██▌       | 170/656 [10:18<28:28,  3.52s/it] 26%|██▌       | 171/656 [10:22<29:11,  3.61s/it] 26%|██▌       | 172/656 [10:26<28:58,  3.59s/it] 26%|██▋       | 173/656 [10:29<28:33,  3.55s/it] 27%|██▋       | 174/656 [10:32<27:55,  3.48s/it] 27%|██▋       | 175/656 [10:36<28:10,  3.51s/it] 27%|██▋       | 176/656 [10:40<28:20,  3.54s/it] 27%|██▋       | 177/656 [10:43<28:15,  3.54s/it] 27%|██▋       | 178/656 [10:47<28:21,  3.56s/it] 27%|██▋       | 179/656 [10:50<27:57,  3.52s/it] 27%|██▋       | 180/656 [10:54<27:43,  3.49s/it]                                                 {'loss': 0.0975, 'learning_rate': 8.518026681462448e-06, 'epoch': 0.55}
 27%|██▋       | 180/656 [10:54<27:43,  3.49s/it] 28%|██▊       | 181/656 [10:57<27:37,  3.49s/it] 28%|██▊       | 182/656 [11:00<27:15,  3.45s/it] 28%|██▊       | 183/656 [11:04<27:48,  3.53s/it] 28%|██▊       | 184/656 [11:08<27:36,  3.51s/it] 28%|██▊       | 185/656 [11:11<27:58,  3.56s/it] 28%|██▊       | 186/656 [11:15<27:16,  3.48s/it] 29%|██▊       | 187/656 [11:18<27:06,  3.47s/it] 29%|██▊       | 188/656 [11:22<27:21,  3.51s/it] 29%|██▉       | 189/656 [11:25<27:03,  3.48s/it] 29%|██▉       | 190/656 [11:28<26:49,  3.45s/it]                                                 {'loss': 0.0975, 'learning_rate': 8.338304813079866e-06, 'epoch': 0.58}
 29%|██▉       | 190/656 [11:29<26:49,  3.45s/it] 29%|██▉       | 191/656 [11:32<26:24,  3.41s/it] 29%|██▉       | 192/656 [11:35<26:13,  3.39s/it] 29%|██▉       | 193/656 [11:38<26:03,  3.38s/it] 30%|██▉       | 194/656 [11:42<26:02,  3.38s/it] 30%|██▉       | 195/656 [11:46<27:25,  3.57s/it] 30%|██▉       | 196/656 [11:49<27:18,  3.56s/it] 30%|███       | 197/656 [11:53<27:08,  3.55s/it] 30%|███       | 198/656 [11:56<26:52,  3.52s/it] 30%|███       | 199/656 [12:00<27:08,  3.56s/it] 30%|███       | 200/656 [12:04<27:40,  3.64s/it]                                                 {'loss': 0.098, 'learning_rate': 8.150439217908557e-06, 'epoch': 0.61}
 30%|███       | 200/656 [12:04<27:40,  3.64s/it]***** Running Evaluation *****
  Num examples = 802
  Batch size = 2

  0%|          | 0/101 [00:00<?, ?it/s][A
  2%|▏         | 2/101 [00:00<00:05, 16.81it/s][A
  4%|▍         | 4/101 [00:00<00:09,  9.90it/s][A
  6%|▌         | 6/101 [00:00<00:12,  7.75it/s][A
  7%|▋         | 7/101 [00:00<00:11,  8.03it/s][A
  8%|▊         | 8/101 [00:00<00:11,  8.01it/s][A
  9%|▉         | 9/101 [00:01<00:11,  7.71it/s][A
 11%|█         | 11/101 [00:01<00:10,  8.22it/s][A
 12%|█▏        | 12/101 [00:01<00:10,  8.22it/s][A
 13%|█▎        | 13/101 [00:01<00:10,  8.43it/s][A
 14%|█▍        | 14/101 [00:01<00:10,  7.97it/s][A
 15%|█▍        | 15/101 [00:01<00:10,  7.91it/s][A
 16%|█▌        | 16/101 [00:01<00:10,  7.82it/s][A
 17%|█▋        | 17/101 [00:02<00:10,  7.79it/s][A
 18%|█▊        | 18/101 [00:02<00:10,  8.12it/s][A
 19%|█▉        | 19/101 [00:02<00:09,  8.22it/s][A
 20%|█▉        | 20/101 [00:02<00:10,  7.82it/s][A
 21%|██        | 21/101 [00:02<00:10,  7.43it/s][A
 22%|██▏       | 22/101 [00:02<00:11,  6.62it/s][A
 23%|██▎       | 23/101 [00:02<00:11,  7.05it/s][A
 24%|██▍       | 24/101 [00:03<00:10,  7.38it/s][A
 25%|██▍       | 25/101 [00:03<00:10,  7.42it/s][A
 26%|██▌       | 26/101 [00:03<00:09,  7.65it/s][A
 27%|██▋       | 27/101 [00:03<00:09,  7.68it/s][A
 28%|██▊       | 28/101 [00:03<00:09,  7.61it/s][A
 29%|██▊       | 29/101 [00:03<00:10,  7.14it/s][A
 30%|██▉       | 30/101 [00:03<00:09,  7.42it/s][A
 31%|███       | 31/101 [00:03<00:08,  7.84it/s][A
 32%|███▏      | 32/101 [00:04<00:08,  7.94it/s][A
 33%|███▎      | 33/101 [00:04<00:08,  8.20it/s][A
 34%|███▎      | 34/101 [00:04<00:08,  8.02it/s][A
 35%|███▍      | 35/101 [00:04<00:08,  8.04it/s][A
 36%|███▌      | 36/101 [00:04<00:08,  8.01it/s][A
 37%|███▋      | 37/101 [00:04<00:08,  7.66it/s][A
 38%|███▊      | 38/101 [00:04<00:08,  7.83it/s][A
 39%|███▊      | 39/101 [00:04<00:07,  7.99it/s][A
 40%|███▉      | 40/101 [00:05<00:07,  7.86it/s][A
 41%|████      | 41/101 [00:05<00:07,  7.99it/s][A
 42%|████▏     | 42/101 [00:05<00:07,  7.62it/s][A
 43%|████▎     | 43/101 [00:05<00:08,  7.22it/s][A
 44%|████▎     | 44/101 [00:05<00:07,  7.68it/s][A
 45%|████▍     | 45/101 [00:05<00:07,  7.81it/s][A
 46%|████▌     | 46/101 [00:05<00:07,  7.24it/s][A
 47%|████▋     | 47/101 [00:06<00:07,  7.48it/s][A
 48%|████▊     | 48/101 [00:06<00:17,  3.10it/s][A
 49%|████▊     | 49/101 [00:07<00:22,  2.36it/s][A
 50%|████▉     | 50/101 [00:07<00:17,  2.89it/s][A
 50%|█████     | 51/101 [00:07<00:14,  3.51it/s][A
 51%|█████▏    | 52/101 [00:07<00:11,  4.12it/s][A
 52%|█████▏    | 53/101 [00:08<00:10,  4.71it/s][A
 53%|█████▎    | 54/101 [00:08<00:08,  5.30it/s][A
 54%|█████▍    | 55/101 [00:08<00:08,  5.46it/s][A
 55%|█████▌    | 56/101 [00:08<00:08,  5.31it/s][A
 56%|█████▋    | 57/101 [00:08<00:07,  5.74it/s][A
 57%|█████▋    | 58/101 [00:08<00:06,  6.17it/s][A
 58%|█████▊    | 59/101 [00:09<00:09,  4.41it/s][A
 59%|█████▉    | 60/101 [00:09<00:08,  5.03it/s][A
 60%|██████    | 61/101 [00:09<00:07,  5.37it/s][A
 61%|██████▏   | 62/101 [00:09<00:06,  5.80it/s][A
 62%|██████▏   | 63/101 [00:09<00:06,  6.24it/s][A
 63%|██████▎   | 64/101 [00:09<00:05,  6.57it/s][A
 64%|██████▍   | 65/101 [00:10<00:05,  6.82it/s][A
 65%|██████▌   | 66/101 [00:10<00:05,  6.72it/s][A
 66%|██████▋   | 67/101 [00:10<00:05,  6.80it/s][A
 67%|██████▋   | 68/101 [00:10<00:05,  6.60it/s][A
 68%|██████▊   | 69/101 [00:10<00:04,  6.81it/s][A
 69%|██████▉   | 70/101 [00:10<00:04,  6.30it/s][A
 70%|███████   | 71/101 [00:10<00:04,  6.75it/s][A
 71%|███████▏  | 72/101 [00:11<00:04,  7.00it/s][A
 72%|███████▏  | 73/101 [00:11<00:03,  7.34it/s][A
 73%|███████▎  | 74/101 [00:11<00:04,  6.50it/s][A
 74%|███████▍  | 75/101 [00:11<00:03,  6.58it/s][A
 75%|███████▌  | 76/101 [00:11<00:04,  6.05it/s][A
 76%|███████▌  | 77/101 [00:11<00:03,  6.07it/s][A
 77%|███████▋  | 78/101 [00:12<00:03,  6.33it/s][A
 78%|███████▊  | 79/101 [00:12<00:03,  5.85it/s][A
 79%|███████▉  | 80/101 [00:12<00:03,  6.23it/s][A
 80%|████████  | 81/101 [00:12<00:03,  6.41it/s][A
 81%|████████  | 82/101 [00:12<00:02,  6.39it/s][A
 82%|████████▏ | 83/101 [00:12<00:02,  6.09it/s][A
 83%|████████▎ | 84/101 [00:13<00:02,  5.89it/s][A
 84%|████████▍ | 85/101 [00:13<00:02,  5.97it/s][A
 85%|████████▌ | 86/101 [00:13<00:02,  6.38it/s][A
 86%|████████▌ | 87/101 [00:13<00:02,  6.39it/s][A
 87%|████████▋ | 88/101 [00:13<00:01,  6.56it/s][A
 88%|████████▊ | 89/101 [00:13<00:01,  6.79it/s][A
 89%|████████▉ | 90/101 [00:13<00:01,  7.02it/s][A
 90%|█████████ | 91/101 [00:14<00:01,  7.15it/s][A
 91%|█████████ | 92/101 [00:14<00:01,  7.10it/s][A
 92%|█████████▏| 93/101 [00:14<00:01,  7.59it/s][A
 94%|█████████▍| 95/101 [00:14<00:00,  8.57it/s][A
 96%|█████████▌| 97/101 [00:14<00:00,  9.20it/s][A
 97%|█████████▋| 98/101 [00:14<00:00,  9.35it/s][A
 98%|█████████▊| 99/101 [00:14<00:00,  9.48it/s][A
 99%|█████████▉| 100/101 [00:14<00:00,  9.58it/s][A
100%|██████████| 101/101 [00:15<00:00,  8.67it/s][A                                                 
                                                 [A{'eval_loss': 0.1225866973400116, 'eval_acc': 62.422, 'eval_precision': 0.7065936466329652, 'eval_recall': 0.623824812967581, 'eval_f1': 0.5822088600466135, 'eval_runtime': 15.3823, 'eval_samples_per_second': 52.138, 'eval_steps_per_second': 6.566, 'epoch': 0.61}
 30%|███       | 200/656 [12:19<27:40,  3.64s/it]
100%|██████████| 101/101 [00:15<00:00,  8.67it/s][A
                                                 [A 31%|███       | 201/656 [12:23<1:02:20,  8.22s/it] 31%|███       | 202/656 [12:26<51:32,  6.81s/it]   31%|███       | 203/656 [12:30<44:16,  5.86s/it] 31%|███       | 204/656 [12:34<39:11,  5.20s/it] 31%|███▏      | 205/656 [12:37<35:19,  4.70s/it] 31%|███▏      | 206/656 [12:41<32:33,  4.34s/it] 32%|███▏      | 207/656 [12:44<30:23,  4.06s/it] 32%|███▏      | 208/656 [12:48<29:18,  3.93s/it] 32%|███▏      | 209/656 [12:51<27:59,  3.76s/it] 32%|███▏      | 210/656 [12:54<27:07,  3.65s/it]                                                 {'loss': 0.0988, 'learning_rate': 7.954888190252292e-06, 'epoch': 0.64}
 32%|███▏      | 210/656 [12:55<27:07,  3.65s/it] 32%|███▏      | 211/656 [12:58<26:37,  3.59s/it] 32%|███▏      | 212/656 [13:01<26:05,  3.53s/it] 32%|███▏      | 213/656 [13:05<27:00,  3.66s/it] 33%|███▎      | 214/656 [13:09<26:19,  3.57s/it] 33%|███▎      | 215/656 [13:13<27:05,  3.69s/it] 33%|███▎      | 216/656 [13:16<27:27,  3.75s/it] 33%|███▎      | 217/656 [13:20<26:47,  3.66s/it] 33%|███▎      | 218/656 [13:23<26:34,  3.64s/it] 33%|███▎      | 219/656 [13:27<25:43,  3.53s/it] 34%|███▎      | 220/656 [13:30<25:34,  3.52s/it]                                                 {'loss': 0.0936, 'learning_rate': 7.752128772871292e-06, 'epoch': 0.67}
 34%|███▎      | 220/656 [13:30<25:34,  3.52s/it] 34%|███▎      | 221/656 [13:34<26:24,  3.64s/it] 34%|███▍      | 222/656 [13:38<25:59,  3.59s/it] 34%|███▍      | 223/656 [13:41<26:27,  3.67s/it] 34%|███▍      | 224/656 [13:45<26:22,  3.66s/it] 34%|███▍      | 225/656 [13:49<26:31,  3.69s/it] 34%|███▍      | 226/656 [13:52<25:58,  3.62s/it] 35%|███▍      | 227/656 [13:56<25:26,  3.56s/it] 35%|███▍      | 228/656 [13:59<25:06,  3.52s/it] 35%|███▍      | 229/656 [14:03<26:41,  3.75s/it] 35%|███▌      | 230/656 [14:07<25:36,  3.61s/it]                                                 {'loss': 0.0764, 'learning_rate': 7.542655593246103e-06, 'epoch': 0.7}
 35%|███▌      | 230/656 [14:07<25:36,  3.61s/it] 35%|███▌      | 231/656 [14:10<25:07,  3.55s/it] 35%|███▌      | 232/656 [14:14<24:37,  3.49s/it] 36%|███▌      | 233/656 [14:17<24:32,  3.48s/it] 36%|███▌      | 234/656 [14:21<24:36,  3.50s/it] 36%|███▌      | 235/656 [14:24<25:05,  3.58s/it] 36%|███▌      | 236/656 [14:28<24:34,  3.51s/it] 36%|███▌      | 237/656 [14:31<24:07,  3.46s/it] 36%|███▋      | 238/656 [14:34<23:46,  3.41s/it] 36%|███▋      | 239/656 [14:38<24:01,  3.46s/it] 37%|███▋      | 240/656 [14:42<24:35,  3.55s/it]                                                 {'loss': 0.0992, 'learning_rate': 7.326979656943907e-06, 'epoch': 0.73}
 37%|███▋      | 240/656 [14:42<24:35,  3.55s/it] 37%|███▋      | 241/656 [14:45<24:18,  3.51s/it] 37%|███▋      | 242/656 [14:49<24:35,  3.56s/it] 37%|███▋      | 243/656 [14:52<24:09,  3.51s/it] 37%|███▋      | 244/656 [14:55<23:38,  3.44s/it] 37%|███▋      | 245/656 [14:59<23:19,  3.41s/it] 38%|███▊      | 246/656 [15:02<23:39,  3.46s/it] 38%|███▊      | 247/656 [15:06<23:53,  3.50s/it] 38%|███▊      | 248/656 [15:09<23:22,  3.44s/it] 38%|███▊      | 249/656 [15:13<23:12,  3.42s/it] 38%|███▊      | 250/656 [15:16<22:53,  3.38s/it]                                                 {'loss': 0.08, 'learning_rate': 7.105627101030816e-06, 'epoch': 0.76}
 38%|███▊      | 250/656 [15:16<22:53,  3.38s/it] 38%|███▊      | 251/656 [15:19<22:57,  3.40s/it] 38%|███▊      | 252/656 [15:23<22:46,  3.38s/it] 39%|███▊      | 253/656 [15:26<22:26,  3.34s/it] 39%|███▊      | 254/656 [15:30<23:05,  3.45s/it] 39%|███▉      | 255/656 [15:33<22:39,  3.39s/it] 39%|███▉      | 256/656 [15:36<22:40,  3.40s/it] 39%|███▉      | 257/656 [15:40<23:03,  3.47s/it] 39%|███▉      | 258/656 [15:43<23:01,  3.47s/it] 39%|███▉      | 259/656 [15:47<22:37,  3.42s/it] 40%|███▉      | 260/656 [15:50<22:32,  3.41s/it]                                                 {'loss': 0.1013, 'learning_rate': 6.879137910571191e-06, 'epoch': 0.79}
 40%|███▉      | 260/656 [15:50<22:32,  3.41s/it] 40%|███▉      | 261/656 [15:53<22:20,  3.39s/it] 40%|███▉      | 262/656 [15:57<22:22,  3.41s/it] 40%|████      | 263/656 [16:00<22:38,  3.46s/it] 40%|████      | 264/656 [16:04<22:46,  3.49s/it] 40%|████      | 265/656 [16:07<22:27,  3.45s/it] 41%|████      | 266/656 [16:11<22:19,  3.43s/it] 41%|████      | 267/656 [16:14<21:54,  3.38s/it] 41%|████      | 268/656 [16:17<21:55,  3.39s/it] 41%|████      | 269/656 [16:21<22:15,  3.45s/it] 41%|████      | 270/656 [16:24<22:12,  3.45s/it]                                                 {'loss': 0.0818, 'learning_rate': 6.64806460134504e-06, 'epoch': 0.82}
 41%|████      | 270/656 [16:25<22:12,  3.45s/it] 41%|████▏     | 271/656 [16:28<22:06,  3.45s/it] 41%|████▏     | 272/656 [16:31<22:04,  3.45s/it] 42%|████▏     | 273/656 [16:35<22:07,  3.47s/it] 42%|████▏     | 274/656 [16:38<22:05,  3.47s/it] 42%|████▏     | 275/656 [16:42<22:05,  3.48s/it] 42%|████▏     | 276/656 [16:46<22:24,  3.54s/it] 42%|████▏     | 277/656 [16:49<22:36,  3.58s/it] 42%|████▏     | 278/656 [16:53<22:20,  3.55s/it] 43%|████▎     | 279/656 [16:56<22:40,  3.61s/it] 43%|████▎     | 280/656 [17:00<22:07,  3.53s/it]                                                 {'loss': 0.0914, 'learning_rate': 6.412970871996995e-06, 'epoch': 0.85}
 43%|████▎     | 280/656 [17:00<22:07,  3.53s/it] 43%|████▎     | 281/656 [17:03<21:42,  3.47s/it] 43%|████▎     | 282/656 [17:07<21:34,  3.46s/it] 43%|████▎     | 283/656 [17:10<21:32,  3.46s/it] 43%|████▎     | 284/656 [17:14<22:07,  3.57s/it] 43%|████▎     | 285/656 [17:18<22:27,  3.63s/it] 44%|████▎     | 286/656 [17:21<22:06,  3.59s/it] 44%|████▍     | 287/656 [17:25<21:52,  3.56s/it] 44%|████▍     | 288/656 [17:29<22:37,  3.69s/it] 44%|████▍     | 289/656 [17:32<22:15,  3.64s/it] 44%|████▍     | 290/656 [17:36<22:11,  3.64s/it]                                                 {'loss': 0.1039, 'learning_rate': 6.17443022890492e-06, 'epoch': 0.88}
 44%|████▍     | 290/656 [17:36<22:11,  3.64s/it] 44%|████▍     | 291/656 [17:39<21:25,  3.52s/it] 45%|████▍     | 292/656 [17:42<21:09,  3.49s/it] 45%|████▍     | 293/656 [17:46<21:01,  3.47s/it] 45%|████▍     | 294/656 [17:49<21:01,  3.48s/it] 45%|████▍     | 295/656 [17:53<21:17,  3.54s/it] 45%|████▌     | 296/656 [17:56<20:48,  3.47s/it] 45%|████▌     | 297/656 [18:00<20:23,  3.41s/it] 45%|████▌     | 298/656 [18:04<22:02,  3.69s/it] 46%|████▌     | 299/656 [18:07<21:25,  3.60s/it] 46%|████▌     | 300/656 [18:11<20:52,  3.52s/it]                                                 {'loss': 0.09, 'learning_rate': 5.933024587122745e-06, 'epoch': 0.91}
 46%|████▌     | 300/656 [18:11<20:52,  3.52s/it]***** Running Evaluation *****
  Num examples = 802
  Batch size = 2

  0%|          | 0/101 [00:00<?, ?it/s][A
  2%|▏         | 2/101 [00:00<00:05, 16.65it/s][A
  4%|▍         | 4/101 [00:00<00:09,  9.88it/s][A
  6%|▌         | 6/101 [00:00<00:12,  7.78it/s][A
  7%|▋         | 7/101 [00:00<00:11,  8.03it/s][A
  8%|▊         | 8/101 [00:00<00:11,  8.00it/s][A
  9%|▉         | 9/101 [00:01<00:11,  7.70it/s][A
 11%|█         | 11/101 [00:01<00:10,  8.21it/s][A
 12%|█▏        | 12/101 [00:01<00:10,  8.21it/s][A
 13%|█▎        | 13/101 [00:01<00:10,  8.43it/s][A
 14%|█▍        | 14/101 [00:01<00:10,  7.97it/s][A
 15%|█▍        | 15/101 [00:01<00:10,  7.91it/s][A
 16%|█▌        | 16/101 [00:01<00:10,  7.81it/s][A
 17%|█▋        | 17/101 [00:02<00:10,  7.80it/s][A
 18%|█▊        | 18/101 [00:02<00:10,  8.12it/s][A
 19%|█▉        | 19/101 [00:02<00:09,  8.20it/s][A
 20%|█▉        | 20/101 [00:02<00:10,  7.83it/s][A
 21%|██        | 21/101 [00:02<00:10,  7.43it/s][A
 22%|██▏       | 22/101 [00:02<00:11,  6.65it/s][A
 23%|██▎       | 23/101 [00:02<00:11,  7.07it/s][A
 24%|██▍       | 24/101 [00:03<00:10,  7.40it/s][A
 25%|██▍       | 25/101 [00:03<00:10,  7.44it/s][A
 26%|██▌       | 26/101 [00:03<00:09,  7.67it/s][A
 27%|██▋       | 27/101 [00:03<00:09,  7.71it/s][A
 28%|██▊       | 28/101 [00:03<00:09,  7.63it/s][A
 29%|██▊       | 29/101 [00:03<00:10,  7.17it/s][A
 30%|██▉       | 30/101 [00:03<00:09,  7.46it/s][A
 31%|███       | 31/101 [00:03<00:08,  7.87it/s][A
 32%|███▏      | 32/101 [00:04<00:08,  7.98it/s][A
 33%|███▎      | 33/101 [00:04<00:08,  8.24it/s][A
 34%|███▎      | 34/101 [00:04<00:08,  8.05it/s][A
 35%|███▍      | 35/101 [00:04<00:08,  8.06it/s][A
 36%|███▌      | 36/101 [00:04<00:08,  8.05it/s][A
 37%|███▋      | 37/101 [00:04<00:08,  7.70it/s][A
 38%|███▊      | 38/101 [00:04<00:08,  7.85it/s][A
 39%|███▊      | 39/101 [00:04<00:07,  8.02it/s][A
 40%|███▉      | 40/101 [00:05<00:07,  7.89it/s][A
 41%|████      | 41/101 [00:05<00:07,  8.02it/s][A
 42%|████▏     | 42/101 [00:05<00:07,  7.65it/s][A
 43%|████▎     | 43/101 [00:05<00:07,  7.27it/s][A
 44%|████▎     | 44/101 [00:05<00:07,  7.73it/s][A
 45%|████▍     | 45/101 [00:05<00:07,  7.87it/s][A
 46%|████▌     | 46/101 [00:05<00:07,  7.27it/s][A
 47%|████▋     | 47/101 [00:05<00:07,  7.53it/s][A
 48%|████▊     | 48/101 [00:06<00:17,  3.11it/s][A
 49%|████▊     | 49/101 [00:07<00:21,  2.37it/s][A
 50%|████▉     | 50/101 [00:07<00:17,  2.91it/s][A
 50%|█████     | 51/101 [00:07<00:14,  3.52it/s][A
 51%|█████▏    | 52/101 [00:07<00:11,  4.14it/s][A
 52%|█████▏    | 53/101 [00:07<00:10,  4.73it/s][A
 53%|█████▎    | 54/101 [00:08<00:08,  5.32it/s][A
 54%|█████▍    | 55/101 [00:08<00:08,  5.48it/s][A
 55%|█████▌    | 56/101 [00:08<00:08,  5.34it/s][A
 56%|█████▋    | 57/101 [00:08<00:07,  5.76it/s][A
 57%|█████▋    | 58/101 [00:08<00:06,  6.19it/s][A
 58%|█████▊    | 59/101 [00:09<00:09,  4.43it/s][A
 59%|█████▉    | 60/101 [00:09<00:08,  5.05it/s][A
 60%|██████    | 61/101 [00:09<00:07,  5.39it/s][A
 61%|██████▏   | 62/101 [00:09<00:06,  5.83it/s][A
 62%|██████▏   | 63/101 [00:09<00:06,  6.27it/s][A
 63%|██████▎   | 64/101 [00:09<00:05,  6.57it/s][A
 64%|██████▍   | 65/101 [00:09<00:05,  6.81it/s][A
 65%|██████▌   | 66/101 [00:10<00:05,  6.72it/s][A
 66%|██████▋   | 67/101 [00:10<00:04,  6.80it/s][A
 67%|██████▋   | 68/101 [00:10<00:04,  6.62it/s][A
 68%|██████▊   | 69/101 [00:10<00:04,  6.83it/s][A
 69%|██████▉   | 70/101 [00:10<00:04,  6.33it/s][A
 70%|███████   | 71/101 [00:10<00:04,  6.78it/s][A
 71%|███████▏  | 72/101 [00:11<00:04,  7.03it/s][A
 72%|███████▏  | 73/101 [00:11<00:03,  7.37it/s][A
 73%|███████▎  | 74/101 [00:11<00:04,  6.53it/s][A
 74%|███████▍  | 75/101 [00:11<00:03,  6.62it/s][A
 75%|███████▌  | 76/101 [00:11<00:04,  6.08it/s][A
 76%|███████▌  | 77/101 [00:11<00:03,  6.08it/s][A
 77%|███████▋  | 78/101 [00:11<00:03,  6.33it/s][A
 78%|███████▊  | 79/101 [00:12<00:03,  5.86it/s][A
 79%|███████▉  | 80/101 [00:12<00:03,  6.25it/s][A
 80%|████████  | 81/101 [00:12<00:03,  6.42it/s][A
 81%|████████  | 82/101 [00:12<00:02,  6.39it/s][A
 82%|████████▏ | 83/101 [00:12<00:02,  6.10it/s][A
 83%|████████▎ | 84/101 [00:12<00:02,  5.91it/s][A
 84%|████████▍ | 85/101 [00:13<00:02,  5.99it/s][A
 85%|████████▌ | 86/101 [00:13<00:02,  6.40it/s][A
 86%|████████▌ | 87/101 [00:13<00:02,  6.42it/s][A
 87%|████████▋ | 88/101 [00:13<00:01,  6.59it/s][A
 88%|████████▊ | 89/101 [00:13<00:01,  6.80it/s][A
 89%|████████▉ | 90/101 [00:13<00:01,  7.05it/s][A
 90%|█████████ | 91/101 [00:13<00:01,  7.17it/s][A
 91%|█████████ | 92/101 [00:14<00:01,  7.11it/s][A
 92%|█████████▏| 93/101 [00:14<00:01,  7.61it/s][A
 94%|█████████▍| 95/101 [00:14<00:00,  8.57it/s][A
 96%|█████████▌| 97/101 [00:14<00:00,  9.22it/s][A
 97%|█████████▋| 98/101 [00:14<00:00,  9.36it/s][A
 98%|█████████▊| 99/101 [00:14<00:00,  9.48it/s][A
 99%|█████████▉| 100/101 [00:14<00:00,  9.60it/s][A
100%|██████████| 101/101 [00:15<00:00,  8.68it/s][A                                                 
                                                 [A{'eval_loss': 0.13632915914058685, 'eval_acc': 51.0612, 'eval_precision': 0.5106741573033708, 'eval_recall': 0.5105423940149626, 'eval_f1': 0.5090622537431048, 'eval_runtime': 15.3366, 'eval_samples_per_second': 52.293, 'eval_steps_per_second': 6.586, 'epoch': 0.91}
 46%|████▌     | 300/656 [18:26<20:52,  3.52s/it]
100%|██████████| 101/101 [00:15<00:00,  8.68it/s][A
                                                 [A 46%|████▌     | 301/656 [18:30<48:16,  8.16s/it] 46%|████▌     | 302/656 [18:33<39:56,  6.77s/it] 46%|████▌     | 303/656 [18:37<34:04,  5.79s/it] 46%|████▋     | 304/656 [18:40<29:47,  5.08s/it] 46%|████▋     | 305/656 [18:43<26:46,  4.58s/it] 47%|████▋     | 306/656 [18:47<24:37,  4.22s/it] 47%|████▋     | 307/656 [18:50<23:23,  4.02s/it] 47%|████▋     | 308/656 [18:54<22:40,  3.91s/it] 47%|████▋     | 309/656 [18:57<21:43,  3.76s/it] 47%|████▋     | 310/656 [19:01<20:57,  3.63s/it]                                                 {'loss': 0.0787, 'learning_rate': 5.689342850810523e-06, 'epoch': 0.94}
 47%|████▋     | 310/656 [19:01<20:57,  3.63s/it] 47%|████▋     | 311/656 [19:05<21:39,  3.77s/it] 48%|████▊     | 312/656 [19:08<20:53,  3.64s/it] 48%|████▊     | 313/656 [19:12<20:25,  3.57s/it] 48%|████▊     | 314/656 [19:16<20:48,  3.65s/it] 48%|████▊     | 315/656 [19:19<20:40,  3.64s/it] 48%|████▊     | 316/656 [19:23<20:14,  3.57s/it] 48%|████▊     | 317/656 [19:26<19:51,  3.52s/it] 48%|████▊     | 318/656 [19:30<20:37,  3.66s/it] 49%|████▊     | 319/656 [19:33<19:57,  3.55s/it] 49%|████▉     | 320/656 [19:37<19:41,  3.52s/it]                                                 {'loss': 0.0869, 'learning_rate': 5.443979476614674e-06, 'epoch': 0.98}
 49%|████▉     | 320/656 [19:37<19:41,  3.52s/it] 49%|████▉     | 321/656 [19:40<19:24,  3.48s/it] 49%|████▉     | 322/656 [19:43<19:06,  3.43s/it] 49%|████▉     | 323/656 [19:47<18:55,  3.41s/it] 49%|████▉     | 324/656 [19:51<20:25,  3.69s/it] 50%|████▉     | 325/656 [19:54<19:56,  3.61s/it] 50%|████▉     | 326/656 [19:58<19:28,  3.54s/it] 50%|████▉     | 327/656 [20:01<19:05,  3.48s/it] 50%|█████     | 328/656 [20:05<19:18,  3.53s/it]Saving model checkpoint to /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-328
Configuration saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-328/config.json
Configuration saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-328/generation_config.json
Model weights saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-328/pytorch_model.bin
tokenizer config file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-328/tokenizer_config.json
Special tokens file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-328/special_tokens_map.json
added tokens file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-328/added_tokens.json
 50%|█████     | 329/656 [22:10<3:37:57, 39.99s/it] 50%|█████     | 330/656 [22:13<2:37:43, 29.03s/it]                                                   {'loss': 0.0932, 'learning_rate': 5.19753302350309e-06, 'epoch': 1.01}
 50%|█████     | 330/656 [22:13<2:37:43, 29.03s/it] 50%|█████     | 331/656 [22:17<1:55:44, 21.37s/it] 51%|█████     | 332/656 [22:21<1:27:05, 16.13s/it] 51%|█████     | 333/656 [22:25<1:07:33, 12.55s/it] 51%|█████     | 334/656 [22:29<52:53,  9.86s/it]   51%|█████     | 335/656 [22:32<42:42,  7.98s/it] 51%|█████     | 336/656 [22:36<35:24,  6.64s/it] 51%|█████▏    | 337/656 [22:39<30:14,  5.69s/it] 52%|█████▏    | 338/656 [22:43<26:31,  5.00s/it] 52%|█████▏    | 339/656 [22:46<24:37,  4.66s/it] 52%|█████▏    | 340/656 [22:50<22:33,  4.28s/it]                                                 {'loss': 0.0738, 'learning_rate': 4.9506046925926725e-06, 'epoch': 1.04}
 52%|█████▏    | 340/656 [22:50<22:33,  4.28s/it] 52%|█████▏    | 341/656 [22:53<20:59,  4.00s/it] 52%|█████▏    | 342/656 [22:57<20:17,  3.88s/it] 52%|█████▏    | 343/656 [23:00<19:23,  3.72s/it] 52%|█████▏    | 344/656 [23:04<19:22,  3.73s/it] 53%|█████▎    | 345/656 [23:08<19:18,  3.73s/it] 53%|█████▎    | 346/656 [23:11<18:52,  3.65s/it] 53%|█████▎    | 347/656 [23:14<18:20,  3.56s/it] 53%|█████▎    | 348/656 [23:18<18:56,  3.69s/it] 53%|█████▎    | 349/656 [23:22<18:23,  3.59s/it] 53%|█████▎    | 350/656 [23:26<19:32,  3.83s/it]                                                 {'loss': 0.0773, 'learning_rate': 4.703796860531429e-06, 'epoch': 1.07}
 53%|█████▎    | 350/656 [23:26<19:32,  3.83s/it] 54%|█████▎    | 351/656 [23:30<19:01,  3.74s/it] 54%|█████▎    | 352/656 [23:33<18:22,  3.63s/it] 54%|█████▍    | 353/656 [23:36<17:51,  3.54s/it] 54%|█████▍    | 354/656 [23:40<17:57,  3.57s/it] 54%|█████▍    | 355/656 [23:43<17:25,  3.47s/it] 54%|█████▍    | 356/656 [23:47<17:13,  3.44s/it] 54%|█████▍    | 357/656 [23:50<17:00,  3.41s/it] 55%|█████▍    | 358/656 [23:54<17:12,  3.46s/it] 55%|█████▍    | 359/656 [23:57<17:10,  3.47s/it] 55%|█████▍    | 360/656 [24:00<16:51,  3.42s/it]                                                 {'loss': 0.0651, 'learning_rate': 4.457711610012873e-06, 'epoch': 1.1}
 55%|█████▍    | 360/656 [24:00<16:51,  3.42s/it] 55%|█████▌    | 361/656 [24:04<17:11,  3.50s/it] 55%|█████▌    | 362/656 [24:08<17:09,  3.50s/it] 55%|█████▌    | 363/656 [24:11<16:58,  3.48s/it] 55%|█████▌    | 364/656 [24:14<16:50,  3.46s/it] 56%|█████▌    | 365/656 [24:18<16:35,  3.42s/it] 56%|█████▌    | 366/656 [24:22<18:10,  3.76s/it] 56%|█████▌    | 367/656 [24:26<17:29,  3.63s/it] 56%|█████▌    | 368/656 [24:29<17:39,  3.68s/it] 56%|█████▋    | 369/656 [24:33<17:12,  3.60s/it] 56%|█████▋    | 370/656 [24:36<17:09,  3.60s/it]                                                 {'loss': 0.0639, 'learning_rate': 4.212949261007519e-06, 'epoch': 1.13}
 56%|█████▋    | 370/656 [24:36<17:09,  3.60s/it] 57%|█████▋    | 371/656 [24:40<16:52,  3.55s/it] 57%|█████▋    | 372/656 [24:43<16:33,  3.50s/it] 57%|█████▋    | 373/656 [24:47<16:40,  3.54s/it] 57%|█████▋    | 374/656 [24:50<16:39,  3.54s/it] 57%|█████▋    | 375/656 [24:54<16:38,  3.55s/it] 57%|█████▋    | 376/656 [24:57<16:32,  3.55s/it] 57%|█████▋    | 377/656 [25:01<16:38,  3.58s/it] 58%|█████▊    | 378/656 [25:04<16:10,  3.49s/it] 58%|█████▊    | 379/656 [25:08<16:00,  3.47s/it] 58%|█████▊    | 380/656 [25:11<16:02,  3.49s/it]                                                 {'loss': 0.0682, 'learning_rate': 3.970106906294509e-06, 'epoch': 1.16}
 58%|█████▊    | 380/656 [25:11<16:02,  3.49s/it] 58%|█████▊    | 381/656 [25:15<15:50,  3.46s/it] 58%|█████▊    | 382/656 [25:18<15:44,  3.45s/it] 58%|█████▊    | 383/656 [25:22<15:41,  3.45s/it] 59%|█████▊    | 384/656 [25:25<15:37,  3.44s/it] 59%|█████▊    | 385/656 [25:28<15:21,  3.40s/it] 59%|█████▉    | 386/656 [25:32<15:32,  3.45s/it] 59%|█████▉    | 387/656 [25:36<15:48,  3.52s/it] 59%|█████▉    | 388/656 [25:39<15:36,  3.49s/it] 59%|█████▉    | 389/656 [25:43<15:45,  3.54s/it] 59%|█████▉    | 390/656 [25:46<15:22,  3.47s/it]                                                 {'loss': 0.0608, 'learning_rate': 3.729776954865905e-06, 'epoch': 1.19}
 59%|█████▉    | 390/656 [25:46<15:22,  3.47s/it] 60%|█████▉    | 391/656 [25:50<15:25,  3.49s/it] 60%|█████▉    | 392/656 [25:53<15:15,  3.47s/it] 60%|█████▉    | 393/656 [25:57<15:21,  3.50s/it] 60%|██████    | 394/656 [26:00<15:04,  3.45s/it] 60%|██████    | 395/656 [26:03<15:06,  3.47s/it] 60%|██████    | 396/656 [26:07<14:56,  3.45s/it] 61%|██████    | 397/656 [26:10<14:49,  3.43s/it] 61%|██████    | 398/656 [26:13<14:35,  3.39s/it] 61%|██████    | 399/656 [26:17<14:41,  3.43s/it] 61%|██████    | 400/656 [26:20<14:39,  3.43s/it]                                                 {'loss': 0.0595, 'learning_rate': 3.492545686756986e-06, 'epoch': 1.22}
 61%|██████    | 400/656 [26:21<14:39,  3.43s/it]***** Running Evaluation *****
  Num examples = 802
  Batch size = 2

  0%|          | 0/101 [00:00<?, ?it/s][A
  2%|▏         | 2/101 [00:00<00:05, 16.78it/s][A
  4%|▍         | 4/101 [00:00<00:09,  9.89it/s][A
  6%|▌         | 6/101 [00:00<00:12,  7.79it/s][A
  7%|▋         | 7/101 [00:00<00:11,  8.04it/s][A
  8%|▊         | 8/101 [00:00<00:11,  8.02it/s][A
  9%|▉         | 9/101 [00:01<00:11,  7.72it/s][A
 11%|█         | 11/101 [00:01<00:10,  8.23it/s][A
 12%|█▏        | 12/101 [00:01<00:10,  8.23it/s][A
 13%|█▎        | 13/101 [00:01<00:10,  8.44it/s][A
 14%|█▍        | 14/101 [00:01<00:10,  7.97it/s][A
 15%|█▍        | 15/101 [00:01<00:10,  7.92it/s][A
 16%|█▌        | 16/101 [00:01<00:10,  7.83it/s][A
 17%|█▋        | 17/101 [00:02<00:10,  7.80it/s][A
 18%|█▊        | 18/101 [00:02<00:10,  8.14it/s][A
 19%|█▉        | 19/101 [00:02<00:09,  8.22it/s][A
 20%|█▉        | 20/101 [00:02<00:10,  7.82it/s][A
 21%|██        | 21/101 [00:02<00:10,  7.44it/s][A
 22%|██▏       | 22/101 [00:02<00:11,  6.64it/s][A
 23%|██▎       | 23/101 [00:02<00:11,  7.05it/s][A
 24%|██▍       | 24/101 [00:03<00:10,  7.39it/s][A
 25%|██▍       | 25/101 [00:03<00:10,  7.43it/s][A
 26%|██▌       | 26/101 [00:03<00:09,  7.66it/s][A
 27%|██▋       | 27/101 [00:03<00:09,  7.70it/s][A
 28%|██▊       | 28/101 [00:03<00:09,  7.61it/s][A
 29%|██▊       | 29/101 [00:03<00:10,  7.15it/s][A
 30%|██▉       | 30/101 [00:03<00:09,  7.43it/s][A
 31%|███       | 31/101 [00:03<00:08,  7.86it/s][A
 32%|███▏      | 32/101 [00:04<00:08,  7.96it/s][A
 33%|███▎      | 33/101 [00:04<00:08,  8.21it/s][A
 34%|███▎      | 34/101 [00:04<00:08,  8.03it/s][A
 35%|███▍      | 35/101 [00:04<00:08,  8.03it/s][A
 36%|███▌      | 36/101 [00:04<00:08,  8.02it/s][A
 37%|███▋      | 37/101 [00:04<00:08,  7.67it/s][A
 38%|███▊      | 38/101 [00:04<00:08,  7.86it/s][A
 39%|███▊      | 39/101 [00:04<00:07,  8.02it/s][A
 40%|███▉      | 40/101 [00:05<00:07,  7.90it/s][A
 41%|████      | 41/101 [00:05<00:07,  8.04it/s][A
 42%|████▏     | 42/101 [00:05<00:07,  7.67it/s][A
 43%|████▎     | 43/101 [00:05<00:07,  7.26it/s][A
 44%|████▎     | 44/101 [00:05<00:07,  7.73it/s][A
 45%|████▍     | 45/101 [00:05<00:07,  7.87it/s][A
 46%|████▌     | 46/101 [00:05<00:07,  7.27it/s][A
 47%|████▋     | 47/101 [00:05<00:07,  7.52it/s][A
 48%|████▊     | 48/101 [00:06<00:17,  3.11it/s][A
 49%|████▊     | 49/101 [00:07<00:21,  2.37it/s][A
 50%|████▉     | 50/101 [00:07<00:17,  2.90it/s][A
 50%|█████     | 51/101 [00:07<00:14,  3.52it/s][A
 51%|█████▏    | 52/101 [00:07<00:11,  4.13it/s][A
 52%|█████▏    | 53/101 [00:08<00:10,  4.72it/s][A
 53%|█████▎    | 54/101 [00:08<00:08,  5.32it/s][A
 54%|█████▍    | 55/101 [00:08<00:08,  5.48it/s][A
 55%|█████▌    | 56/101 [00:08<00:08,  5.34it/s][A
 56%|█████▋    | 57/101 [00:08<00:07,  5.75it/s][A
 57%|█████▋    | 58/101 [00:08<00:06,  6.18it/s][A
 58%|█████▊    | 59/101 [00:09<00:09,  4.42it/s][A
 59%|█████▉    | 60/101 [00:09<00:08,  5.04it/s][A
 60%|██████    | 61/101 [00:09<00:07,  5.38it/s][A
 61%|██████▏   | 62/101 [00:09<00:06,  5.82it/s][A
 62%|██████▏   | 63/101 [00:09<00:06,  6.25it/s][A
 63%|██████▎   | 64/101 [00:09<00:05,  6.56it/s][A
 64%|██████▍   | 65/101 [00:09<00:05,  6.82it/s][A
 65%|██████▌   | 66/101 [00:10<00:05,  6.73it/s][A
 66%|██████▋   | 67/101 [00:10<00:05,  6.80it/s][A
 67%|██████▋   | 68/101 [00:10<00:04,  6.61it/s][A
 68%|██████▊   | 69/101 [00:10<00:04,  6.83it/s][A
 69%|██████▉   | 70/101 [00:10<00:04,  6.33it/s][A
 70%|███████   | 71/101 [00:10<00:04,  6.77it/s][A
 71%|███████▏  | 72/101 [00:11<00:04,  7.02it/s][A
 72%|███████▏  | 73/101 [00:11<00:03,  7.37it/s][A
 73%|███████▎  | 74/101 [00:11<00:04,  6.53it/s][A
 74%|███████▍  | 75/101 [00:11<00:03,  6.62it/s][A
 75%|███████▌  | 76/101 [00:11<00:04,  6.08it/s][A
 76%|███████▌  | 77/101 [00:11<00:03,  6.08it/s][A
 77%|███████▋  | 78/101 [00:11<00:03,  6.35it/s][A
 78%|███████▊  | 79/101 [00:12<00:03,  5.86it/s][A
 79%|███████▉  | 80/101 [00:12<00:03,  6.24it/s][A
 80%|████████  | 81/101 [00:12<00:03,  6.42it/s][A
 81%|████████  | 82/101 [00:12<00:02,  6.39it/s][A
 82%|████████▏ | 83/101 [00:12<00:02,  6.11it/s][A
 83%|████████▎ | 84/101 [00:12<00:02,  5.91it/s][A
 84%|████████▍ | 85/101 [00:13<00:02,  5.98it/s][A
 85%|████████▌ | 86/101 [00:13<00:02,  6.39it/s][A
 86%|████████▌ | 87/101 [00:13<00:02,  6.40it/s][A
 87%|████████▋ | 88/101 [00:13<00:01,  6.57it/s][A
 88%|████████▊ | 89/101 [00:13<00:01,  6.79it/s][A
 89%|████████▉ | 90/101 [00:13<00:01,  7.02it/s][A
 90%|█████████ | 91/101 [00:13<00:01,  7.14it/s][A
 91%|█████████ | 92/101 [00:14<00:01,  7.10it/s][A
 92%|█████████▏| 93/101 [00:14<00:01,  7.59it/s][A
 94%|█████████▍| 95/101 [00:14<00:00,  8.57it/s][A
 96%|█████████▌| 97/101 [00:14<00:00,  9.19it/s][A
 97%|█████████▋| 98/101 [00:14<00:00,  9.32it/s][A
 98%|█████████▊| 99/101 [00:14<00:00,  9.45it/s][A
 99%|█████████▉| 100/101 [00:14<00:00,  9.55it/s][A
100%|██████████| 101/101 [00:15<00:00,  8.65it/s][A                                                 
                                                 [A{'eval_loss': 0.1305738091468811, 'eval_acc': 64.4195, 'eval_precision': 0.6638569604086846, 'eval_recall': 0.6439775561097256, 'eval_f1': 0.6329829051721781, 'eval_runtime': 15.3513, 'eval_samples_per_second': 52.243, 'eval_steps_per_second': 6.579, 'epoch': 1.22}
 61%|██████    | 400/656 [26:36<14:39,  3.43s/it]
100%|██████████| 101/101 [00:15<00:00,  8.65it/s][A
                                                 [A 61%|██████    | 401/656 [26:39<34:01,  8.00s/it] 61%|██████▏   | 402/656 [26:43<28:08,  6.65s/it] 61%|██████▏   | 403/656 [26:46<23:56,  5.68s/it] 62%|██████▏   | 404/656 [26:50<21:09,  5.04s/it] 62%|██████▏   | 405/656 [26:53<18:59,  4.54s/it] 62%|██████▏   | 406/656 [26:56<17:39,  4.24s/it] 62%|██████▏   | 407/656 [27:00<16:25,  3.96s/it] 62%|██████▏   | 408/656 [27:03<15:49,  3.83s/it] 62%|██████▏   | 409/656 [27:07<15:39,  3.81s/it] 62%|██████▎   | 410/656 [27:10<15:08,  3.69s/it]                                                 {'loss': 0.0736, 'learning_rate': 3.258991822828007e-06, 'epoch': 1.25}
 62%|██████▎   | 410/656 [27:11<15:08,  3.69s/it] 63%|██████▎   | 411/656 [27:14<15:27,  3.79s/it] 63%|██████▎   | 412/656 [27:18<14:50,  3.65s/it] 63%|██████▎   | 413/656 [27:21<14:23,  3.55s/it] 63%|██████▎   | 414/656 [27:25<14:09,  3.51s/it] 63%|██████▎   | 415/656 [27:28<14:05,  3.51s/it] 63%|██████▎   | 416/656 [27:32<14:14,  3.56s/it] 64%|██████▎   | 417/656 [27:35<14:00,  3.51s/it] 64%|██████▎   | 418/656 [27:38<13:38,  3.44s/it] 64%|██████▍   | 419/656 [27:42<13:28,  3.41s/it] 64%|██████▍   | 420/656 [27:45<13:47,  3.51s/it]                                                 {'loss': 0.0573, 'learning_rate': 3.029685112986417e-06, 'epoch': 1.28}
 64%|██████▍   | 420/656 [27:46<13:47,  3.51s/it] 64%|██████▍   | 421/656 [27:49<13:37,  3.48s/it] 64%|██████▍   | 422/656 [27:52<13:21,  3.43s/it] 64%|██████▍   | 423/656 [27:56<14:06,  3.63s/it] 65%|██████▍   | 424/656 [28:00<13:41,  3.54s/it] 65%|██████▍   | 425/656 [28:03<13:28,  3.50s/it] 65%|██████▍   | 426/656 [28:07<13:41,  3.57s/it] 65%|██████▌   | 427/656 [28:10<13:34,  3.56s/it] 65%|██████▌   | 428/656 [28:14<14:04,  3.71s/it] 65%|██████▌   | 429/656 [28:18<13:38,  3.61s/it] 66%|██████▌   | 430/656 [28:22<13:55,  3.70s/it]                                                 {'loss': 0.0724, 'learning_rate': 2.805184946293532e-06, 'epoch': 1.31}
 66%|██████▌   | 430/656 [28:22<13:55,  3.70s/it] 66%|██████▌   | 431/656 [28:25<13:22,  3.56s/it] 66%|██████▌   | 432/656 [28:28<13:05,  3.51s/it] 66%|██████▌   | 433/656 [28:32<13:40,  3.68s/it] 66%|██████▌   | 434/656 [28:36<13:35,  3.68s/it] 66%|██████▋   | 435/656 [28:40<13:32,  3.68s/it] 66%|██████▋   | 436/656 [28:43<13:13,  3.60s/it] 67%|██████▋   | 437/656 [28:47<13:08,  3.60s/it] 67%|██████▋   | 438/656 [28:50<12:46,  3.52s/it] 67%|██████▋   | 439/656 [28:53<12:32,  3.47s/it] 67%|██████▋   | 440/656 [28:57<12:37,  3.51s/it]                                                 {'loss': 0.0639, 'learning_rate': 2.5860389863462765e-06, 'epoch': 1.34}
 67%|██████▋   | 440/656 [28:57<12:37,  3.51s/it] 67%|██████▋   | 441/656 [29:00<12:27,  3.48s/it] 67%|██████▋   | 442/656 [29:04<12:22,  3.47s/it] 68%|██████▊   | 443/656 [29:07<12:20,  3.48s/it] 68%|██████▊   | 444/656 [29:11<12:23,  3.51s/it] 68%|██████▊   | 445/656 [29:14<12:18,  3.50s/it] 68%|██████▊   | 446/656 [29:18<12:04,  3.45s/it] 68%|██████▊   | 447/656 [29:22<12:35,  3.62s/it] 68%|██████▊   | 448/656 [29:25<12:17,  3.54s/it] 68%|██████▊   | 449/656 [29:28<11:59,  3.47s/it] 69%|██████▊   | 450/656 [29:32<11:46,  3.43s/it]                                                 {'loss': 0.0738, 'learning_rate': 2.372781835262971e-06, 'epoch': 1.37}
 69%|██████▊   | 450/656 [29:32<11:46,  3.43s/it] 69%|██████▉   | 451/656 [29:35<11:37,  3.40s/it] 69%|██████▉   | 452/656 [29:39<11:49,  3.48s/it] 69%|██████▉   | 453/656 [29:42<11:59,  3.54s/it] 69%|██████▉   | 454/656 [29:46<11:53,  3.53s/it] 69%|██████▉   | 455/656 [29:49<11:44,  3.50s/it] 70%|██████▉   | 456/656 [29:53<11:34,  3.47s/it] 70%|██████▉   | 457/656 [29:57<12:05,  3.64s/it] 70%|██████▉   | 458/656 [30:01<12:13,  3.70s/it] 70%|██████▉   | 459/656 [30:04<11:50,  3.61s/it] 70%|███████   | 460/656 [30:07<11:34,  3.54s/it]                                                 {'loss': 0.0761, 'learning_rate': 2.1659337295323117e-06, 'epoch': 1.4}
 70%|███████   | 460/656 [30:08<11:34,  3.54s/it] 70%|███████   | 461/656 [30:11<11:28,  3.53s/it] 70%|███████   | 462/656 [30:14<11:17,  3.49s/it] 71%|███████   | 463/656 [30:18<11:14,  3.50s/it] 71%|███████   | 464/656 [30:21<11:07,  3.48s/it] 71%|███████   | 465/656 [30:25<11:02,  3.47s/it] 71%|███████   | 466/656 [30:28<11:00,  3.47s/it] 71%|███████   | 467/656 [30:32<10:56,  3.47s/it] 71%|███████▏  | 468/656 [30:35<10:44,  3.43s/it] 71%|███████▏  | 469/656 [30:38<10:34,  3.39s/it] 72%|███████▏  | 470/656 [30:42<10:42,  3.45s/it]                                                 {'loss': 0.0632, 'learning_rate': 1.9659992709070346e-06, 'epoch': 1.43}
 72%|███████▏  | 470/656 [30:42<10:42,  3.45s/it] 72%|███████▏  | 471/656 [30:45<10:38,  3.45s/it] 72%|███████▏  | 472/656 [30:49<10:31,  3.43s/it] 72%|███████▏  | 473/656 [30:52<10:37,  3.48s/it] 72%|███████▏  | 474/656 [30:56<10:25,  3.44s/it] 72%|███████▏  | 475/656 [30:59<10:26,  3.46s/it] 73%|███████▎  | 476/656 [31:03<10:26,  3.48s/it] 73%|███████▎  | 477/656 [31:06<10:29,  3.52s/it] 73%|███████▎  | 478/656 [31:10<10:51,  3.66s/it] 73%|███████▎  | 479/656 [31:14<10:30,  3.56s/it] 73%|███████▎  | 480/656 [31:17<10:21,  3.53s/it]                                                 {'loss': 0.0629, 'learning_rate': 1.7734661954381754e-06, 'epoch': 1.46}
 73%|███████▎  | 480/656 [31:17<10:21,  3.53s/it] 73%|███████▎  | 481/656 [31:21<10:30,  3.60s/it] 73%|███████▎  | 482/656 [31:24<10:15,  3.54s/it] 74%|███████▎  | 483/656 [31:28<10:05,  3.50s/it] 74%|███████▍  | 484/656 [31:31<10:01,  3.50s/it] 74%|███████▍  | 485/656 [31:35<09:49,  3.44s/it] 74%|███████▍  | 486/656 [31:38<09:51,  3.48s/it] 74%|███████▍  | 487/656 [31:42<09:50,  3.49s/it] 74%|███████▍  | 488/656 [31:45<09:40,  3.45s/it] 75%|███████▍  | 489/656 [31:48<09:40,  3.48s/it] 75%|███████▍  | 490/656 [31:52<09:38,  3.48s/it]                                                 {'loss': 0.0555, 'learning_rate': 1.5888041836528917e-06, 'epoch': 1.49}
 75%|███████▍  | 490/656 [31:52<09:38,  3.48s/it] 75%|███████▍  | 491/656 [31:56<09:44,  3.54s/it] 75%|███████▌  | 492/656 [31:59<09:28,  3.47s/it] 75%|███████▌  | 493/656 [32:03<09:33,  3.52s/it] 75%|███████▌  | 494/656 [32:06<09:22,  3.47s/it] 75%|███████▌  | 495/656 [32:09<09:13,  3.44s/it] 76%|███████▌  | 496/656 [32:13<09:13,  3.46s/it] 76%|███████▌  | 497/656 [32:17<09:28,  3.58s/it] 76%|███████▌  | 498/656 [32:20<09:19,  3.54s/it] 76%|███████▌  | 499/656 [32:24<09:17,  3.55s/it] 76%|███████▌  | 500/656 [32:27<09:09,  3.52s/it]                                                 {'loss': 0.0626, 'learning_rate': 1.4124637147783431e-06, 'epoch': 1.52}
 76%|███████▌  | 500/656 [32:27<09:09,  3.52s/it]***** Running Evaluation *****
  Num examples = 802
  Batch size = 2

  0%|          | 0/101 [00:00<?, ?it/s][A
  2%|▏         | 2/101 [00:00<00:05, 16.72it/s][A
  4%|▍         | 4/101 [00:00<00:09,  9.88it/s][A
  6%|▌         | 6/101 [00:00<00:12,  7.78it/s][A
  7%|▋         | 7/101 [00:00<00:11,  8.04it/s][A
  8%|▊         | 8/101 [00:00<00:11,  8.02it/s][A
  9%|▉         | 9/101 [00:01<00:11,  7.73it/s][A
 11%|█         | 11/101 [00:01<00:10,  8.25it/s][A
 12%|█▏        | 12/101 [00:01<00:10,  8.25it/s][A
 13%|█▎        | 13/101 [00:01<00:10,  8.46it/s][A
 14%|█▍        | 14/101 [00:01<00:10,  7.99it/s][A
 15%|█▍        | 15/101 [00:01<00:10,  7.93it/s][A
 16%|█▌        | 16/101 [00:01<00:10,  7.84it/s][A
 17%|█▋        | 17/101 [00:02<00:10,  7.82it/s][A
 18%|█▊        | 18/101 [00:02<00:10,  8.12it/s][A
 19%|█▉        | 19/101 [00:02<00:10,  8.19it/s][A
 20%|█▉        | 20/101 [00:02<00:10,  7.81it/s][A
 21%|██        | 21/101 [00:02<00:10,  7.43it/s][A
 22%|██▏       | 22/101 [00:02<00:11,  6.64it/s][A
 23%|██▎       | 23/101 [00:02<00:11,  7.06it/s][A
 24%|██▍       | 24/101 [00:03<00:10,  7.40it/s][A
 25%|██▍       | 25/101 [00:03<00:10,  7.42it/s][A
 26%|██▌       | 26/101 [00:03<00:09,  7.66it/s][A
 27%|██▋       | 27/101 [00:03<00:09,  7.70it/s][A
 28%|██▊       | 28/101 [00:03<00:09,  7.62it/s][A
 29%|██▊       | 29/101 [00:03<00:10,  7.16it/s][A
 30%|██▉       | 30/101 [00:03<00:09,  7.44it/s][A
 31%|███       | 31/101 [00:03<00:08,  7.84it/s][A
 32%|███▏      | 32/101 [00:04<00:08,  7.94it/s][A
 33%|███▎      | 33/101 [00:04<00:08,  8.20it/s][A
 34%|███▎      | 34/101 [00:04<00:08,  8.04it/s][A
 35%|███▍      | 35/101 [00:04<00:08,  8.06it/s][A
 36%|███▌      | 36/101 [00:04<00:08,  8.04it/s][A
 37%|███▋      | 37/101 [00:04<00:08,  7.69it/s][A
 38%|███▊      | 38/101 [00:04<00:08,  7.86it/s][A
 39%|███▊      | 39/101 [00:04<00:07,  8.05it/s][A
 40%|███▉      | 40/101 [00:05<00:07,  7.91it/s][A
 41%|████      | 41/101 [00:05<00:07,  8.04it/s][A
 42%|████▏     | 42/101 [00:05<00:07,  7.67it/s][A
 43%|████▎     | 43/101 [00:05<00:07,  7.26it/s][A
 44%|████▎     | 44/101 [00:05<00:07,  7.71it/s][A
 45%|████▍     | 45/101 [00:05<00:07,  7.87it/s][A
 46%|████▌     | 46/101 [00:05<00:07,  7.30it/s][A
 47%|████▋     | 47/101 [00:05<00:07,  7.55it/s][A
 48%|████▊     | 48/101 [00:06<00:16,  3.12it/s][A
 49%|████▊     | 49/101 [00:07<00:21,  2.37it/s][A
 50%|████▉     | 50/101 [00:07<00:17,  2.91it/s][A
 50%|█████     | 51/101 [00:07<00:14,  3.52it/s][A
 51%|█████▏    | 52/101 [00:07<00:11,  4.14it/s][A
 52%|█████▏    | 53/101 [00:07<00:10,  4.73it/s][A
 53%|█████▎    | 54/101 [00:08<00:08,  5.33it/s][A
 54%|█████▍    | 55/101 [00:08<00:08,  5.49it/s][A
 55%|█████▌    | 56/101 [00:08<00:08,  5.35it/s][A
 56%|█████▋    | 57/101 [00:08<00:07,  5.77it/s][A
 57%|█████▋    | 58/101 [00:08<00:06,  6.20it/s][A
 58%|█████▊    | 59/101 [00:09<00:09,  4.43it/s][A
 59%|█████▉    | 60/101 [00:09<00:08,  5.05it/s][A
 60%|██████    | 61/101 [00:09<00:07,  5.39it/s][A
 61%|██████▏   | 62/101 [00:09<00:06,  5.83it/s][A
 62%|██████▏   | 63/101 [00:09<00:06,  6.26it/s][A
 63%|██████▎   | 64/101 [00:09<00:05,  6.57it/s][A
 64%|██████▍   | 65/101 [00:09<00:05,  6.83it/s][A
 65%|██████▌   | 66/101 [00:10<00:05,  6.75it/s][A
 66%|██████▋   | 67/101 [00:10<00:04,  6.82it/s][A
 67%|██████▋   | 68/101 [00:10<00:04,  6.62it/s][A
 68%|██████▊   | 69/101 [00:10<00:04,  6.84it/s][A
 69%|██████▉   | 70/101 [00:10<00:04,  6.34it/s][A
 70%|███████   | 71/101 [00:10<00:04,  6.79it/s][A
 71%|███████▏  | 72/101 [00:11<00:04,  7.03it/s][A
 72%|███████▏  | 73/101 [00:11<00:03,  7.35it/s][A
 73%|███████▎  | 74/101 [00:11<00:04,  6.53it/s][A
 74%|███████▍  | 75/101 [00:11<00:03,  6.63it/s][A
 75%|███████▌  | 76/101 [00:11<00:04,  6.09it/s][A
 76%|███████▌  | 77/101 [00:11<00:03,  6.10it/s][A
 77%|███████▋  | 78/101 [00:11<00:03,  6.35it/s][A
 78%|███████▊  | 79/101 [00:12<00:03,  5.87it/s][A
 79%|███████▉  | 80/101 [00:12<00:03,  6.26it/s][A
 80%|████████  | 81/101 [00:12<00:03,  6.43it/s][A
 81%|████████  | 82/101 [00:12<00:02,  6.40it/s][A
 82%|████████▏ | 83/101 [00:12<00:02,  6.11it/s][A
 83%|████████▎ | 84/101 [00:12<00:02,  5.91it/s][A
 84%|████████▍ | 85/101 [00:13<00:02,  5.98it/s][A
 85%|████████▌ | 86/101 [00:13<00:02,  6.39it/s][A
 86%|████████▌ | 87/101 [00:13<00:02,  6.40it/s][A
 87%|████████▋ | 88/101 [00:13<00:01,  6.57it/s][A
 88%|████████▊ | 89/101 [00:13<00:01,  6.79it/s][A
 89%|████████▉ | 90/101 [00:13<00:01,  7.04it/s][A
 90%|█████████ | 91/101 [00:13<00:01,  7.16it/s][A
 91%|█████████ | 92/101 [00:14<00:01,  7.12it/s][A
 92%|█████████▏| 93/101 [00:14<00:01,  7.62it/s][A
 94%|█████████▍| 95/101 [00:14<00:00,  8.59it/s][A
 96%|█████████▌| 97/101 [00:14<00:00,  9.20it/s][A
 97%|█████████▋| 98/101 [00:14<00:00,  9.33it/s][A
 98%|█████████▊| 99/101 [00:14<00:00,  9.44it/s][A
 99%|█████████▉| 100/101 [00:14<00:00,  9.53it/s][A
100%|██████████| 101/101 [00:15<00:00,  8.66it/s][A                                                 
                                                 [A{'eval_loss': 0.15611831843852997, 'eval_acc': 65.6679, 'eval_precision': 0.7234583853145606, 'eval_recall': 0.6563372817955112, 'eval_f1': 0.6286671802643624, 'eval_runtime': 15.3354, 'eval_samples_per_second': 52.297, 'eval_steps_per_second': 6.586, 'epoch': 1.52}
 76%|███████▌  | 500/656 [32:43<09:09,  3.52s/it]
100%|██████████| 101/101 [00:15<00:00,  8.66it/s][A
                                                 [A 76%|███████▋  | 501/656 [32:46<20:54,  8.10s/it] 77%|███████▋  | 502/656 [32:49<17:10,  6.69s/it] 77%|███████▋  | 503/656 [32:53<14:33,  5.71s/it] 77%|███████▋  | 504/656 [32:56<12:41,  5.01s/it] 77%|███████▋  | 505/656 [32:59<11:20,  4.50s/it] 77%|███████▋  | 506/656 [33:03<10:31,  4.21s/it] 77%|███████▋  | 507/656 [33:06<09:54,  3.99s/it] 77%|███████▋  | 508/656 [33:11<10:03,  4.08s/it] 78%|███████▊  | 509/656 [33:14<09:34,  3.91s/it] 78%|███████▊  | 510/656 [33:18<09:22,  3.86s/it]                                                 {'loss': 0.0663, 'learning_rate': 1.2448749678067856e-06, 'epoch': 1.55}
 78%|███████▊  | 510/656 [33:18<09:22,  3.86s/it] 78%|███████▊  | 511/656 [33:22<09:14,  3.83s/it] 78%|███████▊  | 512/656 [33:25<09:02,  3.77s/it] 78%|███████▊  | 513/656 [33:29<08:55,  3.75s/it] 78%|███████▊  | 514/656 [33:32<08:36,  3.64s/it] 79%|███████▊  | 515/656 [33:36<08:17,  3.53s/it] 79%|███████▊  | 516/656 [33:40<08:25,  3.61s/it] 79%|███████▉  | 517/656 [33:43<08:11,  3.54s/it] 79%|███████▉  | 518/656 [33:46<08:07,  3.53s/it] 79%|███████▉  | 519/656 [33:50<08:02,  3.52s/it] 79%|███████▉  | 520/656 [33:56<09:32,  4.21s/it]                                                 {'loss': 0.058, 'learning_rate': 1.0864467720826343e-06, 'epoch': 1.58}
 79%|███████▉  | 520/656 [33:56<09:32,  4.21s/it] 79%|███████▉  | 521/656 [33:59<08:57,  3.98s/it] 80%|███████▉  | 522/656 [34:03<08:35,  3.84s/it] 80%|███████▉  | 523/656 [34:07<08:39,  3.90s/it] 80%|███████▉  | 524/656 [34:10<08:17,  3.77s/it] 80%|████████  | 525/656 [34:14<07:55,  3.63s/it] 80%|████████  | 526/656 [34:17<07:42,  3.56s/it] 80%|████████  | 527/656 [34:21<07:54,  3.68s/it] 80%|████████  | 528/656 [34:24<07:43,  3.62s/it] 81%|████████  | 529/656 [34:28<07:31,  3.55s/it] 81%|████████  | 530/656 [34:31<07:30,  3.58s/it]                                                 {'loss': 0.0935, 'learning_rate': 9.375656099715935e-07, 'epoch': 1.62}
 81%|████████  | 530/656 [34:31<07:30,  3.58s/it] 81%|████████  | 531/656 [34:35<07:16,  3.49s/it] 81%|████████  | 532/656 [34:38<07:10,  3.47s/it] 81%|████████▏ | 533/656 [34:42<07:31,  3.67s/it] 81%|████████▏ | 534/656 [34:46<07:19,  3.60s/it] 82%|████████▏ | 535/656 [34:49<07:17,  3.62s/it] 82%|████████▏ | 536/656 [34:53<07:01,  3.51s/it] 82%|████████▏ | 537/656 [34:56<06:53,  3.47s/it] 82%|████████▏ | 538/656 [34:59<06:48,  3.46s/it] 82%|████████▏ | 539/656 [35:03<06:45,  3.47s/it] 82%|████████▏ | 540/656 [35:06<06:46,  3.50s/it]                                                 {'loss': 0.0649, 'learning_rate': 7.985946740447792e-07, 'epoch': 1.65}
 82%|████████▏ | 540/656 [35:07<06:46,  3.50s/it] 82%|████████▏ | 541/656 [35:10<06:43,  3.51s/it] 83%|████████▎ | 542/656 [35:14<06:42,  3.53s/it] 83%|████████▎ | 543/656 [35:17<06:43,  3.57s/it] 83%|████████▎ | 544/656 [35:21<06:36,  3.54s/it] 83%|████████▎ | 545/656 [35:24<06:40,  3.61s/it] 83%|████████▎ | 546/656 [35:28<06:32,  3.57s/it] 83%|████████▎ | 547/656 [35:31<06:20,  3.49s/it] 84%|████████▎ | 548/656 [35:35<06:09,  3.42s/it] 84%|████████▎ | 549/656 [35:38<06:04,  3.40s/it] 84%|████████▍ | 550/656 [35:41<06:02,  3.42s/it]                                                 {'loss': 0.0595, 'learning_rate': 6.698729810778065e-07, 'epoch': 1.68}
 84%|████████▍ | 550/656 [35:41<06:02,  3.42s/it] 84%|████████▍ | 551/656 [35:45<05:55,  3.39s/it] 84%|████████▍ | 552/656 [35:48<05:58,  3.44s/it] 84%|████████▍ | 553/656 [35:52<05:58,  3.48s/it] 84%|████████▍ | 554/656 [35:55<05:49,  3.43s/it] 85%|████████▍ | 555/656 [35:59<05:52,  3.49s/it] 85%|████████▍ | 556/656 [36:02<05:44,  3.45s/it] 85%|████████▍ | 557/656 [36:05<05:39,  3.43s/it] 85%|████████▌ | 558/656 [36:09<05:36,  3.43s/it] 85%|████████▌ | 559/656 [36:12<05:33,  3.44s/it] 85%|████████▌ | 560/656 [36:16<05:30,  3.44s/it]                                                 {'loss': 0.0484, 'learning_rate': 5.517145450262639e-07, 'epoch': 1.71}
 85%|████████▌ | 560/656 [36:16<05:30,  3.44s/it] 86%|████████▌ | 561/656 [36:19<05:28,  3.46s/it] 86%|████████▌ | 562/656 [36:23<05:30,  3.52s/it] 86%|████████▌ | 563/656 [36:26<05:20,  3.44s/it] 86%|████████▌ | 564/656 [36:30<05:20,  3.48s/it] 86%|████████▌ | 565/656 [36:33<05:19,  3.51s/it] 86%|████████▋ | 566/656 [36:37<05:10,  3.45s/it] 86%|████████▋ | 567/656 [36:40<05:03,  3.41s/it] 87%|████████▋ | 568/656 [36:44<05:02,  3.43s/it] 87%|████████▋ | 569/656 [36:47<05:03,  3.49s/it] 87%|████████▋ | 570/656 [36:50<04:55,  3.44s/it]                                                 {'loss': 0.0688, 'learning_rate': 4.444076109950346e-07, 'epoch': 1.74}
 87%|████████▋ | 570/656 [36:51<04:55,  3.44s/it] 87%|████████▋ | 571/656 [36:54<04:53,  3.46s/it] 87%|████████▋ | 572/656 [36:57<04:48,  3.44s/it] 87%|████████▋ | 573/656 [37:01<04:48,  3.47s/it] 88%|████████▊ | 574/656 [37:04<04:46,  3.49s/it] 88%|████████▊ | 575/656 [37:08<04:40,  3.46s/it] 88%|████████▊ | 576/656 [37:11<04:34,  3.43s/it] 88%|████████▊ | 577/656 [37:15<04:38,  3.52s/it] 88%|████████▊ | 578/656 [37:18<04:31,  3.48s/it] 88%|████████▊ | 579/656 [37:22<04:30,  3.51s/it] 88%|████████▊ | 580/656 [37:25<04:27,  3.52s/it]                                                 {'loss': 0.0633, 'learning_rate': 3.4821395207022767e-07, 'epoch': 1.77}
 88%|████████▊ | 580/656 [37:26<04:27,  3.52s/it] 89%|████████▊ | 581/656 [37:29<04:25,  3.55s/it] 89%|████████▊ | 582/656 [37:32<04:20,  3.52s/it] 89%|████████▉ | 583/656 [37:36<04:12,  3.46s/it] 89%|████████▉ | 584/656 [37:40<04:20,  3.62s/it] 89%|████████▉ | 585/656 [37:44<04:23,  3.72s/it] 89%|████████▉ | 586/656 [37:47<04:12,  3.61s/it] 89%|████████▉ | 587/656 [37:51<04:13,  3.68s/it] 90%|████████▉ | 588/656 [37:54<04:02,  3.57s/it] 90%|████████▉ | 589/656 [37:58<03:56,  3.53s/it] 90%|████████▉ | 590/656 [38:01<03:49,  3.48s/it]                                                 {'loss': 0.058, 'learning_rate': 2.6336823072904305e-07, 'epoch': 1.8}
 90%|████████▉ | 590/656 [38:01<03:49,  3.48s/it] 90%|█████████ | 591/656 [38:04<03:43,  3.45s/it] 90%|█████████ | 592/656 [38:08<03:40,  3.44s/it] 90%|█████████ | 593/656 [38:11<03:36,  3.44s/it] 91%|█████████ | 594/656 [38:15<03:33,  3.44s/it] 91%|█████████ | 595/656 [38:19<03:35,  3.54s/it] 91%|█████████ | 596/656 [38:22<03:30,  3.51s/it] 91%|█████████ | 597/656 [38:26<03:31,  3.58s/it] 91%|█████████ | 598/656 [38:29<03:26,  3.56s/it] 91%|█████████▏| 599/656 [38:33<03:22,  3.55s/it] 91%|█████████▏| 600/656 [38:36<03:17,  3.53s/it]                                                 {'loss': 0.0712, 'learning_rate': 1.9007742638543104e-07, 'epoch': 1.83}
 91%|█████████▏| 600/656 [38:36<03:17,  3.53s/it]***** Running Evaluation *****
  Num examples = 802
  Batch size = 2

  0%|          | 0/101 [00:00<?, ?it/s][A
  2%|▏         | 2/101 [00:00<00:05, 16.69it/s][A
  4%|▍         | 4/101 [00:00<00:09,  9.90it/s][A
  6%|▌         | 6/101 [00:00<00:12,  7.77it/s][A
  7%|▋         | 7/101 [00:00<00:11,  8.04it/s][A
  8%|▊         | 8/101 [00:00<00:11,  8.02it/s][A
  9%|▉         | 9/101 [00:01<00:11,  7.72it/s][A
 11%|█         | 11/101 [00:01<00:10,  8.23it/s][A
 12%|█▏        | 12/101 [00:01<00:10,  8.23it/s][A
 13%|█▎        | 13/101 [00:01<00:10,  8.44it/s][A
 14%|█▍        | 14/101 [00:01<00:10,  7.98it/s][A
 15%|█▍        | 15/101 [00:01<00:10,  7.93it/s][A
 16%|█▌        | 16/101 [00:01<00:10,  7.82it/s][A
 17%|█▋        | 17/101 [00:02<00:10,  7.79it/s][A
 18%|█▊        | 18/101 [00:02<00:10,  8.14it/s][A
 19%|█▉        | 19/101 [00:02<00:09,  8.24it/s][A
 20%|█▉        | 20/101 [00:02<00:10,  7.86it/s][A
 21%|██        | 21/101 [00:02<00:10,  7.45it/s][A
 22%|██▏       | 22/101 [00:02<00:11,  6.65it/s][A
 23%|██▎       | 23/101 [00:02<00:11,  7.08it/s][A
 24%|██▍       | 24/101 [00:03<00:10,  7.41it/s][A
 25%|██▍       | 25/101 [00:03<00:10,  7.44it/s][A
 26%|██▌       | 26/101 [00:03<00:09,  7.67it/s][A
 27%|██▋       | 27/101 [00:03<00:09,  7.72it/s][A
 28%|██▊       | 28/101 [00:03<00:09,  7.64it/s][A
 29%|██▊       | 29/101 [00:03<00:10,  7.16it/s][A
 30%|██▉       | 30/101 [00:03<00:09,  7.44it/s][A
 31%|███       | 31/101 [00:03<00:08,  7.85it/s][A
 32%|███▏      | 32/101 [00:04<00:08,  7.96it/s][A
 33%|███▎      | 33/101 [00:04<00:08,  8.23it/s][A
 34%|███▎      | 34/101 [00:04<00:08,  8.05it/s][A
 35%|███▍      | 35/101 [00:04<00:08,  8.06it/s][A
 36%|███▌      | 36/101 [00:04<00:08,  8.05it/s][A
 37%|███▋      | 37/101 [00:04<00:08,  7.69it/s][A
 38%|███▊      | 38/101 [00:04<00:08,  7.86it/s][A
 39%|███▊      | 39/101 [00:04<00:07,  8.03it/s][A
 40%|███▉      | 40/101 [00:05<00:07,  7.90it/s][A
 41%|████      | 41/101 [00:05<00:07,  8.02it/s][A
 42%|████▏     | 42/101 [00:05<00:07,  7.65it/s][A
 43%|████▎     | 43/101 [00:05<00:08,  7.24it/s][A
 44%|████▎     | 44/101 [00:05<00:07,  7.70it/s][A
 45%|████▍     | 45/101 [00:05<00:07,  7.84it/s][A
 46%|████▌     | 46/101 [00:05<00:07,  7.26it/s][A
 47%|████▋     | 47/101 [00:05<00:07,  7.52it/s][A
 48%|████▊     | 48/101 [00:06<00:17,  3.11it/s][A
 49%|████▊     | 49/101 [00:07<00:21,  2.37it/s][A
 50%|████▉     | 50/101 [00:07<00:17,  2.91it/s][A
 50%|█████     | 51/101 [00:07<00:14,  3.52it/s][A
 51%|█████▏    | 52/101 [00:07<00:11,  4.13it/s][A
 52%|█████▏    | 53/101 [00:07<00:10,  4.72it/s][A
 53%|█████▎    | 54/101 [00:08<00:08,  5.32it/s][A
 54%|█████▍    | 55/101 [00:08<00:08,  5.48it/s][A
 55%|█████▌    | 56/101 [00:08<00:08,  5.34it/s][A
 56%|█████▋    | 57/101 [00:08<00:07,  5.76it/s][A
 57%|█████▋    | 58/101 [00:08<00:06,  6.20it/s][A
 58%|█████▊    | 59/101 [00:09<00:09,  4.42it/s][A
 59%|█████▉    | 60/101 [00:09<00:08,  5.05it/s][A
 60%|██████    | 61/101 [00:09<00:07,  5.39it/s][A
 61%|██████▏   | 62/101 [00:09<00:06,  5.83it/s][A
 62%|██████▏   | 63/101 [00:09<00:06,  6.27it/s][A
 63%|██████▎   | 64/101 [00:09<00:05,  6.58it/s][A
 64%|██████▍   | 65/101 [00:09<00:05,  6.83it/s][A
 65%|██████▌   | 66/101 [00:10<00:05,  6.75it/s][A
 66%|██████▋   | 67/101 [00:10<00:04,  6.84it/s][A
 67%|██████▋   | 68/101 [00:10<00:04,  6.64it/s][A
 68%|██████▊   | 69/101 [00:10<00:04,  6.85it/s][A
 69%|██████▉   | 70/101 [00:10<00:04,  6.34it/s][A
 70%|███████   | 71/101 [00:10<00:04,  6.78it/s][A
 71%|███████▏  | 72/101 [00:11<00:04,  7.03it/s][A
 72%|███████▏  | 73/101 [00:11<00:03,  7.36it/s][A
 73%|███████▎  | 74/101 [00:11<00:04,  6.53it/s][A
 74%|███████▍  | 75/101 [00:11<00:03,  6.61it/s][A
 75%|███████▌  | 76/101 [00:11<00:04,  6.08it/s][A
 76%|███████▌  | 77/101 [00:11<00:03,  6.09it/s][A
 77%|███████▋  | 78/101 [00:11<00:03,  6.35it/s][A
 78%|███████▊  | 79/101 [00:12<00:03,  5.87it/s][A
 79%|███████▉  | 80/101 [00:12<00:03,  6.26it/s][A
 80%|████████  | 81/101 [00:12<00:03,  6.42it/s][A
 81%|████████  | 82/101 [00:12<00:02,  6.40it/s][A
 82%|████████▏ | 83/101 [00:12<00:02,  6.10it/s][A
 83%|████████▎ | 84/101 [00:12<00:02,  5.89it/s][A
 84%|████████▍ | 85/101 [00:13<00:02,  5.97it/s][A
 85%|████████▌ | 86/101 [00:13<00:02,  6.37it/s][A
 86%|████████▌ | 87/101 [00:13<00:02,  6.38it/s][A
 87%|████████▋ | 88/101 [00:13<00:01,  6.55it/s][A
 88%|████████▊ | 89/101 [00:13<00:01,  6.78it/s][A
 89%|████████▉ | 90/101 [00:13<00:01,  7.02it/s][A
 90%|█████████ | 91/101 [00:13<00:01,  7.15it/s][A
 91%|█████████ | 92/101 [00:14<00:01,  7.10it/s][A
 92%|█████████▏| 93/101 [00:14<00:01,  7.61it/s][A
 94%|█████████▍| 95/101 [00:14<00:00,  8.57it/s][A
 96%|█████████▌| 97/101 [00:14<00:00,  9.22it/s][A
 97%|█████████▋| 98/101 [00:14<00:00,  9.35it/s][A
 98%|█████████▊| 99/101 [00:14<00:00,  9.49it/s][A
 99%|█████████▉| 100/101 [00:14<00:00,  9.58it/s][A
100%|██████████| 101/101 [00:15<00:00,  8.68it/s][A                                                 
                                                 [A{'eval_loss': 0.1250610053539276, 'eval_acc': 67.166, 'eval_precision': 0.6858949232266436, 'eval_recall': 0.6714869077306733, 'eval_f1': 0.6651130183751235, 'eval_runtime': 15.3396, 'eval_samples_per_second': 52.283, 'eval_steps_per_second': 6.584, 'epoch': 1.83}
 91%|█████████▏| 600/656 [38:52<03:17,  3.53s/it]
100%|██████████| 101/101 [00:15<00:00,  8.68it/s][A
                                                 [A 92%|█████████▏| 601/656 [38:55<07:24,  8.08s/it] 92%|█████████▏| 602/656 [38:58<06:01,  6.70s/it] 92%|█████████▏| 603/656 [39:02<05:04,  5.74s/it] 92%|█████████▏| 604/656 [39:05<04:20,  5.01s/it] 92%|█████████▏| 605/656 [39:09<03:50,  4.53s/it] 92%|█████████▏| 606/656 [39:12<03:29,  4.19s/it] 93%|█████████▎| 607/656 [39:16<03:15,  3.98s/it] 93%|█████████▎| 608/656 [39:19<03:06,  3.88s/it] 93%|█████████▎| 609/656 [39:23<02:59,  3.82s/it] 93%|█████████▎| 610/656 [39:27<03:01,  3.95s/it]                                                 {'loss': 0.068, 'learning_rate': 1.2852033046801106e-07, 'epoch': 1.86}
 93%|█████████▎| 610/656 [39:27<03:01,  3.95s/it] 93%|█████████▎| 611/656 [39:31<02:51,  3.81s/it] 93%|█████████▎| 612/656 [39:34<02:43,  3.72s/it] 93%|█████████▎| 613/656 [39:38<02:45,  3.84s/it] 94%|█████████▎| 614/656 [39:42<02:38,  3.77s/it] 94%|█████████▍| 615/656 [39:45<02:31,  3.69s/it] 94%|█████████▍| 616/656 [39:49<02:27,  3.69s/it] 94%|█████████▍| 617/656 [39:52<02:21,  3.62s/it] 94%|█████████▍| 618/656 [39:56<02:14,  3.54s/it] 94%|█████████▍| 619/656 [39:59<02:12,  3.57s/it] 95%|█████████▍| 620/656 [40:03<02:08,  3.56s/it]                                                 {'loss': 0.0605, 'learning_rate': 7.884711026201586e-08, 'epoch': 1.89}
 95%|█████████▍| 620/656 [40:03<02:08,  3.56s/it] 95%|█████████▍| 621/656 [40:07<02:04,  3.56s/it] 95%|█████████▍| 622/656 [40:10<02:02,  3.59s/it] 95%|█████████▍| 623/656 [40:14<01:56,  3.53s/it] 95%|█████████▌| 624/656 [40:17<01:52,  3.52s/it] 95%|█████████▌| 625/656 [40:20<01:47,  3.45s/it] 95%|█████████▌| 626/656 [40:24<01:43,  3.45s/it] 96%|█████████▌| 627/656 [40:27<01:39,  3.44s/it] 96%|█████████▌| 628/656 [40:31<01:36,  3.45s/it] 96%|█████████▌| 629/656 [40:34<01:33,  3.46s/it] 96%|█████████▌| 630/656 [40:38<01:31,  3.53s/it]                                                 {'loss': 0.058, 'learning_rate': 4.1178942579248036e-08, 'epoch': 1.92}
 96%|█████████▌| 630/656 [40:38<01:31,  3.53s/it] 96%|█████████▌| 631/656 [40:41<01:28,  3.52s/it] 96%|█████████▋| 632/656 [40:45<01:23,  3.50s/it] 96%|█████████▋| 633/656 [40:49<01:22,  3.61s/it] 97%|█████████▋| 634/656 [40:52<01:19,  3.62s/it] 97%|█████████▋| 635/656 [40:56<01:14,  3.55s/it] 97%|█████████▋| 636/656 [40:59<01:10,  3.54s/it] 97%|█████████▋| 637/656 [41:03<01:06,  3.49s/it] 97%|█████████▋| 638/656 [41:06<01:01,  3.43s/it] 97%|█████████▋| 639/656 [41:10<00:59,  3.49s/it] 98%|█████████▊| 640/656 [41:13<00:56,  3.53s/it]                                                 {'loss': 0.0712, 'learning_rate': 1.560771814970885e-08, 'epoch': 1.95}
 98%|█████████▊| 640/656 [41:13<00:56,  3.53s/it] 98%|█████████▊| 641/656 [41:17<00:52,  3.52s/it] 98%|█████████▊| 642/656 [41:20<00:48,  3.48s/it] 98%|█████████▊| 643/656 [41:24<00:45,  3.49s/it] 98%|█████████▊| 644/656 [41:27<00:42,  3.50s/it] 98%|█████████▊| 645/656 [41:31<00:39,  3.56s/it] 98%|█████████▊| 646/656 [41:34<00:35,  3.58s/it] 99%|█████████▊| 647/656 [41:38<00:32,  3.58s/it] 99%|█████████▉| 648/656 [41:42<00:30,  3.78s/it] 99%|█████████▉| 649/656 [41:46<00:25,  3.65s/it] 99%|█████████▉| 650/656 [41:49<00:21,  3.55s/it]                                                 {'loss': 0.0618, 'learning_rate': 2.19581745602826e-09, 'epoch': 1.98}
 99%|█████████▉| 650/656 [41:49<00:21,  3.55s/it] 99%|█████████▉| 651/656 [41:52<00:17,  3.53s/it] 99%|█████████▉| 652/656 [41:56<00:14,  3.57s/it]100%|█████████▉| 653/656 [42:00<00:10,  3.54s/it]100%|█████████▉| 654/656 [42:03<00:06,  3.49s/it]100%|█████████▉| 655/656 [42:07<00:03,  3.55s/it]100%|██████████| 656/656 [42:10<00:00,  3.51s/it]Saving model checkpoint to /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-656
Configuration saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-656/config.json
Configuration saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-656/generation_config.json
Model weights saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-656/pytorch_model.bin
tokenizer config file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-656/tokenizer_config.json
Special tokens file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-656/special_tokens_map.json
added tokens file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/checkpoint-656/added_tokens.json


Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 2656.0464, 'train_samples_per_second': 7.906, 'train_steps_per_second': 0.247, 'train_loss': 0.09000795579901556, 'epoch': 2.0}
100%|██████████| 656/656 [44:06<00:00,  3.51s/it]100%|██████████| 656/656 [44:06<00:00,  4.03s/it]
Saving model checkpoint to /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8
Configuration saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/config.json
Configuration saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/generation_config.json
Model weights saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/pytorch_model.bin
tokenizer config file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/tokenizer_config.json
Special tokens file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/special_tokens_map.json
added tokens file saved in /ML-A100/home/xiangyue/lyf/AttributionBench/checkpoints/llama2_7b-v2.2-template-base_llama-bs32-lr1e-5-gas8/added_tokens.json
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                       eval/acc ▅▆▁▇▇█
wandb:                        eval/f1 ▃▄▁▇▆█
wandb:                      eval/loss ▅▁▄▃█▂
wandb:                 eval/precision ▇▇▁▆█▇
wandb:                    eval/recall ▅▆▁▇▇█
wandb:                   eval/runtime ▃█▁▃▁▂
wandb:        eval/samples_per_second ▆▁█▆█▇
wandb:          eval/steps_per_second ▇▁█▆█▇
wandb:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train/learning_rate ▄███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁
wandb:                     train/loss █▂▂▂▂▂▁▂▂▁▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                       eval/acc 67.166
wandb:                        eval/f1 0.66511
wandb:                      eval/loss 0.12506
wandb:                 eval/precision 0.68589
wandb:                    eval/recall 0.67149
wandb:                   eval/runtime 15.3396
wandb:        eval/samples_per_second 52.283
wandb:          eval/steps_per_second 6.584
wandb:                    train/epoch 2.0
wandb:              train/global_step 656
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0618
wandb:               train/total_flos 5.675088806831718e+16
wandb:               train/train_loss 0.09001
wandb:            train/train_runtime 2656.0464
wandb: train/train_samples_per_second 7.906
wandb:   train/train_steps_per_second 0.247
wandb: 
wandb: 🚀 View run llama2_7b_template-base_llama-bs32-lr1e-5-gas8_dataset_v2.2_2023-10-19-17:20:03 at: https://wandb.ai/flyhero99/attribution-eval-v2.0/runs/9tsm8ipl
wandb: ️⚡ View job at https://wandb.ai/flyhero99/attribution-eval-v2.0/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNzk4Nzk1OQ==/version_details/v3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231019_172136-9tsm8ipl/logs
