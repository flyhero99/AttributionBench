{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import utils\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import uuid\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttributedQA\n",
    "Only pick those data items with human_rating\n",
    "Divide into train / dev / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of filtered_df:  21189\n",
      "len of question_grouped_df:  1000\n",
      "21.189\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../raw_data/AttributedQA/ratings.csv\", index_col=0)\n",
    "\n",
    "filtered_df = df[df['human_rating'].isin(['Y', 'N'])]\n",
    "print(\"len of filtered_df: \", len(filtered_df))\n",
    "\n",
    "# 随机排列 DataFrame 的行\n",
    "shuffled_df = filtered_df.sample(frac=1, random_state=42)\n",
    "\n",
    "# 重置索引，以确保索引是连续的\n",
    "shuffled_df = shuffled_df.reset_index(drop=True)\n",
    "\n",
    "question_grouped_df = shuffled_df.groupby('question')\n",
    "question_grouped_df.head()\n",
    "print(\"len of question_grouped_df: \", len(question_grouped_df))\n",
    "print(question_grouped_df.size().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>passage</th>\n",
       "      <th>nli_score</th>\n",
       "      <th>human_rating</th>\n",
       "      <th>auto_ais</th>\n",
       "      <th>system_name</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who played hyde in league of extraordinary gen...</td>\n",
       "      <td>Jason Flemyng</td>\n",
       "      <td>Title: Jason Flemyng\\nSection: Television and ...</td>\n",
       "      <td>0.981469</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Post-4</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who played hyde in league of extraordinary gen...</td>\n",
       "      <td>Jason Flemyng</td>\n",
       "      <td>Title: Jason Flemyng\\nSection: Television and ...</td>\n",
       "      <td>0.981469</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>RTR+auto_ais_reranking</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who played hyde in league of extraordinary gen...</td>\n",
       "      <td>Jason Flemyng</td>\n",
       "      <td>Title: Jason Flemyng\\nSection: Television and ...</td>\n",
       "      <td>0.981469</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Post-2</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who played hyde in league of extraordinary gen...</td>\n",
       "      <td>Jason Flemyng</td>\n",
       "      <td>Title: Jason Flemyng\\nSection: Television and ...</td>\n",
       "      <td>0.981469</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Post-3</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who played hyde in league of extraordinary gen...</td>\n",
       "      <td>Jason Flemyng</td>\n",
       "      <td>Title: Jason Flemyng\\nSection: Television and ...</td>\n",
       "      <td>0.981469</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Post+auto_ais_reranking</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question         answer  \\\n",
       "0  who played hyde in league of extraordinary gen...  Jason Flemyng   \n",
       "1  who played hyde in league of extraordinary gen...  Jason Flemyng   \n",
       "2  who played hyde in league of extraordinary gen...  Jason Flemyng   \n",
       "3  who played hyde in league of extraordinary gen...  Jason Flemyng   \n",
       "4  who played hyde in league of extraordinary gen...  Jason Flemyng   \n",
       "\n",
       "                                             passage  nli_score human_rating  \\\n",
       "0  Title: Jason Flemyng\\nSection: Television and ...   0.981469            Y   \n",
       "1  Title: Jason Flemyng\\nSection: Television and ...   0.981469            Y   \n",
       "2  Title: Jason Flemyng\\nSection: Television and ...   0.981469            Y   \n",
       "3  Title: Jason Flemyng\\nSection: Television and ...   0.981469            Y   \n",
       "4  Title: Jason Flemyng\\nSection: Television and ...   0.981469            Y   \n",
       "\n",
       "  auto_ais              system_name  \\\n",
       "0        Y                   Post-4   \n",
       "1        Y   RTR+auto_ais_reranking   \n",
       "2        Y                   Post-2   \n",
       "3        Y                   Post-3   \n",
       "4        Y  Post+auto_ais_reranking   \n",
       "\n",
       "                                         attribution  \n",
       "0  http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...  \n",
       "1  http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...  \n",
       "2  http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...  \n",
       "3  http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...  \n",
       "4  http://en.wikipedia.org/wiki/Jason_Flemyng#Jas...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: who played hyde in league of extraordinary gentlemen\n",
      "answer: Jason Flemyng\n",
      "passage: Title: Jason Flemyng\n",
      "Section: Television and film work\n",
      "\n",
      "In the early 2000s he featured in two big-budget Hollywood films which were adaptations of Alan Moore comic books; as John Netley in 2001's From Hell, with Johnny Depp, and 2003's The League of Extraordinary Gentlemen, with Sean Connery, in which Flemyng played Dr. Henry Jekyll and Edward Hyde. The latter film was a disappointment, but Flemyng commented that: \"It was a bit of a nightmare... the film cost a fortune and didn't make back the money it was meant to... But I still get a huge kick out of doing films like that and From Hell. Any day you walk onto a set and Sean Connery or Johnny Depp or Brad Pitt is there has to be a good day.\"\n",
      "label: Y\n",
      "question: who played hyde in league of extraordinary gentlemen\n",
      "answer: Jason Flemyng\n",
      "passage: Title: Jason Flemyng\n",
      "Section: Television and film work\n",
      "\n",
      "In the early 2000s he featured in two big-budget Hollywood films which were adaptations of Alan Moore comic books; as John Netley in 2001's From Hell, with Johnny Depp, and 2003's The League of Extraordinary Gentlemen, with Sean Connery, in which Flemyng played Dr. Henry Jekyll and Edward Hyde. The latter film was a disappointment, but Flemyng commented that: \"It was a bit of a nightmare... the film cost a fortune and didn't make back the money it was meant to... But I still get a huge kick out of doing films like that and From Hell. Any day you walk onto a set and Sean Connery or Johnny Depp or Brad Pitt is there has to be a good day.\"\n",
      "label: Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: AttributedQA, total items: 21189, total unique <question, claim, references> pairs: 9432\n"
     ]
    }
   ],
   "source": [
    "seen = set()\n",
    "unique_data = []\n",
    "cnt = 0\n",
    "for i in range(len(filtered_df)):\n",
    "    item = filtered_df.iloc[i]\n",
    "    key = item[\"question\"] + str(item[\"answer\"]) + item[\"passage\"]\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        unique_data.append(item)\n",
    "    else:\n",
    "        if cnt < 2:\n",
    "            print(\"question:\", item[\"question\"])\n",
    "            print(\"answer:\", item[\"answer\"])\n",
    "            print(\"passage:\", item[\"passage\"])\n",
    "            print(\"label:\", item[\"human_rating\"])\n",
    "            cnt += 1\n",
    "print(f\"Dataset Name: AttributedQA, total items: {len(filtered_df)}, total unique <question, claim, references> pairs: {len(unique_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size: 18024\n",
      "Dev Data Size: 1070\n",
      "Test Data Size: 2095\n",
      "Question Overlap between Train and Test: 0\n",
      "Question Overlap between Train and Dev: 0\n",
      "Question Overlap between Test and Dev: 0\n"
     ]
    }
   ],
   "source": [
    "# 定义比例\n",
    "train_ratio = 0.85\n",
    "dev_ratio = 0.05\n",
    "\n",
    "# 创建用于存储划分后数据的新 DataFrame\n",
    "train_data = pd.DataFrame(columns=shuffled_df.columns)\n",
    "dev_data = pd.DataFrame(columns=shuffled_df.columns)\n",
    "test_data = pd.DataFrame(columns=shuffled_df.columns)\n",
    "\n",
    "total_count = len(shuffled_df)\n",
    "\n",
    "# 遍历分组\n",
    "for name, group in question_grouped_df:\n",
    "    # 计算划分数量\n",
    "    train_count = int(train_ratio * total_count)\n",
    "    dev_count = int(dev_ratio * total_count)\n",
    "    test_count = total_count - train_count - dev_count\n",
    "    \n",
    "    # 将数据添加到相应的集合中\n",
    "    if len(train_data) < train_count:\n",
    "        train_data = pd.concat([train_data, group])\n",
    "    elif len(dev_data) < dev_count:\n",
    "        dev_data = pd.concat([dev_data, group])\n",
    "    else:\n",
    "        test_data = pd.concat([test_data, group])\n",
    "\n",
    "# 确保数据集的索引是连续的\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "dev_data = dev_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "# 打印划分后的数据集大小\n",
    "print(\"Train Data Size:\", len(train_data))\n",
    "print(\"Dev Data Size:\", len(dev_data))\n",
    "print(\"Test Data Size:\", len(test_data))\n",
    "\n",
    "# 假设 train_data、test_data 和 dev_data 是包含数据的 DataFrame\n",
    "# 请将以下代码中的变量名替换为您的实际变量名\n",
    "\n",
    "# 提取每个数据集中的 question 列，并转换为集合\n",
    "train_questions = set(train_data['question'])\n",
    "test_questions = set(test_data['question'])\n",
    "dev_questions = set(dev_data['question'])\n",
    "\n",
    "# 计算 question 重叠数量\n",
    "overlap_train_test = len(train_questions.intersection(test_questions))\n",
    "overlap_train_dev = len(train_questions.intersection(dev_questions))\n",
    "overlap_test_dev = len(test_questions.intersection(dev_questions))\n",
    "\n",
    "# 打印重叠数量\n",
    "print(\"Question Overlap between Train and Test:\", overlap_train_test)\n",
    "print(\"Question Overlap between Train and Dev:\", overlap_train_dev)\n",
    "print(\"Question Overlap between Test and Dev:\", overlap_test_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_data = train_data.sample(frac=1, random_state=42)\n",
    "shuffled_dev_data = dev_data.sample(frac=1, random_state=42)\n",
    "shuffled_test_data = test_data.sample(frac=1, random_state=42)\n",
    "\n",
    "shuffled_train_data.to_csv(\"../our_data/AttributedQA/train.csv\")\n",
    "shuffled_dev_data.to_csv(\"../our_data/AttributedQA/dev.csv\")\n",
    "shuffled_test_data.to_csv(\"../our_data/AttributedQA/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExpertQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2177\n",
      "2177\n",
      "Train Data Size: 1850\n",
      "Dev Data Size: 108\n",
      "Test Data Size: 219\n",
      "Question Overlap between Train and Dev: set()\n",
      "Question Overlap between Train and Test: set()\n",
      "Question Overlap between Dev and Test: set()\n"
     ]
    }
   ],
   "source": [
    "data = [json.loads(line) for line in open(\"../raw_data/ExpertQA/r2_compiled_anon.jsonl\", 'r')]\n",
    "question_to_data = {x[\"question\"]: [] for x in data}\n",
    "for x in data:\n",
    "    question_to_data[x[\"question\"]].append(x)\n",
    "print(len(data))\n",
    "print(len(question_to_data))\n",
    "\n",
    "shuffled_question_to_data = list(question_to_data.items())\n",
    "random.shuffle(shuffled_question_to_data)\n",
    "\n",
    "total_count = len(shuffled_question_to_data)\n",
    "train_count = int(0.85 * total_count)\n",
    "dev_count = int(0.05 * total_count)\n",
    "test_count = total_count - train_count - dev_count\n",
    "\n",
    "# 划分数据集\n",
    "train_dict = dict(shuffled_question_to_data[:train_count])\n",
    "dev_dict = dict(shuffled_question_to_data[train_count:train_count+dev_count])\n",
    "test_dict = dict(shuffled_question_to_data[train_count+dev_count:])\n",
    "\n",
    "# 打印划分后的数据集大小\n",
    "print(\"Train Data Size:\", len(train_dict))\n",
    "print(\"Dev Data Size:\", len(dev_dict))\n",
    "print(\"Test Data Size:\", len(test_dict))\n",
    "\n",
    "# 假设 train_dict、dev_dict 和 test_dict 分别是包含数据的字典\n",
    "# 请将以下代码中的变量名替换为您的实际字典变量\n",
    "\n",
    "# 创建集合来存储各个数据集中的 \"question\" 值\n",
    "train_questions = set(train_dict.keys())\n",
    "dev_questions = set(dev_dict.keys())\n",
    "test_questions = set(test_dict.keys())\n",
    "\n",
    "# 检查是否有 \"question\" 重叠\n",
    "overlap_train_dev = train_questions.intersection(dev_questions)\n",
    "overlap_train_test = train_questions.intersection(test_questions)\n",
    "overlap_dev_test = dev_questions.intersection(test_questions)\n",
    "\n",
    "# 打印重叠情况\n",
    "print(\"Question Overlap between Train and Dev:\", overlap_train_dev)\n",
    "print(\"Question Overlap between Train and Test:\", overlap_train_test)\n",
    "print(\"Question Overlap between Dev and Test:\", overlap_dev_test)\n",
    "\n",
    "# 随机打乱 train_dict 中的元素\n",
    "shuffled_train_data = []\n",
    "for k in train_dict.keys():\n",
    "    for x in train_dict[k]:\n",
    "        shuffled_train_data.append(x)\n",
    "random.shuffle(shuffled_train_data)\n",
    "\n",
    "# 指定保存 train 数据的文件名，例如 \"shuffled_train_data.jsonl\"\n",
    "train_output_file = \"../our_data/ExpertQA/train.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 train 数据写入 JSONL 文件\n",
    "with open(train_output_file, 'w', encoding='utf-8') as train_file:\n",
    "    for item in shuffled_train_data:\n",
    "        json.dump(item, train_file)\n",
    "        train_file.write('\\n')\n",
    "\n",
    "# 随机打乱 dev_dict 中的元素\n",
    "shuffled_dev_data = []\n",
    "for k in dev_dict.keys():\n",
    "    for x in dev_dict[k]:\n",
    "        shuffled_dev_data.append(x)\n",
    "random.shuffle(shuffled_dev_data)\n",
    "\n",
    "# 指定保存 dev 数据的文件名，例如 \"shuffled_dev_data.jsonl\"\n",
    "dev_output_file = \"../our_data/ExpertQA/dev.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 dev 数据写入 JSONL 文件\n",
    "with open(dev_output_file, 'w', encoding='utf-8') as dev_file:\n",
    "    for item in shuffled_dev_data:\n",
    "        json.dump(item, dev_file)\n",
    "        dev_file.write('\\n')\n",
    "\n",
    "# 随机打乱 test_dict 中的元素\n",
    "shuffled_test_data = []\n",
    "for k in test_dict.keys():\n",
    "    for x in test_dict[k]:\n",
    "        shuffled_test_data.append(x)\n",
    "random.shuffle(shuffled_test_data)\n",
    "\n",
    "# 指定保存 test 数据的文件名，例如 \"shuffled_test_data.jsonl\"\n",
    "test_output_file = \"../our_data/ExpertQA/test.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 test 数据写入 JSONL 文件\n",
    "with open(test_output_file, 'w', encoding='utf-8') as test_file:\n",
    "    for item in shuffled_test_data:\n",
    "        json.dump(item, test_file)\n",
    "        test_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAGRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1922it [00:00, 58878.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1922\n",
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "716it [00:00, 54261.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716\n",
      "623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_hagrid_data_item(data_item):\n",
    "    for answer in data_item[\"answers\"]:\n",
    "        if \"attributable\" in answer:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "train_data = [json.loads(line) for line in tqdm(open(\"../raw_data/hagrid/hagrid-v1.0-en/train.jsonl\"))]\n",
    "print(len(train_data))\n",
    "print(len([item for item in train_data if check_hagrid_data_item(item)]))\n",
    "dev_data = [json.loads(line) for line in tqdm(open(\"../raw_data/hagrid/hagrid-v1.0-en/dev.jsonl\"))]\n",
    "print(len(dev_data))\n",
    "print(len([item for item in dev_data if check_hagrid_data_item(item)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1922it [00:00, 16020.53it/s]\n",
      "716it [00:00, 53781.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n",
      "1042\n",
      "Train Data Size: 885\n",
      "Dev Data Size: 52\n",
      "Test Data Size: 105\n",
      "Question Overlap between Train and Dev: set()\n",
      "Question Overlap between Train and Test: set()\n",
      "Question Overlap between Dev and Test: set()\n"
     ]
    }
   ],
   "source": [
    "# loading data from original dataset\n",
    "train_data = [json.loads(line) for line in tqdm(open(\"../raw_data/hagrid/hagrid-v1.0-en/train.jsonl\"))]\n",
    "dev_data = [json.loads(line) for line in tqdm(open(\"../raw_data/hagrid/hagrid-v1.0-en/dev.jsonl\"))]\n",
    "data = train_data + dev_data\n",
    "data = [_ for _ in data if check_hagrid_data_item(_)]\n",
    "question_to_data = {x[\"query\"]: [] for x in data}\n",
    "for x in data:\n",
    "    question_to_data[x[\"query\"]].append(x)\n",
    "print(len(data))\n",
    "print(len(question_to_data))\n",
    "\n",
    "import random\n",
    "\n",
    "# 假设 question_to_data 是包含数据的字典\n",
    "# 请将以下代码中的 \"question_to_data\" 替换为您的实际字典变量\n",
    "\n",
    "# 随机打乱字典的键值对\n",
    "shuffled_question_to_data = list(question_to_data.items())\n",
    "random.shuffle(shuffled_question_to_data)\n",
    "\n",
    "# 计算划分的数据量\n",
    "total_count = len(shuffled_question_to_data)\n",
    "train_count = int(0.85 * total_count)\n",
    "dev_count = int(0.05 * total_count)\n",
    "test_count = total_count - train_count - dev_count\n",
    "\n",
    "# 划分数据集\n",
    "train_dict = dict(shuffled_question_to_data[:train_count])\n",
    "dev_dict = dict(shuffled_question_to_data[train_count:train_count+dev_count])\n",
    "test_dict = dict(shuffled_question_to_data[train_count+dev_count:])\n",
    "\n",
    "# 打印划分后的数据集大小\n",
    "print(\"Train Data Size:\", len(train_dict))\n",
    "print(\"Dev Data Size:\", len(dev_dict))\n",
    "print(\"Test Data Size:\", len(test_dict))\n",
    "\n",
    "# 创建集合来存储各个数据集中的 \"question\" 值\n",
    "train_questions = set(train_dict.keys())\n",
    "dev_questions = set(dev_dict.keys())\n",
    "test_questions = set(test_dict.keys())\n",
    "\n",
    "# 检查是否有 \"question\" 重叠\n",
    "overlap_train_dev = train_questions.intersection(dev_questions)\n",
    "overlap_train_test = train_questions.intersection(test_questions)\n",
    "overlap_dev_test = dev_questions.intersection(test_questions)\n",
    "\n",
    "# 打印重叠情况\n",
    "print(\"Question Overlap between Train and Dev:\", overlap_train_dev)\n",
    "print(\"Question Overlap between Train and Test:\", overlap_train_test)\n",
    "print(\"Question Overlap between Dev and Test:\", overlap_dev_test)\n",
    "\n",
    "# 随机打乱 train_dict 中的元素\n",
    "shuffled_train_data = []\n",
    "for k in train_dict.keys():\n",
    "    for x in train_dict[k]:\n",
    "        shuffled_train_data.append(x)\n",
    "random.shuffle(shuffled_train_data)\n",
    "\n",
    "# 指定保存 train 数据的文件名，例如 \"shuffled_train_data.jsonl\"\n",
    "train_output_file = \"../our_data/hagrid/train.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 train 数据写入 JSONL 文件\n",
    "with open(train_output_file, 'w', encoding='utf-8') as train_file:\n",
    "    for item in shuffled_train_data:\n",
    "        json.dump(item, train_file)\n",
    "        train_file.write('\\n')\n",
    "\n",
    "# 随机打乱 dev_dict 中的元素\n",
    "shuffled_dev_data = []\n",
    "for k in dev_dict.keys():\n",
    "    for x in dev_dict[k]:\n",
    "        shuffled_dev_data.append(x)\n",
    "random.shuffle(shuffled_dev_data)\n",
    "\n",
    "# 指定保存 dev 数据的文件名，例如 \"shuffled_dev_data.jsonl\"\n",
    "dev_output_file = \"../our_data/hagrid/dev.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 dev 数据写入 JSONL 文件\n",
    "with open(dev_output_file, 'w', encoding='utf-8') as dev_file:\n",
    "    for item in shuffled_dev_data:\n",
    "        json.dump(item, dev_file)\n",
    "        dev_file.write('\\n')\n",
    "\n",
    "# 随机打乱 test_dict 中的元素\n",
    "shuffled_test_data = []\n",
    "for k in test_dict.keys():\n",
    "    for x in test_dict[k]:\n",
    "        shuffled_test_data.append(x)\n",
    "random.shuffle(shuffled_test_data)\n",
    "\n",
    "# 指定保存 test 数据的文件名，例如 \"shuffled_test_data.jsonl\"\n",
    "test_output_file = \"../our_data/hagrid/test.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 test 数据写入 JSONL 文件\n",
    "with open(test_output_file, 'w', encoding='utf-8') as test_file:\n",
    "    for item in shuffled_test_data:\n",
    "        json.dump(item, test_file)\n",
    "        test_file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5528it [00:00, 30120.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5528\n",
      "1450\n",
      "Train Data Size: 1232\n",
      "Dev Data Size: 72\n",
      "Test Data Size: 146\n",
      "Question Overlap between Train and Dev: set()\n",
      "Question Overlap between Train and Test: set()\n",
      "Question Overlap between Dev and Test: set()\n",
      "Train Data Size: 4704\n",
      "Dev Data Size: 272\n",
      "Test Data Size: 552\n"
     ]
    }
   ],
   "source": [
    "data = [json.loads(line) for line in tqdm(open(\"../raw_data/Stanford-GenSearch/human_evaluation_annotations.jsonl\"))]\n",
    "question_to_data = {x[\"query\"]: [] for x in data}\n",
    "for x in data:\n",
    "    question_to_data[x[\"query\"]].append(x)\n",
    "print(len(data))\n",
    "print(len(question_to_data))\n",
    "\n",
    "shuffled_question_to_data = list(question_to_data.items())\n",
    "random.shuffle(shuffled_question_to_data)\n",
    "\n",
    "total_count = len(shuffled_question_to_data)\n",
    "train_count = int(0.85 * total_count)\n",
    "dev_count = int(0.05 * total_count)\n",
    "test_count = total_count - train_count - dev_count\n",
    "\n",
    "# 划分数据集\n",
    "train_dict = dict(shuffled_question_to_data[:train_count])\n",
    "dev_dict = dict(shuffled_question_to_data[train_count:train_count+dev_count])\n",
    "test_dict = dict(shuffled_question_to_data[train_count+dev_count:])\n",
    "\n",
    "# 打印划分后的数据集大小\n",
    "print(\"Train Data Size:\", len(train_dict))\n",
    "print(\"Dev Data Size:\", len(dev_dict))\n",
    "print(\"Test Data Size:\", len(test_dict))\n",
    "\n",
    "# 假设 train_dict、dev_dict 和 test_dict 分别是包含数据的字典\n",
    "# 请将以下代码中的变量名替换为您的实际字典变量\n",
    "\n",
    "# 创建集合来存储各个数据集中的 \"question\" 值\n",
    "train_questions = set(train_dict.keys())\n",
    "dev_questions = set(dev_dict.keys())\n",
    "test_questions = set(test_dict.keys())\n",
    "\n",
    "# 检查是否有 \"question\" 重叠\n",
    "overlap_train_dev = train_questions.intersection(dev_questions)\n",
    "overlap_train_test = train_questions.intersection(test_questions)\n",
    "overlap_dev_test = dev_questions.intersection(test_questions)\n",
    "\n",
    "# 打印重叠情况\n",
    "print(\"Question Overlap between Train and Dev:\", overlap_train_dev)\n",
    "print(\"Question Overlap between Train and Test:\", overlap_train_test)\n",
    "print(\"Question Overlap between Dev and Test:\", overlap_dev_test)\n",
    "\n",
    "# 随机打乱 train_dict 中的元素\n",
    "shuffled_train_data = []\n",
    "for k in train_dict.keys():\n",
    "    for x in train_dict[k]:\n",
    "        shuffled_train_data.append(x)\n",
    "random.shuffle(shuffled_train_data)\n",
    "\n",
    "# 指定保存 train 数据的文件名，例如 \"shuffled_train_data.jsonl\"\n",
    "train_output_file = \"../our_data/Stanford-GenSearch/train.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 train 数据写入 JSONL 文件\n",
    "with open(train_output_file, 'w', encoding='utf-8') as train_file:\n",
    "    for item in shuffled_train_data:\n",
    "        json.dump(item, train_file)\n",
    "        train_file.write('\\n')\n",
    "\n",
    "# 随机打乱 dev_dict 中的元素\n",
    "shuffled_dev_data = []\n",
    "for k in dev_dict.keys():\n",
    "    for x in dev_dict[k]:\n",
    "        shuffled_dev_data.append(x)\n",
    "random.shuffle(shuffled_dev_data)\n",
    "\n",
    "# 指定保存 dev 数据的文件名，例如 \"shuffled_dev_data.jsonl\"\n",
    "dev_output_file = \"../our_data/Stanford-GenSearch/dev.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 dev 数据写入 JSONL 文件\n",
    "with open(dev_output_file, 'w', encoding='utf-8') as dev_file:\n",
    "    for item in shuffled_dev_data:\n",
    "        json.dump(item, dev_file)\n",
    "        dev_file.write('\\n')\n",
    "\n",
    "# 随机打乱 test_dict 中的元素\n",
    "shuffled_test_data = []\n",
    "for k in test_dict.keys():\n",
    "    for x in test_dict[k]:\n",
    "        shuffled_test_data.append(x)\n",
    "random.shuffle(shuffled_test_data)\n",
    "\n",
    "# 指定保存 test 数据的文件名，例如 \"shuffled_test_data.jsonl\"\n",
    "test_output_file = \"../our_data/Stanford-GenSearch/test.jsonl\"\n",
    "\n",
    "# 将随机打乱后的 test 数据写入 JSONL 文件\n",
    "with open(test_output_file, 'w', encoding='utf-8') as test_file:\n",
    "    for item in shuffled_test_data:\n",
    "        json.dump(item, test_file)\n",
    "        test_file.write('\\n')\n",
    "\n",
    "print(\"Train Data Size:\", len(shuffled_train_data))\n",
    "print(\"Dev Data Size:\", len(shuffled_dev_data))\n",
    "print(\"Test Data Size:\", len(shuffled_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
