{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import DatasetLoader\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import utils\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = [json.loads(l) for l in open(\"../hf_data/merged_train.jsonl\")]\n",
    "merged_dev = [json.loads(l) for l in open(\"../hf_data/merged_dev.jsonl\")]\n",
    "merged_test = [json.loads(l) for l in open(\"../hf_data/merged_test.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'ek haseena thi ek deewana turkish drama cast',\n",
       " 'claim': 'Natasha and her fiance, Sunny, visit her ancestral property where they meet Devdhar and form a passionate connection with him.[1]',\n",
       " 'claim_raw_string': 'Natasha and her fiance, Sunny, visit her ancestral property where they meet Devdhar and form a passionate connection with him.[1]',\n",
       " 'response': 'Natasha and her fiance, Sunny, visit her ancestral property where they meet Devdhar and form a passionate connection with him.[1]Ek Haseena Thi Ek Deewana Tha (2017) is a romantic drama directed by Suneel Darshan.[2]The movie features a soundtrack of Yaseer Desai, music by Nadeem, mixed by Adam Whittaker, and lyrics by Nadeem.[2]The cast includes Party guest (as Yesmien Bagh Ali), production manager (as Sajida Ahmad), assistant re recording mixer (as Devobrat Chaliha), and sound editor/sound designer (as Aakash Chaudhary).[3]',\n",
       " 'references': ['[1] She sets off for her destination wedding with fiancé, Sunny, to her ancestral property Mt. Unique Estate, only to fall helplessly in love with its stud farm keeper Devdhar'],\n",
       " 'citation_links': ['https://en.wikipedia.org/wiki/Ek_Haseena_Thi_Ek_Deewana_Tha#:~:text=1%20Shiv%20Darshan%20as%20Devdhar%202%20Natasha%20Fernandez,7%20Krishan%20Tandon%208%20Lalitmohan%20Tiwari%20More%20items'],\n",
       " 'webpage_references': [],\n",
       " 'attribution_label': 'attributable',\n",
       " 'src_dataset': 'Stanford-GenSearch',\n",
       " 'id': 'Stanford-GenSearch_8ec32164-58c0-4f28-8fef-78b523ab93f3'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train[25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Count: 29374\n",
      "Attributable Count: 19062 (64.89%)\n",
      "Not Attributable Count: 10312 (35.11%)\n",
      "Attributable / Not Attributable Ratio: 1.85\n",
      "\n",
      "Total Count: 8253\n",
      "Attributable Count: 3053 (36.99%)\n",
      "Not Attributable Count: 5200 (63.01%)\n",
      "Attributable / Not Attributable Ratio: 0.59\n",
      "\n",
      "Total Count: 2977\n",
      "Attributable Count: 2248 (75.51%)\n",
      "Not Attributable Count: 729 (24.49%)\n",
      "Attributable / Not Attributable Ratio: 3.08\n",
      "\n",
      "Total Count: 8827\n",
      "Attributable Count: 6092 (69.02%)\n",
      "Not Attributable Count: 2735 (30.98%)\n",
      "Attributable / Not Attributable Ratio: 2.23\n",
      "\n",
      "Total Count: 9317\n",
      "Attributable Count: 7669 (82.31%)\n",
      "Not Attributable Count: 1648 (17.69%)\n",
      "Attributable / Not Attributable Ratio: 4.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_ratio(data_list, src_dataset=\"any\"):\n",
    "    attributable_count = sum(1 for item in data_list if item['attribution_label'] == 'attributable' and (src_dataset == \"any\" or item[\"src_dataset\"] == src_dataset))\n",
    "    not_attributable_count = sum(1 for item in data_list if item['attribution_label'] == 'not attributable' and (src_dataset == \"any\" or item[\"src_dataset\"] == src_dataset))\n",
    "    total_count = attributable_count + not_attributable_count\n",
    "    \n",
    "    attributable_ratio = attributable_count / total_count\n",
    "    not_attributable_ratio = not_attributable_count / total_count\n",
    "    ratio_ratio = attributable_ratio / not_attributable_ratio\n",
    "    \n",
    "    print(f\"Total Count: {total_count}\")\n",
    "    print(f\"Attributable Count: {attributable_count} ({attributable_ratio:.2%})\")\n",
    "    print(f\"Not Attributable Count: {not_attributable_count} ({not_attributable_ratio:.2%})\")\n",
    "    print(f\"Attributable / Not Attributable Ratio: {ratio_ratio:.2f}\")\n",
    "    print(\"\")\n",
    "\n",
    "display_ratio(merged_train)\n",
    "display_ratio(merged_train, src_dataset=\"AttributedQA\")\n",
    "display_ratio(merged_train, src_dataset=\"HAGRID\")\n",
    "display_ratio(merged_train, src_dataset=\"ExpertQA\")\n",
    "display_ratio(merged_train, src_dataset=\"Stanford-GenSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributedqa_train = [item for item in merged_train if item[\"src_dataset\"] == \"AttributedQA\"]\n",
    "attributedqa_dev = [item for item in merged_dev if item[\"src_dataset\"] == \"AttributedQA\"]\n",
    "attributedqa_test = [item for item in merged_test if item[\"src_dataset\"] == \"AttributedQA\"]\n",
    "hagrid_train = [item for item in merged_train if item[\"src_dataset\"] == \"HAGRID\"]\n",
    "hagrid_dev = [item for item in merged_dev if item[\"src_dataset\"] == \"HAGRID\"]\n",
    "hagrid_test = [item for item in merged_test if item[\"src_dataset\"] == \"HAGRID\"]\n",
    "expertqa_train = [item for item in merged_train if item[\"src_dataset\"] == \"ExpertQA\"]\n",
    "expertqa_dev = [item for item in merged_dev if item[\"src_dataset\"] == \"ExpertQA\"]\n",
    "expertqa_test = [item for item in merged_test if item[\"src_dataset\"] == \"ExpertQA\"]\n",
    "stanford_train = [item for item in merged_train if item[\"src_dataset\"] == \"Stanford-GenSearch\"]\n",
    "stanford_dev = [item for item in merged_dev if item[\"src_dataset\"] == \"Stanford-GenSearch\"]\n",
    "stanford_test = [item for item in merged_test if item[\"src_dataset\"] == \"Stanford-GenSearch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After balancing:\n",
      "Total Count: 2000\n",
      "Attributable Count: 1000 (50.00%)\n",
      "Not Attributable Count: 1000 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 1458\n",
      "Attributable Count: 729 (50.00%)\n",
      "Not Attributable Count: 729 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 5470\n",
      "Attributable Count: 2735 (50.00%)\n",
      "Not Attributable Count: 2735 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 3296\n",
      "Attributable Count: 1648 (50.00%)\n",
      "Not Attributable Count: 1648 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 336\n",
      "Attributable Count: 168 (50.00%)\n",
      "Not Attributable Count: 168 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 64\n",
      "Attributable Count: 32 (50.00%)\n",
      "Not Attributable Count: 32 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 334\n",
      "Attributable Count: 167 (50.00%)\n",
      "Not Attributable Count: 167 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 172\n",
      "Attributable Count: 86 (50.00%)\n",
      "Not Attributable Count: 86 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 716\n",
      "Attributable Count: 358 (50.00%)\n",
      "Not Attributable Count: 358 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 174\n",
      "Attributable Count: 87 (50.00%)\n",
      "Not Attributable Count: 87 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 620\n",
      "Attributable Count: 310 (50.00%)\n",
      "Not Attributable Count: 310 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n",
      "Total Count: 366\n",
      "Attributable Count: 183 (50.00%)\n",
      "Not Attributable Count: 183 (50.00%)\n",
      "Attributable / Not Attributable Ratio: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def balance_data(data_list, src_dataset=\"any\"):\n",
    "    # 分离 \"attributable\" 和 \"not attributable\" 数据\n",
    "    attributable_data = [item for item in data_list if item['attribution_label'] == 'attributable']\n",
    "    not_attributable_data = [item for item in data_list if item['attribution_label'] == 'not attributable']\n",
    "    \n",
    "    # 计算两类数据的数量\n",
    "    min_count = min(len(attributable_data), len(not_attributable_data))\n",
    "    if src_dataset == \"AttributedQA\":\n",
    "        min_count = min(min_count, 1000)\n",
    "    \n",
    "    # 随机采样，使得两类数据的数量相等\n",
    "    balanced_data = random.sample(attributable_data, min_count) + random.sample(not_attributable_data, min_count)\n",
    "    \n",
    "    return balanced_data\n",
    "\n",
    "balanced_attributedqa_train = balance_data(attributedqa_train, src_dataset=\"AttributedQA\")\n",
    "balanced_hagrid_train = balance_data(hagrid_train)\n",
    "balanced_expertqa_train = balance_data(expertqa_train)\n",
    "balanced_stanford_train = balance_data(stanford_train)\n",
    "balanced_attributed_dev = balance_data(attributedqa_dev)\n",
    "balanced_hagrid_dev = balance_data(hagrid_dev)\n",
    "balanced_expertqa_dev = balance_data(expertqa_dev)\n",
    "balanced_stanford_dev = balance_data(stanford_dev)\n",
    "balanced_attributed_test = balance_data(attributedqa_test)\n",
    "balanced_hagrid_test = balance_data(hagrid_test)\n",
    "balanced_expertqa_test = balance_data(expertqa_test)\n",
    "balanced_stanford_test = balance_data(stanford_test)\n",
    "balanced_train = balanced_attributedqa_train + balanced_hagrid_train + balanced_expertqa_train + balanced_stanford_train\n",
    "balanced_dev = balanced_attributed_dev + balanced_hagrid_dev + balanced_expertqa_dev + balanced_stanford_dev\n",
    "balanced_test = balanced_attributed_test + balanced_hagrid_test + balanced_expertqa_test + balanced_stanford_test\n",
    "print(\"After balancing:\")\n",
    "display_ratio(balanced_attributedqa_train)\n",
    "display_ratio(balanced_hagrid_train)\n",
    "display_ratio(balanced_expertqa_train)\n",
    "display_ratio(balanced_stanford_train)\n",
    "display_ratio(balanced_attributed_dev)\n",
    "display_ratio(balanced_hagrid_dev)\n",
    "display_ratio(balanced_expertqa_dev)\n",
    "display_ratio(balanced_stanford_dev)\n",
    "display_ratio(balanced_attributed_test)\n",
    "display_ratio(balanced_hagrid_test)\n",
    "display_ratio(balanced_expertqa_test)\n",
    "display_ratio(balanced_stanford_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../hf_data/train_all_subset_balanced.jsonl\", \"w\") as f:\n",
    "    for item in balanced_train:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "with open(\"../hf_data/dev_all_subset_balanced.jsonl\", \"w\") as f:\n",
    "    for item in balanced_dev:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "with open(\"../hf_data/test_all_subset_balanced.jsonl\", \"w\") as f:\n",
    "    for item in balanced_test:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12224\n",
      "906\n",
      "1876\n"
     ]
    }
   ],
   "source": [
    "print(len(balanced_train))\n",
    "print(len(balanced_dev))\n",
    "print(len(balanced_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
